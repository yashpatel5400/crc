{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import cvxpy as cp\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "from pydmd import DMDc\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution parameters need to be fixed for the simulation\n",
    "mu_m_B, sigma_m_B = np.random.random(), np.abs(np.random.random())\n",
    "mu_m_L, sigma_m_L = np.random.random(), np.abs(np.random.random())\n",
    "mu_d_L, sigma_d_L = np.random.random(), np.abs(np.random.random())\n",
    "mu_k_B, sigma_k_B = np.random.random(), np.abs(np.random.random())\n",
    "mu_d_B, sigma_d_B = np.random.random(), np.abs(np.random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(np.random.normal(mu_m_B, sigma_m_B, 10)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_L = np.expand_dims(np.abs(np.random.normal(mu_m_L, sigma_m_L, 3)),axis=0)\n",
    "m_B = np.expand_dims(np.abs(np.random.normal(mu_m_B, sigma_m_B, 3)),axis=0)\n",
    "np.vstack([m_B, m_L]).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dynamics_matrices(num_samples):\n",
    "    m_B = np.expand_dims(np.abs(np.random.normal(mu_m_B, sigma_m_B, num_samples)),axis=0)\n",
    "    m_L = np.expand_dims(np.abs(np.random.normal(mu_m_L, sigma_m_L, num_samples)),axis=0)\n",
    "    d_L = np.expand_dims(np.abs(np.random.normal(mu_d_L, sigma_d_L, num_samples)),axis=0)\n",
    "    k_B = np.expand_dims(np.abs(np.random.normal(mu_k_B, sigma_k_B, num_samples)),axis=0)\n",
    "    d_B = np.expand_dims(np.abs(np.random.normal(mu_d_B, sigma_d_B, num_samples)),axis=0)\n",
    "    \n",
    "    thetas = np.vstack([m_B, m_L, d_L, k_B, d_B]).T\n",
    "    As = np.zeros((num_samples, 4, 4))\n",
    "    As[:,0,1]  = 1\n",
    "\n",
    "    As[:,1,1] = -d_L / m_L - d_L / m_B \n",
    "    As[:,1,2] = k_B / m_B\n",
    "    As[:,1,3] = d_B / m_B \n",
    "\n",
    "    As[:,2,3] = 1\n",
    "\n",
    "    As[:,3,1] = d_L / m_B\n",
    "    As[:,3,2] = -k_B / m_B\n",
    "    As[:,3,3] = -d_B / m_B\n",
    "\n",
    "    Bs = np.zeros((num_samples, 4, 1))\n",
    "    Bs[:,1,0] = 1 / m_L + 1 / m_B\n",
    "    Bs[:,3,0] = -1 / m_B\n",
    "\n",
    "    return thetas, (As, Bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m: trajectory length\n",
    "def generate_system_trajectories(As, Bs, m = 25):\n",
    "    n = As.shape[-1]\n",
    "    l = Bs.shape[-1]\n",
    "\n",
    "    x0 = np.random.random((n, 1))\n",
    "    u = np.random.rand(l, m - 1) - .5\n",
    "\n",
    "    x0 = np.tile(x0, reps=(As.shape[0],1,1)).astype(np.float32)\n",
    "    u  = np.tile(u,  reps=(Bs.shape[0],1,1)).astype(np.float32)\n",
    "\n",
    "    snapshots = [x0]\n",
    "\n",
    "    for i in range(m - 1):\n",
    "        snapshots.append(As @ snapshots[i] + Bs @ u[:, :, i:i+1])\n",
    "    snapshots = np.array(snapshots).T\n",
    "    return {'snapshots': snapshots, 'u': u, 'B': Bs, 'A': As}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_dynamics_matrices(system):\n",
    "    mb_size = system[\"A\"].shape[0]\n",
    "    A_hats, B_hats = [], []\n",
    "    for i in range(mb_size):\n",
    "        dmdc = DMDc(svd_rank=-1, opt=True)\n",
    "        dmdc.fit(system['snapshots'][:,:,i,:], system['u'][i])\n",
    "        A_hat, B_hat, _ = dmdc.reconstructed_data() # NOTE: the PyDMD reconstructed_data() function was modified to return the dynamics -- this will *not* work by default\n",
    "        A_hats.append(np.real(A_hat))\n",
    "        B_hats.append(np.real(B_hat))\n",
    "    A_hats = np.array(A_hats).reshape(mb_size, -1)\n",
    "    B_hats = np.array(B_hats).reshape(mb_size, -1)\n",
    "    return A_hats, B_hats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_pts):\n",
    "    thetas, (As, Bs) = generate_dynamics_matrices(n_pts)\n",
    "    system = generate_system_trajectories(As, Bs, m = 25)\n",
    "    A_hats, B_hats = estimate_dynamics_matrices(system)\n",
    "    A_hats, B_hats = A_hats.reshape(As.shape), B_hats.reshape(Bs.shape)\n",
    "\n",
    "    thresh    = 0.1\n",
    "    valid_ind = np.where(np.logical_and(\n",
    "        np.linalg.norm(A_hats - As, ord=\"fro\", axis=(1,2)) < thresh,\n",
    "        np.linalg.norm(B_hats - Bs, ord=\"fro\", axis=(1,2)) < thresh,\n",
    "    ))\n",
    "    thetas, As, Bs, A_hats, B_hats = thetas[valid_ind], As[valid_ind], Bs[valid_ind], A_hats[valid_ind], B_hats[valid_ind]\n",
    "\n",
    "    thetas         = torch.from_numpy(thetas).to(torch.float32).to(device)\n",
    "    As, Bs         = torch.from_numpy(As).to(torch.float32).to(device), torch.from_numpy(Bs).to(torch.float32).to(device)\n",
    "    A_hats, B_hats = torch.from_numpy(A_hats).to(torch.float32).to(device), torch.from_numpy(B_hats).to(torch.float32).to(device)\n",
    "\n",
    "    return thetas, (As, Bs), (A_hats, B_hats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextualLQR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(5, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        \n",
    "        self.fc_A = nn.Linear(64, 16)\n",
    "        self.fc_B = nn.Linear(64, 4)\n",
    "        self.fc_C = nn.Linear(64, 24)\n",
    "\n",
    "    def forward(self, theta):\n",
    "        x = F.relu(self.fc1(theta))\n",
    "        \n",
    "        fc2_x = self.fc2(x)\n",
    "        x     = F.relu(x + fc2_x)\n",
    "\n",
    "        fc3_x = self.fc3(x)\n",
    "        x     = F.relu(x + fc3_x)\n",
    "\n",
    "        # for predictions of A matrix\n",
    "        A = self.fc_A(x).reshape((-1,4,4))\n",
    "\n",
    "        # for predictions of B matrix\n",
    "        B = self.fc_B(x).reshape((-1,4,1))\n",
    "\n",
    "        # for predictions of C := [A, B] matrix\n",
    "        # C = self.fc_C(x).reshape((-1,4,6))\n",
    "        # return C\n",
    "        return A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4204965772700907.0. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3849679.6802446805. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 17660239717608.03. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 67486432.07023917. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6269693.246589017. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 940663290090566.8. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.0383402467463137e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4.404246348080496e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 49338309640.86657. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 63352598107399.76. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 8.31493612241135e+16. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 25041323.802183848. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 9513365.99768525. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1162570.0704100425. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 9.281543834683343e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 8.508730745274786e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3041938647.7969856. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 156788041.81968248. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 549473486.1544527. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 116297.82479018807. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.3833372891889669e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 75284277340.89761. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 5568894246742954.0. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 147995030.60409778. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 38571496.95902405. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 5735596480508.872. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2550955799.7392273. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.966429101743364e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 8.798118556040588e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2728054.6695639226. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.08331772000232e+25. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 141107248336.07095. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 754023707670.8755. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 177133674150.15317. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 406381823640.5795. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 756816425398.0323. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 96311974.80174789. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 5065902045.199892. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 9.260404660584893e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.1364497504430377e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.8963767841596902e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 54328358625993.21. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 5.058692723988389e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 12150520740688.883. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 30204230477.50274. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 559679.0540151268. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 53672679.78621372. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6.901369105304952e+16. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.5603253166847988e+16. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3.2737124633241215e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4.560849571986121e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2348107869795133.0. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4.031700493486166e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4.347172576792633e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2650030453235.218. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4309393118024.4014. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1371668600527.9275. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.7815288525485613e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 143481901.09861708. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 915036996438295.0. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 268216.78928952524. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 40774118.79076445. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.9536888466545572e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6.5463544519580824e+16. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.2265964608033655e+21. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 20495479864.78973. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.5866217922458337e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 794736999580622.6. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 30026018378.47642. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.3819360499981826e+23. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3.2299613121252424e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 190154697.11592868. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6.369865657202827e+23. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1597729607.6776369. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3564663108333023.0. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 70769397018991.53. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3.310593916891115e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 21920160422.719265. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 5222136.875919208. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 214147026460.46542. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4597156687.6309. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 42517037.91041403. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4.638712715080766e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 10893323418291.328. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 15218846208333.393. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 547196461187794.0. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.2417995543081088e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6.922985284966891e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 198435117603946.56. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3448218762808.957. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 490154008143.7896. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.9873011851218106e+22. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.1479097349299356e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.777160207122364e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 7.126226273483194e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 961805.5276508725. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2299653493484.589. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 44742205444868.13. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.6062266732959257e+21. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 7.072308355670304e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 179814901701.7554. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4846327618.092017. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 9703816617732932.0. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6428518446291.719. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 50944750006.35799. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 25060336608.63407. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 246223072244.4686. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 156643925987.5973. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 99460114.3019387. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 9.975479896881412e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.54051536523464e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 9.575001987428352e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 15304717237434.188. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1432749561873.7803. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 110333409.94877814. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 723922940.0264941. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 493957690.5376791. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 10719510.4975188. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3332071128.1703663. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 580343036.027237. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1988079386.536094. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4.569286472039765e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 587450427934659.2. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 24695262.875278763. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4753483.439269679. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 155736491.74478292. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.2170662170376856e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 629936741026.2794. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 172168246495.3966. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 981862.9785612785. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1290827.098978919. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 367951479456162.75. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 705523470.8901775. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 270119072.9384531. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 7.01717084987797e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 25137685.87351332. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4.632105372787756e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 136995.38492184805. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 63673205685.13907. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 290768.040352796. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3.3691750521882083e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 9.63799306449492e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 76957988.52624668. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 8.104704200694377e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.4468688225697554e+16. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 7.704632636354937e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2841198313092165.5. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 115443982395.72943. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 7.051947673557824e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.3684050522177501e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.3972723791700783e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 14080724.231067533. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3306974697.24847. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.3775073823379554e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1262892634598.7883. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3.163542667312971e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 11355107.820428487. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6.272152768043139e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.1699998764347492e+21. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.8120302023120596e+16. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 15284294.522771725. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.1330116673561763e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1547369.8701115132. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.453659329182675e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 965517530.2004843. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.291443747664126e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3.905667531329599e+21. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.4598029436466767e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 17004597.01258118. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 207110939272.71542. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 304001841875.6623. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 8.897799317813427e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.1475948079263113e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 7659673641632175.0. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.3763911237027063e+21. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.5751872888834666e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 153670724.23069105. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1640510406108.5115. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 420824171907337.06. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 15101412.208410151. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 164150428698.51205. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3.8563833144468506e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1519249112.4226274. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.4665991692360815e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 187556.9014577733. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 152428657879.46835. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1587528.9025409303. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3891570.114754618. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.947272335176837e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2752451.9781807796. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.984630576913257e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1259768997921.278. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 5.425001536943537e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 741834836696.5657. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.1496035120788426e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.8586605581692646e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.5963196350817796e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4.529705827329315e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1567950878999.356. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.6695082653509248e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4.46684248072209e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 76542729374320.4. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3.855515985652209e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 73868557907213.23. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.8879669685017746e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6.897788462314647e+16. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 8.057222642888722e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 180686.1073124741. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 7.128455991253315e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.162167243429835e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.3136576535269092e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 10062499.244634258. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2169238605549670.5. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.2218535327651965e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 541545742967.909. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.2522233401856727e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 12111147342738.46. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 67887536164.10265. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 300916417318416.3. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.0100246124728856e+21. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 46730610.322498895. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 249492044.88715494. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1203249659548.8232. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2003599.0312568394. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4160056.881557252. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 414925770.1647544. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.1077947983727172e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.2609678168185707e+23. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 665257.9031988129. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 353565701376516.6. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2701443.0171222948. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1735903.5299974098. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4526945659647.145. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 7888092989605.587. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.742390182459801e+21. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2422233046494.008. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4.180741158519655e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 212340646419.238. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 53448930.28277151. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1720131.0389948168. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3222222053575637.5. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1344434018312810.8. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.7792162092608394e+21. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6908303549046428.0. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.3012769344838808e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 420488358.85272753. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.0876616017218414e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 184638966008.66235. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 9.321836131238471e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 497238582.3144744. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3746578398911750.0. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 285854.0537208619. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2135186302399.3079. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4164525632546.4346. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 422324530.36124593. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 5.978208576412264e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 5500639729.991573. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1090081947190.7231. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 23861293362.704628. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 5129149921056.976. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 27286514278734.46. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 8.133966645882521e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 28676101319.131294. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1482075.7182222612. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.2216582252846432e+23. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2834245.1843649964. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.424660530360404e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 12863721056.843199. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 58166715263.257065. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 5.553699290332087e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 42974831.322460726. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.400705461056565e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 562727.7225464493. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "net       = ContextualLQR().to(device)\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "N_train = 500\n",
    "thetas_train, _, (As_train, Bs_train) = generate_data(N_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 18.77172088623047\n",
      "[2,     1] loss: 18.498838424682617\n",
      "[3,     1] loss: 18.23807144165039\n",
      "[4,     1] loss: 17.986616134643555\n",
      "[5,     1] loss: 17.740882873535156\n",
      "[6,     1] loss: 17.499446868896484\n",
      "[7,     1] loss: 17.261913299560547\n",
      "[8,     1] loss: 17.027006149291992\n",
      "[9,     1] loss: 16.79168128967285\n",
      "[10,     1] loss: 16.55467414855957\n",
      "[11,     1] loss: 16.315025329589844\n",
      "[12,     1] loss: 16.073326110839844\n",
      "[13,     1] loss: 15.828147888183594\n",
      "[14,     1] loss: 15.576333045959473\n",
      "[15,     1] loss: 15.316561698913574\n",
      "[16,     1] loss: 15.048047065734863\n",
      "[17,     1] loss: 14.770852088928223\n",
      "[18,     1] loss: 14.485342025756836\n",
      "[19,     1] loss: 14.191618919372559\n",
      "[20,     1] loss: 13.890378952026367\n",
      "[21,     1] loss: 13.58281135559082\n",
      "[22,     1] loss: 13.270419120788574\n",
      "[23,     1] loss: 12.955557823181152\n",
      "[24,     1] loss: 12.640838623046875\n",
      "[25,     1] loss: 12.328874588012695\n",
      "[26,     1] loss: 12.023726463317871\n",
      "[27,     1] loss: 11.730605125427246\n",
      "[28,     1] loss: 11.454116821289062\n",
      "[29,     1] loss: 11.199624061584473\n",
      "[30,     1] loss: 10.97236442565918\n",
      "[31,     1] loss: 10.776632308959961\n",
      "[32,     1] loss: 10.616015434265137\n",
      "[33,     1] loss: 10.492259979248047\n",
      "[34,     1] loss: 10.40479850769043\n",
      "[35,     1] loss: 10.350597381591797\n",
      "[36,     1] loss: 10.323314666748047\n",
      "[37,     1] loss: 10.313666343688965\n",
      "[38,     1] loss: 10.310579299926758\n",
      "[39,     1] loss: 10.303685188293457\n",
      "[40,     1] loss: 10.285371780395508\n",
      "[41,     1] loss: 10.251453399658203\n",
      "[42,     1] loss: 10.201332092285156\n",
      "[43,     1] loss: 10.136926651000977\n",
      "[44,     1] loss: 10.062234878540039\n",
      "[45,     1] loss: 9.98208999633789\n",
      "[46,     1] loss: 9.900991439819336\n",
      "[47,     1] loss: 9.822463035583496\n",
      "[48,     1] loss: 9.748913764953613\n",
      "[49,     1] loss: 9.681954383850098\n",
      "[50,     1] loss: 9.621417045593262\n",
      "[51,     1] loss: 9.566431999206543\n",
      "[52,     1] loss: 9.51574420928955\n",
      "[53,     1] loss: 9.467578887939453\n",
      "[54,     1] loss: 9.420467376708984\n",
      "[55,     1] loss: 9.373088836669922\n",
      "[56,     1] loss: 9.324349403381348\n",
      "[57,     1] loss: 9.27348518371582\n",
      "[58,     1] loss: 9.220070838928223\n",
      "[59,     1] loss: 9.164108276367188\n",
      "[60,     1] loss: 9.105891227722168\n",
      "[61,     1] loss: 9.04573917388916\n",
      "[62,     1] loss: 8.984315872192383\n",
      "[63,     1] loss: 8.92246150970459\n",
      "[64,     1] loss: 8.8607816696167\n",
      "[65,     1] loss: 8.799654960632324\n",
      "[66,     1] loss: 8.73918342590332\n",
      "[67,     1] loss: 8.679544448852539\n",
      "[68,     1] loss: 8.621087074279785\n",
      "[69,     1] loss: 8.563050270080566\n",
      "[70,     1] loss: 8.504889488220215\n",
      "[71,     1] loss: 8.445899963378906\n",
      "[72,     1] loss: 8.385723114013672\n",
      "[73,     1] loss: 8.324259757995605\n",
      "[74,     1] loss: 8.261345863342285\n",
      "[75,     1] loss: 8.197341918945312\n",
      "[76,     1] loss: 8.132369995117188\n",
      "[77,     1] loss: 8.066526412963867\n",
      "[78,     1] loss: 8.000347137451172\n",
      "[79,     1] loss: 7.934049129486084\n",
      "[80,     1] loss: 7.867640018463135\n",
      "[81,     1] loss: 7.801294326782227\n",
      "[82,     1] loss: 7.734823703765869\n",
      "[83,     1] loss: 7.668199062347412\n",
      "[84,     1] loss: 7.601297855377197\n",
      "[85,     1] loss: 7.534143447875977\n",
      "[86,     1] loss: 7.466721534729004\n",
      "[87,     1] loss: 7.399077892303467\n",
      "[88,     1] loss: 7.33065938949585\n",
      "[89,     1] loss: 7.261799335479736\n",
      "[90,     1] loss: 7.192832946777344\n",
      "[91,     1] loss: 7.123965740203857\n",
      "[92,     1] loss: 7.05540657043457\n",
      "[93,     1] loss: 6.987258434295654\n",
      "[94,     1] loss: 6.919771194458008\n",
      "[95,     1] loss: 6.852295398712158\n",
      "[96,     1] loss: 6.784980297088623\n",
      "[97,     1] loss: 6.718113899230957\n",
      "[98,     1] loss: 6.651548385620117\n",
      "[99,     1] loss: 6.585268974304199\n",
      "[100,     1] loss: 6.519465446472168\n",
      "[101,     1] loss: 6.45409631729126\n",
      "[102,     1] loss: 6.389385223388672\n",
      "[103,     1] loss: 6.325368404388428\n",
      "[104,     1] loss: 6.261862277984619\n",
      "[105,     1] loss: 6.199306488037109\n",
      "[106,     1] loss: 6.137257099151611\n",
      "[107,     1] loss: 6.075771331787109\n",
      "[108,     1] loss: 6.014680862426758\n",
      "[109,     1] loss: 5.95421838760376\n",
      "[110,     1] loss: 5.894476890563965\n",
      "[111,     1] loss: 5.835843563079834\n",
      "[112,     1] loss: 5.777843475341797\n",
      "[113,     1] loss: 5.7206878662109375\n",
      "[114,     1] loss: 5.6642889976501465\n",
      "[115,     1] loss: 5.608598709106445\n",
      "[116,     1] loss: 5.553380489349365\n",
      "[117,     1] loss: 5.498736381530762\n",
      "[118,     1] loss: 5.444860935211182\n",
      "[119,     1] loss: 5.391599655151367\n",
      "[120,     1] loss: 5.339046001434326\n",
      "[121,     1] loss: 5.286984443664551\n",
      "[122,     1] loss: 5.235345363616943\n",
      "[123,     1] loss: 5.18435525894165\n",
      "[124,     1] loss: 5.134106636047363\n",
      "[125,     1] loss: 5.084106922149658\n",
      "[126,     1] loss: 5.034458160400391\n",
      "[127,     1] loss: 4.985470771789551\n",
      "[128,     1] loss: 4.936832427978516\n",
      "[129,     1] loss: 4.888428688049316\n",
      "[130,     1] loss: 4.8403849601745605\n",
      "[131,     1] loss: 4.792781352996826\n",
      "[132,     1] loss: 4.745754718780518\n",
      "[133,     1] loss: 4.699163436889648\n",
      "[134,     1] loss: 4.65286922454834\n",
      "[135,     1] loss: 4.607039928436279\n",
      "[136,     1] loss: 4.561783313751221\n",
      "[137,     1] loss: 4.5169172286987305\n",
      "[138,     1] loss: 4.472387313842773\n",
      "[139,     1] loss: 4.428526401519775\n",
      "[140,     1] loss: 4.385340690612793\n",
      "[141,     1] loss: 4.342581272125244\n",
      "[142,     1] loss: 4.300166606903076\n",
      "[143,     1] loss: 4.258524417877197\n",
      "[144,     1] loss: 4.217535495758057\n",
      "[145,     1] loss: 4.1772141456604\n",
      "[146,     1] loss: 4.137715816497803\n",
      "[147,     1] loss: 4.098741054534912\n",
      "[148,     1] loss: 4.059860706329346\n",
      "[149,     1] loss: 4.021368503570557\n",
      "[150,     1] loss: 3.983351230621338\n",
      "[151,     1] loss: 3.945894956588745\n",
      "[152,     1] loss: 3.9084291458129883\n",
      "[153,     1] loss: 3.8711771965026855\n",
      "[154,     1] loss: 3.8341541290283203\n",
      "[155,     1] loss: 3.797590494155884\n",
      "[156,     1] loss: 3.761319637298584\n",
      "[157,     1] loss: 3.7252674102783203\n",
      "[158,     1] loss: 3.689814805984497\n",
      "[159,     1] loss: 3.6548023223876953\n",
      "[160,     1] loss: 3.619915723800659\n",
      "[161,     1] loss: 3.585202693939209\n",
      "[162,     1] loss: 3.550553798675537\n",
      "[163,     1] loss: 3.51625657081604\n",
      "[164,     1] loss: 3.4833157062530518\n",
      "[165,     1] loss: 3.450587511062622\n",
      "[166,     1] loss: 3.4173812866210938\n",
      "[167,     1] loss: 3.383993625640869\n",
      "[168,     1] loss: 3.3510124683380127\n",
      "[169,     1] loss: 3.318225622177124\n",
      "[170,     1] loss: 3.2854199409484863\n",
      "[171,     1] loss: 3.2526700496673584\n",
      "[172,     1] loss: 3.2206273078918457\n",
      "[173,     1] loss: 3.1890552043914795\n",
      "[174,     1] loss: 3.1576900482177734\n",
      "[175,     1] loss: 3.1263535022735596\n",
      "[176,     1] loss: 3.095179319381714\n",
      "[177,     1] loss: 3.0639848709106445\n",
      "[178,     1] loss: 3.033113718032837\n",
      "[179,     1] loss: 3.002352476119995\n",
      "[180,     1] loss: 2.971615791320801\n",
      "[181,     1] loss: 2.9410743713378906\n",
      "[182,     1] loss: 2.9107465744018555\n",
      "[183,     1] loss: 2.8807201385498047\n",
      "[184,     1] loss: 2.851008653640747\n",
      "[185,     1] loss: 2.8216440677642822\n",
      "[186,     1] loss: 2.791975736618042\n",
      "[187,     1] loss: 2.7622430324554443\n",
      "[188,     1] loss: 2.733203887939453\n",
      "[189,     1] loss: 2.704387664794922\n",
      "[190,     1] loss: 2.6755483150482178\n",
      "[191,     1] loss: 2.6468966007232666\n",
      "[192,     1] loss: 2.6185142993927\n",
      "[193,     1] loss: 2.5898492336273193\n",
      "[194,     1] loss: 2.5612926483154297\n",
      "[195,     1] loss: 2.5329036712646484\n",
      "[196,     1] loss: 2.504580497741699\n",
      "[197,     1] loss: 2.4765913486480713\n",
      "[198,     1] loss: 2.44857120513916\n",
      "[199,     1] loss: 2.420499563217163\n",
      "[200,     1] loss: 2.3928186893463135\n",
      "[201,     1] loss: 2.3654520511627197\n",
      "[202,     1] loss: 2.338080644607544\n",
      "[203,     1] loss: 2.3108553886413574\n",
      "[204,     1] loss: 2.284048080444336\n",
      "[205,     1] loss: 2.2572927474975586\n",
      "[206,     1] loss: 2.230907440185547\n",
      "[207,     1] loss: 2.2042348384857178\n",
      "[208,     1] loss: 2.177515745162964\n",
      "[209,     1] loss: 2.1514065265655518\n",
      "[210,     1] loss: 2.1255733966827393\n",
      "[211,     1] loss: 2.0993974208831787\n",
      "[212,     1] loss: 2.0733346939086914\n",
      "[213,     1] loss: 2.0476772785186768\n",
      "[214,     1] loss: 2.0220706462860107\n",
      "[215,     1] loss: 1.996396541595459\n",
      "[216,     1] loss: 1.9709506034851074\n",
      "[217,     1] loss: 1.9459338188171387\n",
      "[218,     1] loss: 1.920654058456421\n",
      "[219,     1] loss: 1.8953777551651\n",
      "[220,     1] loss: 1.8699889183044434\n",
      "[221,     1] loss: 1.8454126119613647\n",
      "[222,     1] loss: 1.8206627368927002\n",
      "[223,     1] loss: 1.7958927154541016\n",
      "[224,     1] loss: 1.7712290287017822\n",
      "[225,     1] loss: 1.7469513416290283\n",
      "[226,     1] loss: 1.7229371070861816\n",
      "[227,     1] loss: 1.6991167068481445\n",
      "[228,     1] loss: 1.67537260055542\n",
      "[229,     1] loss: 1.6515029668807983\n",
      "[230,     1] loss: 1.6277512311935425\n",
      "[231,     1] loss: 1.6041758060455322\n",
      "[232,     1] loss: 1.5808906555175781\n",
      "[233,     1] loss: 1.557892084121704\n",
      "[234,     1] loss: 1.5349197387695312\n",
      "[235,     1] loss: 1.5121058225631714\n",
      "[236,     1] loss: 1.4895273447036743\n",
      "[237,     1] loss: 1.4671756029129028\n",
      "[238,     1] loss: 1.4449317455291748\n",
      "[239,     1] loss: 1.4230000972747803\n",
      "[240,     1] loss: 1.400828242301941\n",
      "[241,     1] loss: 1.378931999206543\n",
      "[242,     1] loss: 1.3573018312454224\n",
      "[243,     1] loss: 1.3357691764831543\n",
      "[244,     1] loss: 1.3144251108169556\n",
      "[245,     1] loss: 1.2933177947998047\n",
      "[246,     1] loss: 1.2724435329437256\n",
      "[247,     1] loss: 1.2515259981155396\n",
      "[248,     1] loss: 1.2310471534729004\n",
      "[249,     1] loss: 1.2106431722640991\n",
      "[250,     1] loss: 1.1904574632644653\n",
      "[251,     1] loss: 1.1701380014419556\n",
      "[252,     1] loss: 1.1497085094451904\n",
      "[253,     1] loss: 1.1300556659698486\n",
      "[254,     1] loss: 1.1104034185409546\n",
      "[255,     1] loss: 1.0907959938049316\n",
      "[256,     1] loss: 1.071823239326477\n",
      "[257,     1] loss: 1.0526150465011597\n",
      "[258,     1] loss: 1.033926248550415\n",
      "[259,     1] loss: 1.0158573389053345\n",
      "[260,     1] loss: 0.9972629547119141\n",
      "[261,     1] loss: 0.9790244698524475\n",
      "[262,     1] loss: 0.960429310798645\n",
      "[263,     1] loss: 0.9419697523117065\n",
      "[264,     1] loss: 0.9231795072555542\n",
      "[265,     1] loss: 0.9050552845001221\n",
      "[266,     1] loss: 0.8877012729644775\n",
      "[267,     1] loss: 0.8718611001968384\n",
      "[268,     1] loss: 0.8557285666465759\n",
      "[269,     1] loss: 0.8402460217475891\n",
      "[270,     1] loss: 0.8250606656074524\n",
      "[271,     1] loss: 0.8102715015411377\n",
      "[272,     1] loss: 0.7956215739250183\n",
      "[273,     1] loss: 0.7813894748687744\n",
      "[274,     1] loss: 0.7672987580299377\n",
      "[275,     1] loss: 0.753375232219696\n",
      "[276,     1] loss: 0.7395233511924744\n",
      "[277,     1] loss: 0.7264897227287292\n",
      "[278,     1] loss: 0.7133254408836365\n",
      "[279,     1] loss: 0.7002732753753662\n",
      "[280,     1] loss: 0.6877735257148743\n",
      "[281,     1] loss: 0.6757273077964783\n",
      "[282,     1] loss: 0.6643348932266235\n",
      "[283,     1] loss: 0.6525906324386597\n",
      "[284,     1] loss: 0.6416407227516174\n",
      "[285,     1] loss: 0.6300957202911377\n",
      "[286,     1] loss: 0.6188061237335205\n",
      "[287,     1] loss: 0.6081013083457947\n",
      "[288,     1] loss: 0.5975497961044312\n",
      "[289,     1] loss: 0.5876641869544983\n",
      "[290,     1] loss: 0.5776828527450562\n",
      "[291,     1] loss: 0.5677944421768188\n",
      "[292,     1] loss: 0.5584141612052917\n",
      "[293,     1] loss: 0.5495390295982361\n",
      "[294,     1] loss: 0.5408004522323608\n",
      "[295,     1] loss: 0.5322511792182922\n",
      "[296,     1] loss: 0.5241154432296753\n",
      "[297,     1] loss: 0.5162370800971985\n",
      "[298,     1] loss: 0.5083417296409607\n",
      "[299,     1] loss: 0.5006040334701538\n",
      "[300,     1] loss: 0.4932066798210144\n",
      "[301,     1] loss: 0.48605209589004517\n",
      "[302,     1] loss: 0.4790601134300232\n",
      "[303,     1] loss: 0.4722107946872711\n",
      "[304,     1] loss: 0.46558111906051636\n",
      "[305,     1] loss: 0.45896387100219727\n",
      "[306,     1] loss: 0.45243799686431885\n",
      "[307,     1] loss: 0.4459168612957001\n",
      "[308,     1] loss: 0.4397728145122528\n",
      "[309,     1] loss: 0.4336893856525421\n",
      "[310,     1] loss: 0.4278552234172821\n",
      "[311,     1] loss: 0.42240622639656067\n",
      "[312,     1] loss: 0.41662266850471497\n",
      "[313,     1] loss: 0.411070853471756\n",
      "[314,     1] loss: 0.4056398570537567\n",
      "[315,     1] loss: 0.40023306012153625\n",
      "[316,     1] loss: 0.3949366807937622\n",
      "[317,     1] loss: 0.38980621099472046\n",
      "[318,     1] loss: 0.3847263753414154\n",
      "[319,     1] loss: 0.3796823024749756\n",
      "[320,     1] loss: 0.3747764229774475\n",
      "[321,     1] loss: 0.36978936195373535\n",
      "[322,     1] loss: 0.3649051785469055\n",
      "[323,     1] loss: 0.3601853847503662\n",
      "[324,     1] loss: 0.3555546700954437\n",
      "[325,     1] loss: 0.3510532081127167\n",
      "[326,     1] loss: 0.34678804874420166\n",
      "[327,     1] loss: 0.3425433039665222\n",
      "[328,     1] loss: 0.33823150396347046\n",
      "[329,     1] loss: 0.33394119143486023\n",
      "[330,     1] loss: 0.32982873916625977\n",
      "[331,     1] loss: 0.32575416564941406\n",
      "[332,     1] loss: 0.32163798809051514\n",
      "[333,     1] loss: 0.3175610303878784\n",
      "[334,     1] loss: 0.3135523200035095\n",
      "[335,     1] loss: 0.30965977907180786\n",
      "[336,     1] loss: 0.30581218004226685\n",
      "[337,     1] loss: 0.30200862884521484\n",
      "[338,     1] loss: 0.2981325685977936\n",
      "[339,     1] loss: 0.29427212476730347\n",
      "[340,     1] loss: 0.2904322147369385\n",
      "[341,     1] loss: 0.28703707456588745\n",
      "[342,     1] loss: 0.2836175262928009\n",
      "[343,     1] loss: 0.2803402841091156\n",
      "[344,     1] loss: 0.27709734439849854\n",
      "[345,     1] loss: 0.27387306094169617\n",
      "[346,     1] loss: 0.2707054316997528\n",
      "[347,     1] loss: 0.267397940158844\n",
      "[348,     1] loss: 0.26426416635513306\n",
      "[349,     1] loss: 0.26115700602531433\n",
      "[350,     1] loss: 0.2580735981464386\n",
      "[351,     1] loss: 0.2551799714565277\n",
      "[352,     1] loss: 0.25221142172813416\n",
      "[353,     1] loss: 0.24927186965942383\n",
      "[354,     1] loss: 0.2462892234325409\n",
      "[355,     1] loss: 0.24327991902828217\n",
      "[356,     1] loss: 0.24047471582889557\n",
      "[357,     1] loss: 0.23776620626449585\n",
      "[358,     1] loss: 0.23497524857521057\n",
      "[359,     1] loss: 0.2321729063987732\n",
      "[360,     1] loss: 0.2294600009918213\n",
      "[361,     1] loss: 0.22679153084754944\n",
      "[362,     1] loss: 0.22408851981163025\n",
      "[363,     1] loss: 0.22144390642642975\n",
      "[364,     1] loss: 0.21881185472011566\n",
      "[365,     1] loss: 0.21625857055187225\n",
      "[366,     1] loss: 0.2137293815612793\n",
      "[367,     1] loss: 0.21126577258110046\n",
      "[368,     1] loss: 0.2088378220796585\n",
      "[369,     1] loss: 0.2063474953174591\n",
      "[370,     1] loss: 0.2039329707622528\n",
      "[371,     1] loss: 0.2014981210231781\n",
      "[372,     1] loss: 0.19911225140094757\n",
      "[373,     1] loss: 0.19680161774158478\n",
      "[374,     1] loss: 0.19454200565814972\n",
      "[375,     1] loss: 0.1922910064458847\n",
      "[376,     1] loss: 0.19007718563079834\n",
      "[377,     1] loss: 0.18788538873195648\n",
      "[378,     1] loss: 0.18575257062911987\n",
      "[379,     1] loss: 0.1836467683315277\n",
      "[380,     1] loss: 0.18158429861068726\n",
      "[381,     1] loss: 0.17952871322631836\n",
      "[382,     1] loss: 0.177573561668396\n",
      "[383,     1] loss: 0.1755734384059906\n",
      "[384,     1] loss: 0.17359456419944763\n",
      "[385,     1] loss: 0.17170602083206177\n",
      "[386,     1] loss: 0.16980834305286407\n",
      "[387,     1] loss: 0.16794627904891968\n",
      "[388,     1] loss: 0.1660599410533905\n",
      "[389,     1] loss: 0.1642393171787262\n",
      "[390,     1] loss: 0.16240371763706207\n",
      "[391,     1] loss: 0.16060812771320343\n",
      "[392,     1] loss: 0.15876638889312744\n",
      "[393,     1] loss: 0.156988725066185\n",
      "[394,     1] loss: 0.15524476766586304\n",
      "[395,     1] loss: 0.15349961817264557\n",
      "[396,     1] loss: 0.15177324414253235\n",
      "[397,     1] loss: 0.14999471604824066\n",
      "[398,     1] loss: 0.1482977271080017\n",
      "[399,     1] loss: 0.14662784337997437\n",
      "[400,     1] loss: 0.14499986171722412\n",
      "[401,     1] loss: 0.14331425726413727\n",
      "[402,     1] loss: 0.141691654920578\n",
      "[403,     1] loss: 0.14009512960910797\n",
      "[404,     1] loss: 0.13849511742591858\n",
      "[405,     1] loss: 0.13688670098781586\n",
      "[406,     1] loss: 0.13529929518699646\n",
      "[407,     1] loss: 0.13378304243087769\n",
      "[408,     1] loss: 0.13223452866077423\n",
      "[409,     1] loss: 0.1307142823934555\n",
      "[410,     1] loss: 0.12922346591949463\n",
      "[411,     1] loss: 0.12770859897136688\n",
      "[412,     1] loss: 0.12630769610404968\n",
      "[413,     1] loss: 0.12491833418607712\n",
      "[414,     1] loss: 0.1234869509935379\n",
      "[415,     1] loss: 0.12210319191217422\n",
      "[416,     1] loss: 0.12072833627462387\n",
      "[417,     1] loss: 0.1193632185459137\n",
      "[418,     1] loss: 0.11797799915075302\n",
      "[419,     1] loss: 0.11660350859165192\n",
      "[420,     1] loss: 0.11525852978229523\n",
      "[421,     1] loss: 0.11392851173877716\n",
      "[422,     1] loss: 0.11262018233537674\n",
      "[423,     1] loss: 0.11129958927631378\n",
      "[424,     1] loss: 0.10999264568090439\n",
      "[425,     1] loss: 0.10868290066719055\n",
      "[426,     1] loss: 0.107393279671669\n",
      "[427,     1] loss: 0.10612612962722778\n",
      "[428,     1] loss: 0.10486156493425369\n",
      "[429,     1] loss: 0.10361136496067047\n",
      "[430,     1] loss: 0.10235850512981415\n",
      "[431,     1] loss: 0.10112771391868591\n",
      "[432,     1] loss: 0.09997313469648361\n",
      "[433,     1] loss: 0.09877040237188339\n",
      "[434,     1] loss: 0.09764187783002853\n",
      "[435,     1] loss: 0.09652641415596008\n",
      "[436,     1] loss: 0.09543336927890778\n",
      "[437,     1] loss: 0.09439804404973984\n",
      "[438,     1] loss: 0.09338150918483734\n",
      "[439,     1] loss: 0.09236253798007965\n",
      "[440,     1] loss: 0.0913703441619873\n",
      "[441,     1] loss: 0.0903671607375145\n",
      "[442,     1] loss: 0.08938094228506088\n",
      "[443,     1] loss: 0.08841098099946976\n",
      "[444,     1] loss: 0.08744145184755325\n",
      "[445,     1] loss: 0.08651240915060043\n",
      "[446,     1] loss: 0.08559175580739975\n",
      "[447,     1] loss: 0.08469085395336151\n",
      "[448,     1] loss: 0.08379662781953812\n",
      "[449,     1] loss: 0.08289944380521774\n",
      "[450,     1] loss: 0.0820295512676239\n",
      "[451,     1] loss: 0.08114796876907349\n",
      "[452,     1] loss: 0.08029945194721222\n",
      "[453,     1] loss: 0.07947172224521637\n",
      "[454,     1] loss: 0.07867903262376785\n",
      "[455,     1] loss: 0.07789021730422974\n",
      "[456,     1] loss: 0.0771014541387558\n",
      "[457,     1] loss: 0.07632424682378769\n",
      "[458,     1] loss: 0.07557502388954163\n",
      "[459,     1] loss: 0.07484129071235657\n",
      "[460,     1] loss: 0.07410694658756256\n",
      "[461,     1] loss: 0.07337501645088196\n",
      "[462,     1] loss: 0.07264846563339233\n",
      "[463,     1] loss: 0.07192718237638474\n",
      "[464,     1] loss: 0.07121702283620834\n",
      "[465,     1] loss: 0.07053664326667786\n",
      "[466,     1] loss: 0.0698564201593399\n",
      "[467,     1] loss: 0.06918974220752716\n",
      "[468,     1] loss: 0.06853199005126953\n",
      "[469,     1] loss: 0.06788574904203415\n",
      "[470,     1] loss: 0.06725205481052399\n",
      "[471,     1] loss: 0.06663305312395096\n",
      "[472,     1] loss: 0.06601577997207642\n",
      "[473,     1] loss: 0.06541027128696442\n",
      "[474,     1] loss: 0.06481003761291504\n",
      "[475,     1] loss: 0.06421148031949997\n",
      "[476,     1] loss: 0.06361944228410721\n",
      "[477,     1] loss: 0.06304105371236801\n",
      "[478,     1] loss: 0.06246946007013321\n",
      "[479,     1] loss: 0.06188822537660599\n",
      "[480,     1] loss: 0.06133527681231499\n",
      "[481,     1] loss: 0.06079404056072235\n",
      "[482,     1] loss: 0.06026527285575867\n",
      "[483,     1] loss: 0.059744320809841156\n",
      "[484,     1] loss: 0.059241607785224915\n",
      "[485,     1] loss: 0.05873676761984825\n",
      "[486,     1] loss: 0.058239445090293884\n",
      "[487,     1] loss: 0.057745885103940964\n",
      "[488,     1] loss: 0.057275526225566864\n",
      "[489,     1] loss: 0.05678913742303848\n",
      "[490,     1] loss: 0.05631870776414871\n",
      "[491,     1] loss: 0.0558595284819603\n",
      "[492,     1] loss: 0.055398061871528625\n",
      "[493,     1] loss: 0.05494826287031174\n",
      "[494,     1] loss: 0.05451023951172829\n",
      "[495,     1] loss: 0.054058149456977844\n",
      "[496,     1] loss: 0.05362946540117264\n",
      "[497,     1] loss: 0.053198039531707764\n",
      "[498,     1] loss: 0.05278061330318451\n",
      "[499,     1] loss: 0.05235838145017624\n",
      "[500,     1] loss: 0.05194634199142456\n",
      "[501,     1] loss: 0.051541876047849655\n",
      "[502,     1] loss: 0.05113609507679939\n",
      "[503,     1] loss: 0.05073140934109688\n",
      "[504,     1] loss: 0.05032475292682648\n",
      "[505,     1] loss: 0.04992646723985672\n",
      "[506,     1] loss: 0.04954516887664795\n",
      "[507,     1] loss: 0.04915644973516464\n",
      "[508,     1] loss: 0.04877164959907532\n",
      "[509,     1] loss: 0.04839835315942764\n",
      "[510,     1] loss: 0.04801609367132187\n",
      "[511,     1] loss: 0.047654762864112854\n",
      "[512,     1] loss: 0.04729115962982178\n",
      "[513,     1] loss: 0.0469268336892128\n",
      "[514,     1] loss: 0.046564582735300064\n",
      "[515,     1] loss: 0.04619535058736801\n",
      "[516,     1] loss: 0.045838937163352966\n",
      "[517,     1] loss: 0.04548181593418121\n",
      "[518,     1] loss: 0.04513290524482727\n",
      "[519,     1] loss: 0.044782496988773346\n",
      "[520,     1] loss: 0.04443642497062683\n",
      "[521,     1] loss: 0.044098127633333206\n",
      "[522,     1] loss: 0.04375304654240608\n",
      "[523,     1] loss: 0.04340469464659691\n",
      "[524,     1] loss: 0.043057870119810104\n",
      "[525,     1] loss: 0.042715609073638916\n",
      "[526,     1] loss: 0.04238181561231613\n",
      "[527,     1] loss: 0.04203762859106064\n",
      "[528,     1] loss: 0.04171309620141983\n",
      "[529,     1] loss: 0.041394077241420746\n",
      "[530,     1] loss: 0.041080765426158905\n",
      "[531,     1] loss: 0.04077811539173126\n",
      "[532,     1] loss: 0.040476243942976\n",
      "[533,     1] loss: 0.040179379284381866\n",
      "[534,     1] loss: 0.03988954797387123\n",
      "[535,     1] loss: 0.03960026800632477\n",
      "[536,     1] loss: 0.0393182598054409\n",
      "[537,     1] loss: 0.03903547674417496\n",
      "[538,     1] loss: 0.038764312863349915\n",
      "[539,     1] loss: 0.03848572075366974\n",
      "[540,     1] loss: 0.03821440041065216\n",
      "[541,     1] loss: 0.03795495629310608\n",
      "[542,     1] loss: 0.037684302777051926\n",
      "[543,     1] loss: 0.03743359446525574\n",
      "[544,     1] loss: 0.03717478737235069\n",
      "[545,     1] loss: 0.03693430870771408\n",
      "[546,     1] loss: 0.036678336560726166\n",
      "[547,     1] loss: 0.0364265963435173\n",
      "[548,     1] loss: 0.03617751598358154\n",
      "[549,     1] loss: 0.03593146800994873\n",
      "[550,     1] loss: 0.035701848566532135\n",
      "[551,     1] loss: 0.03547279164195061\n",
      "[552,     1] loss: 0.0352475680410862\n",
      "[553,     1] loss: 0.0350177101790905\n",
      "[554,     1] loss: 0.03479216992855072\n",
      "[555,     1] loss: 0.034572526812553406\n",
      "[556,     1] loss: 0.034349225461483\n",
      "[557,     1] loss: 0.034132134169340134\n",
      "[558,     1] loss: 0.03391595184803009\n",
      "[559,     1] loss: 0.03371190279722214\n",
      "[560,     1] loss: 0.033504877239465714\n",
      "[561,     1] loss: 0.03329162299633026\n",
      "[562,     1] loss: 0.033086568117141724\n",
      "[563,     1] loss: 0.03287234902381897\n",
      "[564,     1] loss: 0.03266590088605881\n",
      "[565,     1] loss: 0.03246013820171356\n",
      "[566,     1] loss: 0.03225856274366379\n",
      "[567,     1] loss: 0.032059185206890106\n",
      "[568,     1] loss: 0.03185877203941345\n",
      "[569,     1] loss: 0.0316622257232666\n",
      "[570,     1] loss: 0.03146994113922119\n",
      "[571,     1] loss: 0.031280480325222015\n",
      "[572,     1] loss: 0.031093105673789978\n",
      "[573,     1] loss: 0.0309138260781765\n",
      "[574,     1] loss: 0.030732760205864906\n",
      "[575,     1] loss: 0.030552230775356293\n",
      "[576,     1] loss: 0.03037252277135849\n",
      "[577,     1] loss: 0.030198020860552788\n",
      "[578,     1] loss: 0.030028637498617172\n",
      "[579,     1] loss: 0.029858067631721497\n",
      "[580,     1] loss: 0.029693959280848503\n",
      "[581,     1] loss: 0.029529325664043427\n",
      "[582,     1] loss: 0.029363645240664482\n",
      "[583,     1] loss: 0.02920161932706833\n",
      "[584,     1] loss: 0.029042480513453484\n",
      "[585,     1] loss: 0.02888290397822857\n",
      "[586,     1] loss: 0.028729191049933434\n",
      "[587,     1] loss: 0.02858472242951393\n",
      "[588,     1] loss: 0.028437621891498566\n",
      "[589,     1] loss: 0.028291931375861168\n",
      "[590,     1] loss: 0.02814909815788269\n",
      "[591,     1] loss: 0.028008751571178436\n",
      "[592,     1] loss: 0.027871690690517426\n",
      "[593,     1] loss: 0.027738843113183975\n",
      "[594,     1] loss: 0.027602164074778557\n",
      "[595,     1] loss: 0.027466969564557076\n",
      "[596,     1] loss: 0.027334675192832947\n",
      "[597,     1] loss: 0.027202891185879707\n",
      "[598,     1] loss: 0.02706962451338768\n",
      "[599,     1] loss: 0.02694222517311573\n",
      "[600,     1] loss: 0.026817791163921356\n",
      "[601,     1] loss: 0.02669067122042179\n",
      "[602,     1] loss: 0.026564795523881912\n",
      "[603,     1] loss: 0.026440517976880074\n",
      "[604,     1] loss: 0.02631692960858345\n",
      "[605,     1] loss: 0.02619485929608345\n",
      "[606,     1] loss: 0.026075880974531174\n",
      "[607,     1] loss: 0.025959432125091553\n",
      "[608,     1] loss: 0.02584371529519558\n",
      "[609,     1] loss: 0.025728531181812286\n",
      "[610,     1] loss: 0.025613639503717422\n",
      "[611,     1] loss: 0.02549831196665764\n",
      "[612,     1] loss: 0.025385301560163498\n",
      "[613,     1] loss: 0.02527765743434429\n",
      "[614,     1] loss: 0.025169167667627335\n",
      "[615,     1] loss: 0.025057032704353333\n",
      "[616,     1] loss: 0.0249498188495636\n",
      "[617,     1] loss: 0.024845102801918983\n",
      "[618,     1] loss: 0.024738861247897148\n",
      "[619,     1] loss: 0.024632973596453667\n",
      "[620,     1] loss: 0.02452917769551277\n",
      "[621,     1] loss: 0.024425633251667023\n",
      "[622,     1] loss: 0.02432338148355484\n",
      "[623,     1] loss: 0.024223554879426956\n",
      "[624,     1] loss: 0.024124782532453537\n",
      "[625,     1] loss: 0.024024754762649536\n",
      "[626,     1] loss: 0.023926956579089165\n",
      "[627,     1] loss: 0.023829925805330276\n",
      "[628,     1] loss: 0.0237331073731184\n",
      "[629,     1] loss: 0.023637985810637474\n",
      "[630,     1] loss: 0.02354448288679123\n",
      "[631,     1] loss: 0.023451313376426697\n",
      "[632,     1] loss: 0.023359015583992004\n",
      "[633,     1] loss: 0.023268025368452072\n",
      "[634,     1] loss: 0.02317611500620842\n",
      "[635,     1] loss: 0.023086175322532654\n",
      "[636,     1] loss: 0.022998161613941193\n",
      "[637,     1] loss: 0.022908471524715424\n",
      "[638,     1] loss: 0.02282007783651352\n",
      "[639,     1] loss: 0.022733336314558983\n",
      "[640,     1] loss: 0.022647444158792496\n",
      "[641,     1] loss: 0.022561190649867058\n",
      "[642,     1] loss: 0.022476889193058014\n",
      "[643,     1] loss: 0.022392231971025467\n",
      "[644,     1] loss: 0.02231069654226303\n",
      "[645,     1] loss: 0.02222883142530918\n",
      "[646,     1] loss: 0.022147255018353462\n",
      "[647,     1] loss: 0.022067289799451828\n",
      "[648,     1] loss: 0.021988702937960625\n",
      "[649,     1] loss: 0.02191120758652687\n",
      "[650,     1] loss: 0.021833833307027817\n",
      "[651,     1] loss: 0.021757062524557114\n",
      "[652,     1] loss: 0.021680939942598343\n",
      "[653,     1] loss: 0.021606747061014175\n",
      "[654,     1] loss: 0.02153272181749344\n",
      "[655,     1] loss: 0.021459903568029404\n",
      "[656,     1] loss: 0.021387111395597458\n",
      "[657,     1] loss: 0.02131144516170025\n",
      "[658,     1] loss: 0.021241098642349243\n",
      "[659,     1] loss: 0.021171942353248596\n",
      "[660,     1] loss: 0.02110549435019493\n",
      "[661,     1] loss: 0.021038228645920753\n",
      "[662,     1] loss: 0.020969770848751068\n",
      "[663,     1] loss: 0.020901262760162354\n",
      "[664,     1] loss: 0.02082805708050728\n",
      "[665,     1] loss: 0.020756032317876816\n",
      "[666,     1] loss: 0.020685046911239624\n",
      "[667,     1] loss: 0.020617995411157608\n",
      "[668,     1] loss: 0.02055274322628975\n",
      "[669,     1] loss: 0.020488925278186798\n",
      "[670,     1] loss: 0.02042417973279953\n",
      "[671,     1] loss: 0.02035849168896675\n",
      "[672,     1] loss: 0.02029365301132202\n",
      "[673,     1] loss: 0.020230311900377274\n",
      "[674,     1] loss: 0.02016725391149521\n",
      "[675,     1] loss: 0.020104985684156418\n",
      "[676,     1] loss: 0.020041733980178833\n",
      "[677,     1] loss: 0.019978655502200127\n",
      "[678,     1] loss: 0.019916456192731857\n",
      "[679,     1] loss: 0.019856370985507965\n",
      "[680,     1] loss: 0.019796818494796753\n",
      "[681,     1] loss: 0.01973874494433403\n",
      "[682,     1] loss: 0.01967976614832878\n",
      "[683,     1] loss: 0.019620880484580994\n",
      "[684,     1] loss: 0.019562380388379097\n",
      "[685,     1] loss: 0.01950383186340332\n",
      "[686,     1] loss: 0.01944495551288128\n",
      "[687,     1] loss: 0.01938486471772194\n",
      "[688,     1] loss: 0.019325435161590576\n",
      "[689,     1] loss: 0.01926712691783905\n",
      "[690,     1] loss: 0.019212570041418076\n",
      "[691,     1] loss: 0.019155919551849365\n",
      "[692,     1] loss: 0.019099898636341095\n",
      "[693,     1] loss: 0.019041765481233597\n",
      "[694,     1] loss: 0.018985718488693237\n",
      "[695,     1] loss: 0.018930301070213318\n",
      "[696,     1] loss: 0.01887480914592743\n",
      "[697,     1] loss: 0.01882293075323105\n",
      "[698,     1] loss: 0.018767986446619034\n",
      "[699,     1] loss: 0.01871398091316223\n",
      "[700,     1] loss: 0.018661417067050934\n",
      "[701,     1] loss: 0.01860787346959114\n",
      "[702,     1] loss: 0.018556110560894012\n",
      "[703,     1] loss: 0.01850207895040512\n",
      "[704,     1] loss: 0.01845068484544754\n",
      "[705,     1] loss: 0.01839904859662056\n",
      "[706,     1] loss: 0.018347127363085747\n",
      "[707,     1] loss: 0.018296170979738235\n",
      "[708,     1] loss: 0.01824662834405899\n",
      "[709,     1] loss: 0.018196258693933487\n",
      "[710,     1] loss: 0.018147150054574013\n",
      "[711,     1] loss: 0.018097488209605217\n",
      "[712,     1] loss: 0.018049966543912888\n",
      "[713,     1] loss: 0.018002234399318695\n",
      "[714,     1] loss: 0.01795392669737339\n",
      "[715,     1] loss: 0.017907356843352318\n",
      "[716,     1] loss: 0.01786027103662491\n",
      "[717,     1] loss: 0.017813434824347496\n",
      "[718,     1] loss: 0.01776599884033203\n",
      "[719,     1] loss: 0.017721697688102722\n",
      "[720,     1] loss: 0.017674963921308517\n",
      "[721,     1] loss: 0.017628628760576248\n",
      "[722,     1] loss: 0.017584823071956635\n",
      "[723,     1] loss: 0.017539698630571365\n",
      "[724,     1] loss: 0.017495695501565933\n",
      "[725,     1] loss: 0.017452536150813103\n",
      "[726,     1] loss: 0.01740913838148117\n",
      "[727,     1] loss: 0.01736661046743393\n",
      "[728,     1] loss: 0.017323996871709824\n",
      "[729,     1] loss: 0.017280688509345055\n",
      "[730,     1] loss: 0.017238754779100418\n",
      "[731,     1] loss: 0.01719694584608078\n",
      "[732,     1] loss: 0.017156191170215607\n",
      "[733,     1] loss: 0.017114758491516113\n",
      "[734,     1] loss: 0.01707397773861885\n",
      "[735,     1] loss: 0.01703334040939808\n",
      "[736,     1] loss: 0.016992656514048576\n",
      "[737,     1] loss: 0.01695200428366661\n",
      "[738,     1] loss: 0.01691213995218277\n",
      "[739,     1] loss: 0.01687207818031311\n",
      "[740,     1] loss: 0.016833214089274406\n",
      "[741,     1] loss: 0.0167921744287014\n",
      "[742,     1] loss: 0.01674765907227993\n",
      "[743,     1] loss: 0.01670450158417225\n",
      "[744,     1] loss: 0.01666378788650036\n",
      "[745,     1] loss: 0.016626717522740364\n",
      "[746,     1] loss: 0.01658741757273674\n",
      "[747,     1] loss: 0.0165458545088768\n",
      "[748,     1] loss: 0.01650477945804596\n",
      "[749,     1] loss: 0.016465386375784874\n",
      "[750,     1] loss: 0.016428038477897644\n",
      "[751,     1] loss: 0.01638825610280037\n",
      "[752,     1] loss: 0.01634526625275612\n",
      "[753,     1] loss: 0.016302628442645073\n",
      "[754,     1] loss: 0.016262540593743324\n",
      "[755,     1] loss: 0.01622200384736061\n",
      "[756,     1] loss: 0.01618129014968872\n",
      "[757,     1] loss: 0.016140371561050415\n",
      "[758,     1] loss: 0.01610124669969082\n",
      "[759,     1] loss: 0.01606365479528904\n",
      "[760,     1] loss: 0.016025247052311897\n",
      "[761,     1] loss: 0.015986932441592216\n",
      "[762,     1] loss: 0.015948127955198288\n",
      "[763,     1] loss: 0.01591106504201889\n",
      "[764,     1] loss: 0.01587364263832569\n",
      "[765,     1] loss: 0.015836436301469803\n",
      "[766,     1] loss: 0.01579991728067398\n",
      "[767,     1] loss: 0.015763811767101288\n",
      "[768,     1] loss: 0.015728730708360672\n",
      "[769,     1] loss: 0.015693271532654762\n",
      "[770,     1] loss: 0.01565757766366005\n",
      "[771,     1] loss: 0.015622108243405819\n",
      "[772,     1] loss: 0.01558697409927845\n",
      "[773,     1] loss: 0.015553184784948826\n",
      "[774,     1] loss: 0.015518806874752045\n",
      "[775,     1] loss: 0.015484984964132309\n",
      "[776,     1] loss: 0.015452074818313122\n",
      "[777,     1] loss: 0.015420210547745228\n",
      "[778,     1] loss: 0.015389197506010532\n",
      "[779,     1] loss: 0.015357684344053268\n",
      "[780,     1] loss: 0.015327513217926025\n",
      "[781,     1] loss: 0.015296461060643196\n",
      "[782,     1] loss: 0.015263736248016357\n",
      "[783,     1] loss: 0.015229316428303719\n",
      "[784,     1] loss: 0.015194665640592575\n",
      "[785,     1] loss: 0.015160340815782547\n",
      "[786,     1] loss: 0.015127405524253845\n",
      "[787,     1] loss: 0.01509513147175312\n",
      "[788,     1] loss: 0.015063370577991009\n",
      "[789,     1] loss: 0.015031881630420685\n",
      "[790,     1] loss: 0.015000024810433388\n",
      "[791,     1] loss: 0.014968698844313622\n",
      "[792,     1] loss: 0.014937961474061012\n",
      "[793,     1] loss: 0.014907174743711948\n",
      "[794,     1] loss: 0.014875905588269234\n",
      "[795,     1] loss: 0.014844972640275955\n",
      "[796,     1] loss: 0.014814244583249092\n",
      "[797,     1] loss: 0.014783699065446854\n",
      "[798,     1] loss: 0.014753513969480991\n",
      "[799,     1] loss: 0.014723140746355057\n",
      "[800,     1] loss: 0.01469360664486885\n",
      "[801,     1] loss: 0.014663781970739365\n",
      "[802,     1] loss: 0.014633310958743095\n",
      "[803,     1] loss: 0.01460326835513115\n",
      "[804,     1] loss: 0.01457425206899643\n",
      "[805,     1] loss: 0.014545578509569168\n",
      "[806,     1] loss: 0.01451759785413742\n",
      "[807,     1] loss: 0.01448932196944952\n",
      "[808,     1] loss: 0.014460327103734016\n",
      "[809,     1] loss: 0.014431405812501907\n",
      "[810,     1] loss: 0.014402536675333977\n",
      "[811,     1] loss: 0.014373679645359516\n",
      "[812,     1] loss: 0.014345473609864712\n",
      "[813,     1] loss: 0.014317423105239868\n",
      "[814,     1] loss: 0.014290869235992432\n",
      "[815,     1] loss: 0.014263372868299484\n",
      "[816,     1] loss: 0.014235913753509521\n",
      "[817,     1] loss: 0.014208601787686348\n",
      "[818,     1] loss: 0.014181509613990784\n",
      "[819,     1] loss: 0.014154374599456787\n",
      "[820,     1] loss: 0.014127443544566631\n",
      "[821,     1] loss: 0.014100352302193642\n",
      "[822,     1] loss: 0.014073695987462997\n",
      "[823,     1] loss: 0.014046878553926945\n",
      "[824,     1] loss: 0.014020655304193497\n",
      "[825,     1] loss: 0.013992063701152802\n",
      "[826,     1] loss: 0.013962763361632824\n",
      "[827,     1] loss: 0.01393327210098505\n",
      "[828,     1] loss: 0.0139040257781744\n",
      "[829,     1] loss: 0.013874072581529617\n",
      "[830,     1] loss: 0.013843739405274391\n",
      "[831,     1] loss: 0.013813283294439316\n",
      "[832,     1] loss: 0.013782819733023643\n",
      "[833,     1] loss: 0.01375206932425499\n",
      "[834,     1] loss: 0.01372169516980648\n",
      "[835,     1] loss: 0.013691438362002373\n",
      "[836,     1] loss: 0.013660939410328865\n",
      "[837,     1] loss: 0.013630775734782219\n",
      "[838,     1] loss: 0.013600440695881844\n",
      "[839,     1] loss: 0.013570723123848438\n",
      "[840,     1] loss: 0.013541012071073055\n",
      "[841,     1] loss: 0.013511847704648972\n",
      "[842,     1] loss: 0.013481445610523224\n",
      "[843,     1] loss: 0.013451769948005676\n",
      "[844,     1] loss: 0.013421883806586266\n",
      "[845,     1] loss: 0.013392472639679909\n",
      "[846,     1] loss: 0.013363066129386425\n",
      "[847,     1] loss: 0.013334126211702824\n",
      "[848,     1] loss: 0.01330537348985672\n",
      "[849,     1] loss: 0.013276584446430206\n",
      "[850,     1] loss: 0.013248424977064133\n",
      "[851,     1] loss: 0.013220055028796196\n",
      "[852,     1] loss: 0.013192180544137955\n",
      "[853,     1] loss: 0.013164554722607136\n",
      "[854,     1] loss: 0.01313766185194254\n",
      "[855,     1] loss: 0.01311049796640873\n",
      "[856,     1] loss: 0.013084005564451218\n",
      "[857,     1] loss: 0.013058571144938469\n",
      "[858,     1] loss: 0.013034035451710224\n",
      "[859,     1] loss: 0.013011462055146694\n",
      "[860,     1] loss: 0.012990336865186691\n",
      "[861,     1] loss: 0.012970887124538422\n",
      "[862,     1] loss: 0.01295196171849966\n",
      "[863,     1] loss: 0.012929885648190975\n",
      "[864,     1] loss: 0.012902926653623581\n",
      "[865,     1] loss: 0.012871109880506992\n",
      "[866,     1] loss: 0.01283751055598259\n",
      "[867,     1] loss: 0.012806217186152935\n",
      "[868,     1] loss: 0.012778750620782375\n",
      "[869,     1] loss: 0.012754623778164387\n",
      "[870,     1] loss: 0.012732243165373802\n",
      "[871,     1] loss: 0.012710483744740486\n",
      "[872,     1] loss: 0.012687559239566326\n",
      "[873,     1] loss: 0.01266387663781643\n",
      "[874,     1] loss: 0.012640045955777168\n",
      "[875,     1] loss: 0.012616986408829689\n",
      "[876,     1] loss: 0.012595160864293575\n",
      "[877,     1] loss: 0.01257258839905262\n",
      "[878,     1] loss: 0.012549228966236115\n",
      "[879,     1] loss: 0.012524641118943691\n",
      "[880,     1] loss: 0.012500671669840813\n",
      "[881,     1] loss: 0.012477496638894081\n",
      "[882,     1] loss: 0.012455156072974205\n",
      "[883,     1] loss: 0.012433815747499466\n",
      "[884,     1] loss: 0.01241232082247734\n",
      "[885,     1] loss: 0.012390479445457458\n",
      "[886,     1] loss: 0.012367645278573036\n",
      "[887,     1] loss: 0.012344956398010254\n",
      "[888,     1] loss: 0.012322674505412579\n",
      "[889,     1] loss: 0.012300807051360607\n",
      "[890,     1] loss: 0.012279614806175232\n",
      "[891,     1] loss: 0.012258822098374367\n",
      "[892,     1] loss: 0.0122374864295125\n",
      "[893,     1] loss: 0.012215770781040192\n",
      "[894,     1] loss: 0.012194039300084114\n",
      "[895,     1] loss: 0.012172119691967964\n",
      "[896,     1] loss: 0.012150880880653858\n",
      "[897,     1] loss: 0.012130219489336014\n",
      "[898,     1] loss: 0.01210970338433981\n",
      "[899,     1] loss: 0.012089025229215622\n",
      "[900,     1] loss: 0.012067842297255993\n",
      "[901,     1] loss: 0.01204651314765215\n",
      "[902,     1] loss: 0.012025868520140648\n",
      "[903,     1] loss: 0.012005431577563286\n",
      "[904,     1] loss: 0.01198551058769226\n",
      "[905,     1] loss: 0.011965705081820488\n",
      "[906,     1] loss: 0.011945407837629318\n",
      "[907,     1] loss: 0.011924870312213898\n",
      "[908,     1] loss: 0.011904649436473846\n",
      "[909,     1] loss: 0.011884825304150581\n",
      "[910,     1] loss: 0.011865053325891495\n",
      "[911,     1] loss: 0.011845413595438004\n",
      "[912,     1] loss: 0.011825945228338242\n",
      "[913,     1] loss: 0.011806521564722061\n",
      "[914,     1] loss: 0.011787250638008118\n",
      "[915,     1] loss: 0.011767884716391563\n",
      "[916,     1] loss: 0.011748703196644783\n",
      "[917,     1] loss: 0.011729427613317966\n",
      "[918,     1] loss: 0.011710654944181442\n",
      "[919,     1] loss: 0.011691943742334843\n",
      "[920,     1] loss: 0.011672910302877426\n",
      "[921,     1] loss: 0.011654224246740341\n",
      "[922,     1] loss: 0.011635658331215382\n",
      "[923,     1] loss: 0.011617311276495457\n",
      "[924,     1] loss: 0.011598952114582062\n",
      "[925,     1] loss: 0.01158078107982874\n",
      "[926,     1] loss: 0.011562594212591648\n",
      "[927,     1] loss: 0.011544743552803993\n",
      "[928,     1] loss: 0.011526361107826233\n",
      "[929,     1] loss: 0.011508257128298283\n",
      "[930,     1] loss: 0.011490454897284508\n",
      "[931,     1] loss: 0.01147252693772316\n",
      "[932,     1] loss: 0.011454682797193527\n",
      "[933,     1] loss: 0.011436856351792812\n",
      "[934,     1] loss: 0.011419287882745266\n",
      "[935,     1] loss: 0.011401673778891563\n",
      "[936,     1] loss: 0.011384446173906326\n",
      "[937,     1] loss: 0.011366793885827065\n",
      "[938,     1] loss: 0.011349578388035297\n",
      "[939,     1] loss: 0.01133255660533905\n",
      "[940,     1] loss: 0.011315528303384781\n",
      "[941,     1] loss: 0.01129854191094637\n",
      "[942,     1] loss: 0.011281786486506462\n",
      "[943,     1] loss: 0.0112651027739048\n",
      "[944,     1] loss: 0.011248212307691574\n",
      "[945,     1] loss: 0.01123109646141529\n",
      "[946,     1] loss: 0.011213622987270355\n",
      "[947,     1] loss: 0.011195730417966843\n",
      "[948,     1] loss: 0.011178206652402878\n",
      "[949,     1] loss: 0.011160742491483688\n",
      "[950,     1] loss: 0.011144021525979042\n",
      "[951,     1] loss: 0.01112741231918335\n",
      "[952,     1] loss: 0.011111467145383358\n",
      "[953,     1] loss: 0.011094917543232441\n",
      "[954,     1] loss: 0.01107846386730671\n",
      "[955,     1] loss: 0.011061602272093296\n",
      "[956,     1] loss: 0.011044904589653015\n",
      "[957,     1] loss: 0.011028366163372993\n",
      "[958,     1] loss: 0.011011797934770584\n",
      "[959,     1] loss: 0.010995255783200264\n",
      "[960,     1] loss: 0.010978959500789642\n",
      "[961,     1] loss: 0.010962413623929024\n",
      "[962,     1] loss: 0.010946094058454037\n",
      "[963,     1] loss: 0.010929591953754425\n",
      "[964,     1] loss: 0.010913277976214886\n",
      "[965,     1] loss: 0.010897206142544746\n",
      "[966,     1] loss: 0.010881366208195686\n",
      "[967,     1] loss: 0.010865747928619385\n",
      "[968,     1] loss: 0.01085023581981659\n",
      "[969,     1] loss: 0.01083490252494812\n",
      "[970,     1] loss: 0.010819682851433754\n",
      "[971,     1] loss: 0.010804546996951103\n",
      "[972,     1] loss: 0.010790186002850533\n",
      "[973,     1] loss: 0.010775677859783173\n",
      "[974,     1] loss: 0.010760441422462463\n",
      "[975,     1] loss: 0.010745721869170666\n",
      "[976,     1] loss: 0.010730789043009281\n",
      "[977,     1] loss: 0.010715455748140812\n",
      "[978,     1] loss: 0.01069922186434269\n",
      "[979,     1] loss: 0.010681851767003536\n",
      "[980,     1] loss: 0.010663307271897793\n",
      "[981,     1] loss: 0.010644716210663319\n",
      "[982,     1] loss: 0.010626176372170448\n",
      "[983,     1] loss: 0.010607533156871796\n",
      "[984,     1] loss: 0.010589542798697948\n",
      "[985,     1] loss: 0.010572230443358421\n",
      "[986,     1] loss: 0.010555380024015903\n",
      "[987,     1] loss: 0.010539374314248562\n",
      "[988,     1] loss: 0.010523502714931965\n",
      "[989,     1] loss: 0.010508177801966667\n",
      "[990,     1] loss: 0.01049322821199894\n",
      "[991,     1] loss: 0.010477777570486069\n",
      "[992,     1] loss: 0.010461829602718353\n",
      "[993,     1] loss: 0.010445223189890385\n",
      "[994,     1] loss: 0.0104279275983572\n",
      "[995,     1] loss: 0.01041024923324585\n",
      "[996,     1] loss: 0.010392844676971436\n",
      "[997,     1] loss: 0.0103766405954957\n",
      "[998,     1] loss: 0.010361122898757458\n",
      "[999,     1] loss: 0.010346150025725365\n",
      "[1000,     1] loss: 0.010331102646887302\n",
      "[1001,     1] loss: 0.010315775871276855\n",
      "[1002,     1] loss: 0.010299904271960258\n",
      "[1003,     1] loss: 0.01028397772461176\n",
      "[1004,     1] loss: 0.010268427431583405\n",
      "[1005,     1] loss: 0.010253100655972958\n",
      "[1006,     1] loss: 0.010237786918878555\n",
      "[1007,     1] loss: 0.010222776792943478\n",
      "[1008,     1] loss: 0.010207682847976685\n",
      "[1009,     1] loss: 0.010192488320171833\n",
      "[1010,     1] loss: 0.010177073068916798\n",
      "[1011,     1] loss: 0.010161875747144222\n",
      "[1012,     1] loss: 0.01014679204672575\n",
      "[1013,     1] loss: 0.010132133960723877\n",
      "[1014,     1] loss: 0.010117494501173496\n",
      "[1015,     1] loss: 0.010102649219334126\n",
      "[1016,     1] loss: 0.010087798349559307\n",
      "[1017,     1] loss: 0.010073295794427395\n",
      "[1018,     1] loss: 0.010058335028588772\n",
      "[1019,     1] loss: 0.010043756105005741\n",
      "[1020,     1] loss: 0.010029022581875324\n",
      "[1021,     1] loss: 0.010014493018388748\n",
      "[1022,     1] loss: 0.01000004168599844\n",
      "[1023,     1] loss: 0.009985503740608692\n",
      "[1024,     1] loss: 0.009971309453248978\n",
      "[1025,     1] loss: 0.009957161732017994\n",
      "[1026,     1] loss: 0.009942926466464996\n",
      "[1027,     1] loss: 0.00992861669510603\n",
      "[1028,     1] loss: 0.009914442896842957\n",
      "[1029,     1] loss: 0.009900352917611599\n",
      "[1030,     1] loss: 0.009886320680379868\n",
      "[1031,     1] loss: 0.009872246533632278\n",
      "[1032,     1] loss: 0.009858272969722748\n",
      "[1033,     1] loss: 0.009844467043876648\n",
      "[1034,     1] loss: 0.009830605238676071\n",
      "[1035,     1] loss: 0.009817161597311497\n",
      "[1036,     1] loss: 0.009803145192563534\n",
      "[1037,     1] loss: 0.009789377450942993\n",
      "[1038,     1] loss: 0.009775918908417225\n",
      "[1039,     1] loss: 0.009762337431311607\n",
      "[1040,     1] loss: 0.009748758748173714\n",
      "[1041,     1] loss: 0.00973560567945242\n",
      "[1042,     1] loss: 0.00972259696573019\n",
      "[1043,     1] loss: 0.009709388948976994\n",
      "[1044,     1] loss: 0.009696495719254017\n",
      "[1045,     1] loss: 0.009683682583272457\n",
      "[1046,     1] loss: 0.009671572595834732\n",
      "[1047,     1] loss: 0.009659594856202602\n",
      "[1048,     1] loss: 0.009648064151406288\n",
      "[1049,     1] loss: 0.009637704119086266\n",
      "[1050,     1] loss: 0.00962875597178936\n",
      "[1051,     1] loss: 0.009620873257517815\n",
      "[1052,     1] loss: 0.00961464922875166\n",
      "[1053,     1] loss: 0.009609070606529713\n",
      "[1054,     1] loss: 0.009603166952729225\n",
      "[1055,     1] loss: 0.009593507274985313\n",
      "[1056,     1] loss: 0.009576791897416115\n",
      "[1057,     1] loss: 0.009553252719342709\n",
      "[1058,     1] loss: 0.009526553563773632\n",
      "[1059,     1] loss: 0.009504394605755806\n",
      "[1060,     1] loss: 0.009489729069173336\n",
      "[1061,     1] loss: 0.009480682201683521\n",
      "[1062,     1] loss: 0.009472548961639404\n",
      "[1063,     1] loss: 0.009461205452680588\n",
      "[1064,     1] loss: 0.009445455856621265\n",
      "[1065,     1] loss: 0.009428439661860466\n",
      "[1066,     1] loss: 0.009413090534508228\n",
      "[1067,     1] loss: 0.009399968199431896\n",
      "[1068,     1] loss: 0.009388433769345284\n",
      "[1069,     1] loss: 0.009377081878483295\n",
      "[1070,     1] loss: 0.009364204481244087\n",
      "[1071,     1] loss: 0.009350303560495377\n",
      "[1072,     1] loss: 0.009336515329778194\n",
      "[1073,     1] loss: 0.009323122911155224\n",
      "[1074,     1] loss: 0.009310216642916203\n",
      "[1075,     1] loss: 0.009298192337155342\n",
      "[1076,     1] loss: 0.009285902604460716\n",
      "[1077,     1] loss: 0.009273327887058258\n",
      "[1078,     1] loss: 0.009260278195142746\n",
      "[1079,     1] loss: 0.009247463196516037\n",
      "[1080,     1] loss: 0.00923527404665947\n",
      "[1081,     1] loss: 0.009223286993801594\n",
      "[1082,     1] loss: 0.009210841730237007\n",
      "[1083,     1] loss: 0.009198201820254326\n",
      "[1084,     1] loss: 0.009186009876430035\n",
      "[1085,     1] loss: 0.009173605591058731\n",
      "[1086,     1] loss: 0.009161299094557762\n",
      "[1087,     1] loss: 0.009149083867669106\n",
      "[1088,     1] loss: 0.009136932902038097\n",
      "[1089,     1] loss: 0.009124807082116604\n",
      "[1090,     1] loss: 0.009112667292356491\n",
      "[1091,     1] loss: 0.009100292809307575\n",
      "[1092,     1] loss: 0.009087992832064629\n",
      "[1093,     1] loss: 0.009076029062271118\n",
      "[1094,     1] loss: 0.009063934907317162\n",
      "[1095,     1] loss: 0.009051973931491375\n",
      "[1096,     1] loss: 0.009039896540343761\n",
      "[1097,     1] loss: 0.009027767926454544\n",
      "[1098,     1] loss: 0.009015673771500587\n",
      "[1099,     1] loss: 0.009003909304738045\n",
      "[1100,     1] loss: 0.00899219699203968\n",
      "[1101,     1] loss: 0.008980059996247292\n",
      "[1102,     1] loss: 0.008967984467744827\n",
      "[1103,     1] loss: 0.008956301026046276\n",
      "[1104,     1] loss: 0.008944883942604065\n",
      "[1105,     1] loss: 0.008933227509260178\n",
      "[1106,     1] loss: 0.008921753615140915\n",
      "[1107,     1] loss: 0.008909981697797775\n",
      "[1108,     1] loss: 0.008898520842194557\n",
      "[1109,     1] loss: 0.00888731237500906\n",
      "[1110,     1] loss: 0.00887554232031107\n",
      "[1111,     1] loss: 0.008863881230354309\n",
      "[1112,     1] loss: 0.008852772414684296\n",
      "[1113,     1] loss: 0.008841287344694138\n",
      "[1114,     1] loss: 0.008829799480736256\n",
      "[1115,     1] loss: 0.008818279951810837\n",
      "[1116,     1] loss: 0.00880708359181881\n",
      "[1117,     1] loss: 0.00879601575434208\n",
      "[1118,     1] loss: 0.00878459308296442\n",
      "[1119,     1] loss: 0.008773185312747955\n",
      "[1120,     1] loss: 0.008761775679886341\n",
      "[1121,     1] loss: 0.008750571869313717\n",
      "[1122,     1] loss: 0.008739258162677288\n",
      "[1123,     1] loss: 0.008727959357202053\n",
      "[1124,     1] loss: 0.008717063814401627\n",
      "[1125,     1] loss: 0.008705800399184227\n",
      "[1126,     1] loss: 0.00869465246796608\n",
      "[1127,     1] loss: 0.008683525025844574\n",
      "[1128,     1] loss: 0.008672491647303104\n",
      "[1129,     1] loss: 0.008661319501698017\n",
      "[1130,     1] loss: 0.008650314062833786\n",
      "[1131,     1] loss: 0.00863933376967907\n",
      "[1132,     1] loss: 0.008628453128039837\n",
      "[1133,     1] loss: 0.008617515675723553\n",
      "[1134,     1] loss: 0.008606445044279099\n",
      "[1135,     1] loss: 0.008595846593379974\n",
      "[1136,     1] loss: 0.008585517294704914\n",
      "[1137,     1] loss: 0.008575187996029854\n",
      "[1138,     1] loss: 0.008565306663513184\n",
      "[1139,     1] loss: 0.008555877022445202\n",
      "[1140,     1] loss: 0.008546947501599789\n",
      "[1141,     1] loss: 0.008537879213690758\n",
      "[1142,     1] loss: 0.00852745957672596\n",
      "[1143,     1] loss: 0.008515657857060432\n",
      "[1144,     1] loss: 0.008502757176756859\n",
      "[1145,     1] loss: 0.008490145206451416\n",
      "[1146,     1] loss: 0.008479293435811996\n",
      "[1147,     1] loss: 0.008470052853226662\n",
      "[1148,     1] loss: 0.008460797369480133\n",
      "[1149,     1] loss: 0.008450598455965519\n",
      "[1150,     1] loss: 0.008439091965556145\n",
      "[1151,     1] loss: 0.008426651358604431\n",
      "[1152,     1] loss: 0.008414157666265965\n",
      "[1153,     1] loss: 0.008402440696954727\n",
      "[1154,     1] loss: 0.008391207084059715\n",
      "[1155,     1] loss: 0.008379843086004257\n",
      "[1156,     1] loss: 0.008368134498596191\n",
      "[1157,     1] loss: 0.008356635458767414\n",
      "[1158,     1] loss: 0.008345904760062695\n",
      "[1159,     1] loss: 0.008335957303643227\n",
      "[1160,     1] loss: 0.008325304836034775\n",
      "[1161,     1] loss: 0.008314146660268307\n",
      "[1162,     1] loss: 0.008302699774503708\n",
      "[1163,     1] loss: 0.008290944620966911\n",
      "[1164,     1] loss: 0.008279575034976006\n",
      "[1165,     1] loss: 0.00826866552233696\n",
      "[1166,     1] loss: 0.008258325047791004\n",
      "[1167,     1] loss: 0.008247745223343372\n",
      "[1168,     1] loss: 0.008237120695412159\n",
      "[1169,     1] loss: 0.008225996047258377\n",
      "[1170,     1] loss: 0.008215106092393398\n",
      "[1171,     1] loss: 0.008204526267945766\n",
      "[1172,     1] loss: 0.00819399394094944\n",
      "[1173,     1] loss: 0.00818354357033968\n",
      "[1174,     1] loss: 0.008173263631761074\n",
      "[1175,     1] loss: 0.008163206279277802\n",
      "[1176,     1] loss: 0.00815270934253931\n",
      "[1177,     1] loss: 0.00814251322299242\n",
      "[1178,     1] loss: 0.008132684044539928\n",
      "[1179,     1] loss: 0.008123043924570084\n",
      "[1180,     1] loss: 0.008113495074212551\n",
      "[1181,     1] loss: 0.008104386739432812\n",
      "[1182,     1] loss: 0.008096224628388882\n",
      "[1183,     1] loss: 0.008089564740657806\n",
      "[1184,     1] loss: 0.00808444619178772\n",
      "[1185,     1] loss: 0.00808135885745287\n",
      "[1186,     1] loss: 0.008080882951617241\n",
      "[1187,     1] loss: 0.008082321844995022\n",
      "[1188,     1] loss: 0.008082306943833828\n",
      "[1189,     1] loss: 0.008075816556811333\n",
      "[1190,     1] loss: 0.008060325868427753\n",
      "[1191,     1] loss: 0.008037116378545761\n",
      "[1192,     1] loss: 0.008012416772544384\n",
      "[1193,     1] loss: 0.007992183789610863\n",
      "[1194,     1] loss: 0.007979121059179306\n",
      "[1195,     1] loss: 0.007972114719450474\n",
      "[1196,     1] loss: 0.007967177778482437\n",
      "[1197,     1] loss: 0.007959551177918911\n",
      "[1198,     1] loss: 0.007947182282805443\n",
      "[1199,     1] loss: 0.007931062020361423\n",
      "[1200,     1] loss: 0.007915044203400612\n",
      "[1201,     1] loss: 0.007903479970991611\n",
      "[1202,     1] loss: 0.007896814495325089\n",
      "[1203,     1] loss: 0.007891198620200157\n",
      "[1204,     1] loss: 0.00788226630538702\n",
      "[1205,     1] loss: 0.007868810556828976\n",
      "[1206,     1] loss: 0.007854410447180271\n",
      "[1207,     1] loss: 0.007842586375772953\n",
      "[1208,     1] loss: 0.007833953946828842\n",
      "[1209,     1] loss: 0.007826394401490688\n",
      "[1210,     1] loss: 0.007817381992936134\n",
      "[1211,     1] loss: 0.007806213106960058\n",
      "[1212,     1] loss: 0.0077942535281181335\n",
      "[1213,     1] loss: 0.007783401291817427\n",
      "[1214,     1] loss: 0.007774056866765022\n",
      "[1215,     1] loss: 0.0077651687897741795\n",
      "[1216,     1] loss: 0.00775554496794939\n",
      "[1217,     1] loss: 0.0077452282421290874\n",
      "[1218,     1] loss: 0.007734844461083412\n",
      "[1219,     1] loss: 0.007724572904407978\n",
      "[1220,     1] loss: 0.007715027779340744\n",
      "[1221,     1] loss: 0.00770525261759758\n",
      "[1222,     1] loss: 0.0076955510303378105\n",
      "[1223,     1] loss: 0.007685855962336063\n",
      "[1224,     1] loss: 0.007676512468606234\n",
      "[1225,     1] loss: 0.007667107507586479\n",
      "[1226,     1] loss: 0.0076573695987463\n",
      "[1227,     1] loss: 0.007647538557648659\n",
      "[1228,     1] loss: 0.007637914270162582\n",
      "[1229,     1] loss: 0.007628591265529394\n",
      "[1230,     1] loss: 0.007619569078087807\n",
      "[1231,     1] loss: 0.007610557600855827\n",
      "[1232,     1] loss: 0.007601249497383833\n",
      "[1233,     1] loss: 0.007591813802719116\n",
      "[1234,     1] loss: 0.00758255273103714\n",
      "[1235,     1] loss: 0.007573273964226246\n",
      "[1236,     1] loss: 0.007564221508800983\n",
      "[1237,     1] loss: 0.007555065210908651\n",
      "[1238,     1] loss: 0.007546244654804468\n",
      "[1239,     1] loss: 0.007537204772233963\n",
      "[1240,     1] loss: 0.007528034970164299\n",
      "[1241,     1] loss: 0.007518939673900604\n",
      "[1242,     1] loss: 0.007510017603635788\n",
      "[1243,     1] loss: 0.007500908337533474\n",
      "[1244,     1] loss: 0.00749203423038125\n",
      "[1245,     1] loss: 0.007483066990971565\n",
      "[1246,     1] loss: 0.007474198006093502\n",
      "[1247,     1] loss: 0.00746533926576376\n",
      "[1248,     1] loss: 0.007456501014530659\n",
      "[1249,     1] loss: 0.007447667419910431\n",
      "[1250,     1] loss: 0.00743890181183815\n",
      "[1251,     1] loss: 0.0074301306158304214\n",
      "[1252,     1] loss: 0.007421310991048813\n",
      "[1253,     1] loss: 0.007412659004330635\n",
      "[1254,     1] loss: 0.007404147647321224\n",
      "[1255,     1] loss: 0.007395446766167879\n",
      "[1256,     1] loss: 0.007386940531432629\n",
      "[1257,     1] loss: 0.007378434296697378\n",
      "[1258,     1] loss: 0.007370295934379101\n",
      "[1259,     1] loss: 0.007362208794802427\n",
      "[1260,     1] loss: 0.007354297675192356\n",
      "[1261,     1] loss: 0.007345939055085182\n",
      "[1262,     1] loss: 0.007337961345911026\n",
      "[1263,     1] loss: 0.00732976570725441\n",
      "[1264,     1] loss: 0.007321832701563835\n",
      "[1265,     1] loss: 0.00731326499953866\n",
      "[1266,     1] loss: 0.007304446306079626\n",
      "[1267,     1] loss: 0.007295525632798672\n",
      "[1268,     1] loss: 0.0072866263799369335\n",
      "[1269,     1] loss: 0.007278125733137131\n",
      "[1270,     1] loss: 0.007270270027220249\n",
      "[1271,     1] loss: 0.007262804079800844\n",
      "[1272,     1] loss: 0.007254983298480511\n",
      "[1273,     1] loss: 0.007246703375130892\n",
      "[1274,     1] loss: 0.007237914949655533\n",
      "[1275,     1] loss: 0.007228711619973183\n",
      "[1276,     1] loss: 0.007219366263598204\n",
      "[1277,     1] loss: 0.007210168056190014\n",
      "[1278,     1] loss: 0.0072011761367321014\n",
      "[1279,     1] loss: 0.007192717399448156\n",
      "[1280,     1] loss: 0.007184354122728109\n",
      "[1281,     1] loss: 0.007176173850893974\n",
      "[1282,     1] loss: 0.007167663890868425\n",
      "[1283,     1] loss: 0.007159202825278044\n",
      "[1284,     1] loss: 0.007150610908865929\n",
      "[1285,     1] loss: 0.007141992449760437\n",
      "[1286,     1] loss: 0.00713352020829916\n",
      "[1287,     1] loss: 0.007125226315110922\n",
      "[1288,     1] loss: 0.007116949185729027\n",
      "[1289,     1] loss: 0.007108749821782112\n",
      "[1290,     1] loss: 0.007100680377334356\n",
      "[1291,     1] loss: 0.007092068903148174\n",
      "[1292,     1] loss: 0.007083852309733629\n",
      "[1293,     1] loss: 0.0070755695924162865\n",
      "[1294,     1] loss: 0.007067404221743345\n",
      "[1295,     1] loss: 0.007059034425765276\n",
      "[1296,     1] loss: 0.007050866726785898\n",
      "[1297,     1] loss: 0.007042733021080494\n",
      "[1298,     1] loss: 0.00703470129519701\n",
      "[1299,     1] loss: 0.00702659273520112\n",
      "[1300,     1] loss: 0.007018514443188906\n",
      "[1301,     1] loss: 0.007010192610323429\n",
      "[1302,     1] loss: 0.007002187427133322\n",
      "[1303,     1] loss: 0.006994173396378756\n",
      "[1304,     1] loss: 0.0069863395765423775\n",
      "[1305,     1] loss: 0.006978696212172508\n",
      "[1306,     1] loss: 0.006971253082156181\n",
      "[1307,     1] loss: 0.006963688880205154\n",
      "[1308,     1] loss: 0.006956551223993301\n",
      "[1309,     1] loss: 0.006949865724891424\n",
      "[1310,     1] loss: 0.0069434004835784435\n",
      "[1311,     1] loss: 0.006937422789633274\n",
      "[1312,     1] loss: 0.006931931246072054\n",
      "[1313,     1] loss: 0.006927205249667168\n",
      "[1314,     1] loss: 0.006923132110387087\n",
      "[1315,     1] loss: 0.006919235922396183\n",
      "[1316,     1] loss: 0.00691539142280817\n",
      "[1317,     1] loss: 0.006910473108291626\n",
      "[1318,     1] loss: 0.006903495639562607\n",
      "[1319,     1] loss: 0.006893295794725418\n",
      "[1320,     1] loss: 0.006880643777549267\n",
      "[1321,     1] loss: 0.006866829469799995\n",
      "[1322,     1] loss: 0.006853604689240456\n",
      "[1323,     1] loss: 0.006842509843409061\n",
      "[1324,     1] loss: 0.006833441089838743\n",
      "[1325,     1] loss: 0.006825852207839489\n",
      "[1326,     1] loss: 0.006819155067205429\n",
      "[1327,     1] loss: 0.006812599487602711\n",
      "[1328,     1] loss: 0.006805486511439085\n",
      "[1329,     1] loss: 0.006797718815505505\n",
      "[1330,     1] loss: 0.006789553910493851\n",
      "[1331,     1] loss: 0.006780934985727072\n",
      "[1332,     1] loss: 0.006772127002477646\n",
      "[1333,     1] loss: 0.006763423793017864\n",
      "[1334,     1] loss: 0.006754991598427296\n",
      "[1335,     1] loss: 0.006746878381818533\n",
      "[1336,     1] loss: 0.006738862954080105\n",
      "[1337,     1] loss: 0.006731333676725626\n",
      "[1338,     1] loss: 0.006723896600306034\n",
      "[1339,     1] loss: 0.006716468371450901\n",
      "[1340,     1] loss: 0.006709020584821701\n",
      "[1341,     1] loss: 0.006701234262436628\n",
      "[1342,     1] loss: 0.006693469360470772\n",
      "[1343,     1] loss: 0.00668578315526247\n",
      "[1344,     1] loss: 0.006678061559796333\n",
      "[1345,     1] loss: 0.00667036697268486\n",
      "[1346,     1] loss: 0.006662909872829914\n",
      "[1347,     1] loss: 0.006655318662524223\n",
      "[1348,     1] loss: 0.006647732108831406\n",
      "[1349,     1] loss: 0.006639985833317041\n",
      "[1350,     1] loss: 0.0066322581842541695\n",
      "[1351,     1] loss: 0.006624515634030104\n",
      "[1352,     1] loss: 0.006616754923015833\n",
      "[1353,     1] loss: 0.006609272677451372\n",
      "[1354,     1] loss: 0.006602093577384949\n",
      "[1355,     1] loss: 0.006594713311642408\n",
      "[1356,     1] loss: 0.006587529089301825\n",
      "[1357,     1] loss: 0.0065803928300738335\n",
      "[1358,     1] loss: 0.006573350168764591\n",
      "[1359,     1] loss: 0.006566207855939865\n",
      "[1360,     1] loss: 0.006559011526405811\n",
      "[1361,     1] loss: 0.006552135571837425\n",
      "[1362,     1] loss: 0.006545133888721466\n",
      "[1363,     1] loss: 0.006538425572216511\n",
      "[1364,     1] loss: 0.006531714927405119\n",
      "[1365,     1] loss: 0.006525150965899229\n",
      "[1366,     1] loss: 0.006518433801829815\n",
      "[1367,     1] loss: 0.00651146424934268\n",
      "[1368,     1] loss: 0.006504694931209087\n",
      "[1369,     1] loss: 0.006497759371995926\n",
      "[1370,     1] loss: 0.006490656174719334\n",
      "[1371,     1] loss: 0.00648347707465291\n",
      "[1372,     1] loss: 0.006476250477135181\n",
      "[1373,     1] loss: 0.006469255778938532\n",
      "[1374,     1] loss: 0.006462435703724623\n",
      "[1375,     1] loss: 0.006455757189542055\n",
      "[1376,     1] loss: 0.006448980420827866\n",
      "[1377,     1] loss: 0.006442158482968807\n",
      "[1378,     1] loss: 0.0064353374764323235\n",
      "[1379,     1] loss: 0.006428579334169626\n",
      "[1380,     1] loss: 0.006421591155230999\n",
      "[1381,     1] loss: 0.006414264440536499\n",
      "[1382,     1] loss: 0.006406701635569334\n",
      "[1383,     1] loss: 0.006399131380021572\n",
      "[1384,     1] loss: 0.006391462869942188\n",
      "[1385,     1] loss: 0.006383833475410938\n",
      "[1386,     1] loss: 0.006376741454005241\n",
      "[1387,     1] loss: 0.006370207294821739\n",
      "[1388,     1] loss: 0.006363946013152599\n",
      "[1389,     1] loss: 0.00635748403146863\n",
      "[1390,     1] loss: 0.006350796669721603\n",
      "[1391,     1] loss: 0.006344257853925228\n",
      "[1392,     1] loss: 0.006337688770145178\n",
      "[1393,     1] loss: 0.0063311392441391945\n",
      "[1394,     1] loss: 0.006324509624391794\n",
      "[1395,     1] loss: 0.00631770258769393\n",
      "[1396,     1] loss: 0.006310906261205673\n",
      "[1397,     1] loss: 0.006303907372057438\n",
      "[1398,     1] loss: 0.0062965815886855125\n",
      "[1399,     1] loss: 0.006289323791861534\n",
      "[1400,     1] loss: 0.0062820324674248695\n",
      "[1401,     1] loss: 0.006274451967328787\n",
      "[1402,     1] loss: 0.006266762036830187\n",
      "[1403,     1] loss: 0.006259518675506115\n",
      "[1404,     1] loss: 0.00625248346477747\n",
      "[1405,     1] loss: 0.006245554890483618\n",
      "[1406,     1] loss: 0.006238607224076986\n",
      "[1407,     1] loss: 0.006231662817299366\n",
      "[1408,     1] loss: 0.00622476264834404\n",
      "[1409,     1] loss: 0.006217824295163155\n",
      "[1410,     1] loss: 0.006210987456142902\n",
      "[1411,     1] loss: 0.006204053293913603\n",
      "[1412,     1] loss: 0.006197236478328705\n",
      "[1413,     1] loss: 0.0061905235052108765\n",
      "[1414,     1] loss: 0.006183984689414501\n",
      "[1415,     1] loss: 0.006177499890327454\n",
      "[1416,     1] loss: 0.006171241402626038\n",
      "[1417,     1] loss: 0.0061652446165680885\n",
      "[1418,     1] loss: 0.006159564480185509\n",
      "[1419,     1] loss: 0.006153883412480354\n",
      "[1420,     1] loss: 0.006148585118353367\n",
      "[1421,     1] loss: 0.006143220700323582\n",
      "[1422,     1] loss: 0.006137843243777752\n",
      "[1423,     1] loss: 0.006132964044809341\n",
      "[1424,     1] loss: 0.006128107663244009\n",
      "[1425,     1] loss: 0.00612297747284174\n",
      "[1426,     1] loss: 0.006117463111877441\n",
      "[1427,     1] loss: 0.006111816503107548\n",
      "[1428,     1] loss: 0.0061056483536958694\n",
      "[1429,     1] loss: 0.006098829675465822\n",
      "[1430,     1] loss: 0.0060911779291927814\n",
      "[1431,     1] loss: 0.006082977168262005\n",
      "[1432,     1] loss: 0.006074339151382446\n",
      "[1433,     1] loss: 0.006065667606890202\n",
      "[1434,     1] loss: 0.00605820445343852\n",
      "[1435,     1] loss: 0.006052350625395775\n",
      "[1436,     1] loss: 0.006047320086508989\n",
      "[1437,     1] loss: 0.00604245625436306\n",
      "[1438,     1] loss: 0.0060372017323970795\n",
      "[1439,     1] loss: 0.006031721830368042\n",
      "[1440,     1] loss: 0.006026281975209713\n",
      "[1441,     1] loss: 0.006021336652338505\n",
      "[1442,     1] loss: 0.006016617175191641\n",
      "[1443,     1] loss: 0.00601202342659235\n",
      "[1444,     1] loss: 0.006006943061947823\n",
      "[1445,     1] loss: 0.0060012186877429485\n",
      "[1446,     1] loss: 0.005994709208607674\n",
      "[1447,     1] loss: 0.005987842567265034\n",
      "[1448,     1] loss: 0.0059808846563100815\n",
      "[1449,     1] loss: 0.005973323713988066\n",
      "[1450,     1] loss: 0.005964973941445351\n",
      "[1451,     1] loss: 0.005955604836344719\n",
      "[1452,     1] loss: 0.005946439225226641\n",
      "[1453,     1] loss: 0.005937639623880386\n",
      "[1454,     1] loss: 0.005929957143962383\n",
      "[1455,     1] loss: 0.005922997836023569\n",
      "[1456,     1] loss: 0.0059170774184167385\n",
      "[1457,     1] loss: 0.005911301821470261\n",
      "[1458,     1] loss: 0.005905402358621359\n",
      "[1459,     1] loss: 0.0058989133685827255\n",
      "[1460,     1] loss: 0.005892052315175533\n",
      "[1461,     1] loss: 0.005885142832994461\n",
      "[1462,     1] loss: 0.005878262687474489\n",
      "[1463,     1] loss: 0.005871565546840429\n",
      "[1464,     1] loss: 0.005865035112947226\n",
      "[1465,     1] loss: 0.005858731921762228\n",
      "[1466,     1] loss: 0.005852482281625271\n",
      "[1467,     1] loss: 0.005846430081874132\n",
      "[1468,     1] loss: 0.005840474274009466\n",
      "[1469,     1] loss: 0.0058345007710158825\n",
      "[1470,     1] loss: 0.005828474648296833\n",
      "[1471,     1] loss: 0.005822638049721718\n",
      "[1472,     1] loss: 0.005816809833049774\n",
      "[1473,     1] loss: 0.005810877308249474\n",
      "[1474,     1] loss: 0.005804812535643578\n",
      "[1475,     1] loss: 0.005798520054668188\n",
      "[1476,     1] loss: 0.005791942588984966\n",
      "[1477,     1] loss: 0.005785434506833553\n",
      "[1478,     1] loss: 0.005778946448117495\n",
      "[1479,     1] loss: 0.005772555246949196\n",
      "[1480,     1] loss: 0.005766408983618021\n",
      "[1481,     1] loss: 0.0057604131288826466\n",
      "[1482,     1] loss: 0.005754576530307531\n",
      "[1483,     1] loss: 0.00574860442429781\n",
      "[1484,     1] loss: 0.005742679815739393\n",
      "[1485,     1] loss: 0.00573690515011549\n",
      "[1486,     1] loss: 0.005731265060603619\n",
      "[1487,     1] loss: 0.005725744646042585\n",
      "[1488,     1] loss: 0.005720356944948435\n",
      "[1489,     1] loss: 0.005715243052691221\n",
      "[1490,     1] loss: 0.005710371769964695\n",
      "[1491,     1] loss: 0.005705490708351135\n",
      "[1492,     1] loss: 0.005700576584786177\n",
      "[1493,     1] loss: 0.005695960484445095\n",
      "[1494,     1] loss: 0.005691578146070242\n",
      "[1495,     1] loss: 0.005687213037163019\n",
      "[1496,     1] loss: 0.005682316608726978\n",
      "[1497,     1] loss: 0.0056770313531160355\n",
      "[1498,     1] loss: 0.005671024322509766\n",
      "[1499,     1] loss: 0.005664440803229809\n",
      "[1500,     1] loss: 0.005657773464918137\n",
      "[1501,     1] loss: 0.005650387145578861\n",
      "[1502,     1] loss: 0.005642847158014774\n",
      "[1503,     1] loss: 0.005635202396661043\n",
      "[1504,     1] loss: 0.005627474281936884\n",
      "[1505,     1] loss: 0.005619890987873077\n",
      "[1506,     1] loss: 0.0056124464608728886\n",
      "[1507,     1] loss: 0.005605138838291168\n",
      "[1508,     1] loss: 0.00559789314866066\n",
      "[1509,     1] loss: 0.005590860266238451\n",
      "[1510,     1] loss: 0.0055842348374426365\n",
      "[1511,     1] loss: 0.005577954463660717\n",
      "[1512,     1] loss: 0.005572134628891945\n",
      "[1513,     1] loss: 0.005567010957747698\n",
      "[1514,     1] loss: 0.005562189035117626\n",
      "[1515,     1] loss: 0.005557474680244923\n",
      "[1516,     1] loss: 0.005552827380597591\n",
      "[1517,     1] loss: 0.005548295099288225\n",
      "[1518,     1] loss: 0.005543415900319815\n",
      "[1519,     1] loss: 0.005538392346352339\n",
      "[1520,     1] loss: 0.005532864481210709\n",
      "[1521,     1] loss: 0.005527478642761707\n",
      "[1522,     1] loss: 0.005521601997315884\n",
      "[1523,     1] loss: 0.005515749100595713\n",
      "[1524,     1] loss: 0.0055092861875891685\n",
      "[1525,     1] loss: 0.005502923391759396\n",
      "[1526,     1] loss: 0.005495986435562372\n",
      "[1527,     1] loss: 0.005488828755915165\n",
      "[1528,     1] loss: 0.005481733474880457\n",
      "[1529,     1] loss: 0.00547464843839407\n",
      "[1530,     1] loss: 0.005467720329761505\n",
      "[1531,     1] loss: 0.005461215972900391\n",
      "[1532,     1] loss: 0.005455076694488525\n",
      "[1533,     1] loss: 0.0054490286856889725\n",
      "[1534,     1] loss: 0.005443235859274864\n",
      "[1535,     1] loss: 0.005437579471617937\n",
      "[1536,     1] loss: 0.005431882105767727\n",
      "[1537,     1] loss: 0.005426220595836639\n",
      "[1538,     1] loss: 0.005420583765953779\n",
      "[1539,     1] loss: 0.00541504705324769\n",
      "[1540,     1] loss: 0.005409623961895704\n",
      "[1541,     1] loss: 0.005404313560575247\n",
      "[1542,     1] loss: 0.005399215966463089\n",
      "[1543,     1] loss: 0.005394390784204006\n",
      "[1544,     1] loss: 0.00538980308920145\n",
      "[1545,     1] loss: 0.005385898984968662\n",
      "[1546,     1] loss: 0.005382650066167116\n",
      "[1547,     1] loss: 0.005380173213779926\n",
      "[1548,     1] loss: 0.0053786057978868484\n",
      "[1549,     1] loss: 0.005378132686018944\n",
      "[1550,     1] loss: 0.005378143861889839\n",
      "[1551,     1] loss: 0.005378039553761482\n",
      "[1552,     1] loss: 0.00537643488496542\n",
      "[1553,     1] loss: 0.005372792482376099\n",
      "[1554,     1] loss: 0.005366328172385693\n",
      "[1555,     1] loss: 0.005357732065021992\n",
      "[1556,     1] loss: 0.005347851663827896\n",
      "[1557,     1] loss: 0.005339123774319887\n",
      "[1558,     1] loss: 0.005331814289093018\n",
      "[1559,     1] loss: 0.005327343940734863\n",
      "[1560,     1] loss: 0.005324028432369232\n",
      "[1561,     1] loss: 0.005320494994521141\n",
      "[1562,     1] loss: 0.00531419925391674\n",
      "[1563,     1] loss: 0.005305147264152765\n",
      "[1564,     1] loss: 0.005293317139148712\n",
      "[1565,     1] loss: 0.005281629040837288\n",
      "[1566,     1] loss: 0.005271832924336195\n",
      "[1567,     1] loss: 0.005264753941446543\n",
      "[1568,     1] loss: 0.005260271951556206\n",
      "[1569,     1] loss: 0.005257125478237867\n",
      "[1570,     1] loss: 0.005254102870821953\n",
      "[1571,     1] loss: 0.005250084213912487\n",
      "[1572,     1] loss: 0.005245336797088385\n",
      "[1573,     1] loss: 0.005239289719611406\n",
      "[1574,     1] loss: 0.005233371164649725\n",
      "[1575,     1] loss: 0.0052269380539655685\n",
      "[1576,     1] loss: 0.005219804123044014\n",
      "[1577,     1] loss: 0.0052121407352387905\n",
      "[1578,     1] loss: 0.005204983055591583\n",
      "[1579,     1] loss: 0.005198888015002012\n",
      "[1580,     1] loss: 0.005193561315536499\n",
      "[1581,     1] loss: 0.00518905371427536\n",
      "[1582,     1] loss: 0.005184568930417299\n",
      "[1583,     1] loss: 0.005180069711059332\n",
      "[1584,     1] loss: 0.00517524778842926\n",
      "[1585,     1] loss: 0.005170430988073349\n",
      "[1586,     1] loss: 0.005165604874491692\n",
      "[1587,     1] loss: 0.005161281209439039\n",
      "[1588,     1] loss: 0.005156651139259338\n",
      "[1589,     1] loss: 0.005151865538209677\n",
      "[1590,     1] loss: 0.0051465947180986404\n",
      "[1591,     1] loss: 0.0051408736035227776\n",
      "[1592,     1] loss: 0.005134847015142441\n",
      "[1593,     1] loss: 0.0051288907416164875\n",
      "[1594,     1] loss: 0.005123197101056576\n",
      "[1595,     1] loss: 0.005117602646350861\n",
      "[1596,     1] loss: 0.005112263839691877\n",
      "[1597,     1] loss: 0.005107153207063675\n",
      "[1598,     1] loss: 0.00510207936167717\n",
      "[1599,     1] loss: 0.005096782930195332\n",
      "[1600,     1] loss: 0.005091617349535227\n",
      "[1601,     1] loss: 0.005086495541036129\n",
      "[1602,     1] loss: 0.005081375129520893\n",
      "[1603,     1] loss: 0.005076386500149965\n",
      "[1604,     1] loss: 0.005071522202342749\n",
      "[1605,     1] loss: 0.0050667948089540005\n",
      "[1606,     1] loss: 0.005062027834355831\n",
      "[1607,     1] loss: 0.005057509522885084\n",
      "[1608,     1] loss: 0.005053195636719465\n",
      "[1609,     1] loss: 0.005049186758697033\n",
      "[1610,     1] loss: 0.005045500583946705\n",
      "[1611,     1] loss: 0.005042075179517269\n",
      "[1612,     1] loss: 0.005039248149842024\n",
      "[1613,     1] loss: 0.005036117509007454\n",
      "[1614,     1] loss: 0.005032965913414955\n",
      "[1615,     1] loss: 0.0050294529646635056\n",
      "[1616,     1] loss: 0.005025905556976795\n",
      "[1617,     1] loss: 0.005021283403038979\n",
      "[1618,     1] loss: 0.005016949027776718\n",
      "[1619,     1] loss: 0.005011207424104214\n",
      "[1620,     1] loss: 0.005005779676139355\n",
      "[1621,     1] loss: 0.004998972173780203\n",
      "[1622,     1] loss: 0.004991736263036728\n",
      "[1623,     1] loss: 0.004984564613550901\n",
      "[1624,     1] loss: 0.004977790638804436\n",
      "[1625,     1] loss: 0.004971558693796396\n",
      "[1626,     1] loss: 0.004966021049767733\n",
      "[1627,     1] loss: 0.004961021710187197\n",
      "[1628,     1] loss: 0.004956583958119154\n",
      "[1629,     1] loss: 0.004952545277774334\n",
      "[1630,     1] loss: 0.004948583897203207\n",
      "[1631,     1] loss: 0.004944811575114727\n",
      "[1632,     1] loss: 0.004941568709909916\n",
      "[1633,     1] loss: 0.004938419442623854\n",
      "[1634,     1] loss: 0.004935603588819504\n",
      "[1635,     1] loss: 0.004932730458676815\n",
      "[1636,     1] loss: 0.004929196089506149\n",
      "[1637,     1] loss: 0.004925436340272427\n",
      "[1638,     1] loss: 0.004920717794448137\n",
      "[1639,     1] loss: 0.004915808793157339\n",
      "[1640,     1] loss: 0.004910137504339218\n",
      "[1641,     1] loss: 0.004904208704829216\n",
      "[1642,     1] loss: 0.0048980144783854485\n",
      "[1643,     1] loss: 0.00489205215126276\n",
      "[1644,     1] loss: 0.004886548034846783\n",
      "[1645,     1] loss: 0.004881245084106922\n",
      "[1646,     1] loss: 0.0048763807862997055\n",
      "[1647,     1] loss: 0.004871706012636423\n",
      "[1648,     1] loss: 0.004867227282375097\n",
      "[1649,     1] loss: 0.004862846806645393\n",
      "[1650,     1] loss: 0.004858510103076696\n",
      "[1651,     1] loss: 0.0048542264848947525\n",
      "[1652,     1] loss: 0.0048501091077923775\n",
      "[1653,     1] loss: 0.004845904652029276\n",
      "[1654,     1] loss: 0.0048415446653962135\n",
      "[1655,     1] loss: 0.004837078507989645\n",
      "[1656,     1] loss: 0.0048326291143894196\n",
      "[1657,     1] loss: 0.004828324541449547\n",
      "[1658,     1] loss: 0.004824291914701462\n",
      "[1659,     1] loss: 0.004820795729756355\n",
      "[1660,     1] loss: 0.004817910026758909\n",
      "[1661,     1] loss: 0.004815404303371906\n",
      "[1662,     1] loss: 0.004813329316675663\n",
      "[1663,     1] loss: 0.004811491817235947\n",
      "[1664,     1] loss: 0.004809582605957985\n",
      "[1665,     1] loss: 0.004807992372661829\n",
      "[1666,     1] loss: 0.004805964417755604\n",
      "[1667,     1] loss: 0.0048033567145466805\n",
      "[1668,     1] loss: 0.0047990186139941216\n",
      "[1669,     1] loss: 0.004793187137693167\n",
      "[1670,     1] loss: 0.004785943776369095\n",
      "[1671,     1] loss: 0.004778234753757715\n",
      "[1672,     1] loss: 0.004769910592585802\n",
      "[1673,     1] loss: 0.00476178340613842\n",
      "[1674,     1] loss: 0.004754329100251198\n",
      "[1675,     1] loss: 0.0047478387132287025\n",
      "[1676,     1] loss: 0.004742457997053862\n",
      "[1677,     1] loss: 0.004737995099276304\n",
      "[1678,     1] loss: 0.00473381020128727\n",
      "[1679,     1] loss: 0.004729889333248138\n",
      "[1680,     1] loss: 0.0047261458821594715\n",
      "[1681,     1] loss: 0.004722196608781815\n",
      "[1682,     1] loss: 0.0047183167189359665\n",
      "[1683,     1] loss: 0.004714655689895153\n",
      "[1684,     1] loss: 0.00471135787665844\n",
      "[1685,     1] loss: 0.004708628635853529\n",
      "[1686,     1] loss: 0.004706487990915775\n",
      "[1687,     1] loss: 0.004704458639025688\n",
      "[1688,     1] loss: 0.004702282138168812\n",
      "[1689,     1] loss: 0.004699711222201586\n",
      "[1690,     1] loss: 0.00469724927097559\n",
      "[1691,     1] loss: 0.004693211987614632\n",
      "[1692,     1] loss: 0.004688466899096966\n",
      "[1693,     1] loss: 0.0046826438046991825\n",
      "[1694,     1] loss: 0.004676364362239838\n",
      "[1695,     1] loss: 0.00466954056173563\n",
      "[1696,     1] loss: 0.004663339350372553\n",
      "[1697,     1] loss: 0.004657479468733072\n",
      "[1698,     1] loss: 0.004652305040508509\n",
      "[1699,     1] loss: 0.004647888243198395\n",
      "[1700,     1] loss: 0.004644427448511124\n",
      "[1701,     1] loss: 0.004641453269869089\n",
      "[1702,     1] loss: 0.004639227408915758\n",
      "[1703,     1] loss: 0.004637795966118574\n",
      "[1704,     1] loss: 0.004636791534721851\n",
      "[1705,     1] loss: 0.004636506550014019\n",
      "[1706,     1] loss: 0.004636030178517103\n",
      "[1707,     1] loss: 0.004634639248251915\n",
      "[1708,     1] loss: 0.004632024560123682\n",
      "[1709,     1] loss: 0.004628071561455727\n",
      "[1710,     1] loss: 0.004622249398380518\n",
      "[1711,     1] loss: 0.0046152169816195965\n",
      "[1712,     1] loss: 0.004607098177075386\n",
      "[1713,     1] loss: 0.004599007777869701\n",
      "[1714,     1] loss: 0.0045912545174360275\n",
      "[1715,     1] loss: 0.004585553891956806\n",
      "[1716,     1] loss: 0.00458112545311451\n",
      "[1717,     1] loss: 0.004577714018523693\n",
      "[1718,     1] loss: 0.004574041347950697\n",
      "[1719,     1] loss: 0.004569951444864273\n",
      "[1720,     1] loss: 0.0045655593276023865\n",
      "[1721,     1] loss: 0.004561096895486116\n",
      "[1722,     1] loss: 0.004556967876851559\n",
      "[1723,     1] loss: 0.004552771337330341\n",
      "[1724,     1] loss: 0.004548497498035431\n",
      "[1725,     1] loss: 0.004544257652014494\n",
      "[1726,     1] loss: 0.004540115129202604\n",
      "[1727,     1] loss: 0.004536325111985207\n",
      "[1728,     1] loss: 0.0045329499989748\n",
      "[1729,     1] loss: 0.004530486650764942\n",
      "[1730,     1] loss: 0.00452820397913456\n",
      "[1731,     1] loss: 0.004526050295680761\n",
      "[1732,     1] loss: 0.004524035379290581\n",
      "[1733,     1] loss: 0.004522799979895353\n",
      "[1734,     1] loss: 0.004521278664469719\n",
      "[1735,     1] loss: 0.004519790410995483\n",
      "[1736,     1] loss: 0.004517482593655586\n",
      "[1737,     1] loss: 0.004515678156167269\n",
      "[1738,     1] loss: 0.004511959385126829\n",
      "[1739,     1] loss: 0.004506271332502365\n",
      "[1740,     1] loss: 0.0044995564967393875\n",
      "[1741,     1] loss: 0.004492672625929117\n",
      "[1742,     1] loss: 0.004485641606152058\n",
      "[1743,     1] loss: 0.004479037597775459\n",
      "[1744,     1] loss: 0.0044729141518473625\n",
      "[1745,     1] loss: 0.004467246122658253\n",
      "[1746,     1] loss: 0.004462016746401787\n",
      "[1747,     1] loss: 0.004457153379917145\n",
      "[1748,     1] loss: 0.004452376160770655\n",
      "[1749,     1] loss: 0.0044479393400251865\n",
      "[1750,     1] loss: 0.004443895071744919\n",
      "[1751,     1] loss: 0.004440221935510635\n",
      "[1752,     1] loss: 0.00443696603178978\n",
      "[1753,     1] loss: 0.004434175323694944\n",
      "[1754,     1] loss: 0.004431848414242268\n",
      "[1755,     1] loss: 0.004429956898093224\n",
      "[1756,     1] loss: 0.00442830566316843\n",
      "[1757,     1] loss: 0.004426746629178524\n",
      "[1758,     1] loss: 0.0044255563989281654\n",
      "[1759,     1] loss: 0.00442405603826046\n",
      "[1760,     1] loss: 0.0044223591685295105\n",
      "[1761,     1] loss: 0.004420115612447262\n",
      "[1762,     1] loss: 0.004418124444782734\n",
      "[1763,     1] loss: 0.004414611961692572\n",
      "[1764,     1] loss: 0.004410934168845415\n",
      "[1765,     1] loss: 0.004406359978020191\n",
      "[1766,     1] loss: 0.004401005804538727\n",
      "[1767,     1] loss: 0.004395106807351112\n",
      "[1768,     1] loss: 0.00438890652731061\n",
      "[1769,     1] loss: 0.004382790066301823\n",
      "[1770,     1] loss: 0.004376737400889397\n",
      "[1771,     1] loss: 0.004371420480310917\n",
      "[1772,     1] loss: 0.004366545006632805\n",
      "[1773,     1] loss: 0.004362050443887711\n",
      "[1774,     1] loss: 0.004357809200882912\n",
      "[1775,     1] loss: 0.004353746771812439\n",
      "[1776,     1] loss: 0.004349842667579651\n",
      "[1777,     1] loss: 0.00434607919305563\n",
      "[1778,     1] loss: 0.004342470318078995\n",
      "[1779,     1] loss: 0.004339128732681274\n",
      "[1780,     1] loss: 0.0043358467519283295\n",
      "[1781,     1] loss: 0.0043330504558980465\n",
      "[1782,     1] loss: 0.0043310136534273624\n",
      "[1783,     1] loss: 0.004329773131757975\n",
      "[1784,     1] loss: 0.004329347983002663\n",
      "[1785,     1] loss: 0.004330612253397703\n",
      "[1786,     1] loss: 0.0043322378769516945\n",
      "[1787,     1] loss: 0.004334097728133202\n",
      "[1788,     1] loss: 0.004335013218224049\n",
      "[1789,     1] loss: 0.00433633616194129\n",
      "[1790,     1] loss: 0.004335206933319569\n",
      "[1791,     1] loss: 0.004332999233156443\n",
      "[1792,     1] loss: 0.0043276455253362656\n",
      "[1793,     1] loss: 0.004321270622313023\n",
      "[1794,     1] loss: 0.0043133944272994995\n",
      "[1795,     1] loss: 0.004304602742195129\n",
      "[1796,     1] loss: 0.004295006860047579\n",
      "[1797,     1] loss: 0.0042857760563492775\n",
      "[1798,     1] loss: 0.004277550615370274\n",
      "[1799,     1] loss: 0.004270927514880896\n",
      "[1800,     1] loss: 0.004266132600605488\n",
      "[1801,     1] loss: 0.0042634825222194195\n",
      "[1802,     1] loss: 0.00426255539059639\n",
      "[1803,     1] loss: 0.004262910690158606\n",
      "[1804,     1] loss: 0.0042640091851353645\n",
      "[1805,     1] loss: 0.0042646038345992565\n",
      "[1806,     1] loss: 0.004264963790774345\n",
      "[1807,     1] loss: 0.004263818264007568\n",
      "[1808,     1] loss: 0.004262627102434635\n",
      "[1809,     1] loss: 0.004259477369487286\n",
      "[1810,     1] loss: 0.004254685714840889\n",
      "[1811,     1] loss: 0.004247939679771662\n",
      "[1812,     1] loss: 0.004240307491272688\n",
      "[1813,     1] loss: 0.004232084844261408\n",
      "[1814,     1] loss: 0.004224634263664484\n",
      "[1815,     1] loss: 0.004218364134430885\n",
      "[1816,     1] loss: 0.004213383421301842\n",
      "[1817,     1] loss: 0.004209502600133419\n",
      "[1818,     1] loss: 0.0042064618319272995\n",
      "[1819,     1] loss: 0.004204270429909229\n",
      "[1820,     1] loss: 0.004202696960419416\n",
      "[1821,     1] loss: 0.004201763309538364\n",
      "[1822,     1] loss: 0.004201020114123821\n",
      "[1823,     1] loss: 0.004200703464448452\n",
      "[1824,     1] loss: 0.004199948161840439\n",
      "[1825,     1] loss: 0.004199005663394928\n",
      "[1826,     1] loss: 0.004196541383862495\n",
      "[1827,     1] loss: 0.004192831926047802\n",
      "[1828,     1] loss: 0.004187609534710646\n",
      "[1829,     1] loss: 0.004181558266282082\n",
      "[1830,     1] loss: 0.004174394533038139\n",
      "[1831,     1] loss: 0.004167029168456793\n",
      "[1832,     1] loss: 0.0041602300480008125\n",
      "[1833,     1] loss: 0.004154369235038757\n",
      "[1834,     1] loss: 0.0041495393961668015\n",
      "[1835,     1] loss: 0.0041457004845142365\n",
      "[1836,     1] loss: 0.004142507910728455\n",
      "[1837,     1] loss: 0.004139726981520653\n",
      "[1838,     1] loss: 0.004137253388762474\n",
      "[1839,     1] loss: 0.0041349842213094234\n",
      "[1840,     1] loss: 0.004132948350161314\n",
      "[1841,     1] loss: 0.004131305497139692\n",
      "[1842,     1] loss: 0.004130316432565451\n",
      "[1843,     1] loss: 0.004129523411393166\n",
      "[1844,     1] loss: 0.004129596054553986\n",
      "[1845,     1] loss: 0.004129443783313036\n",
      "[1846,     1] loss: 0.004129034001380205\n",
      "[1847,     1] loss: 0.004127868451178074\n",
      "[1848,     1] loss: 0.004125890787690878\n",
      "[1849,     1] loss: 0.00412220461294055\n",
      "[1850,     1] loss: 0.004117695614695549\n",
      "[1851,     1] loss: 0.0041115605272352695\n",
      "[1852,     1] loss: 0.004105082713067532\n",
      "[1853,     1] loss: 0.004097945988178253\n",
      "[1854,     1] loss: 0.004091557115316391\n",
      "[1855,     1] loss: 0.004085180349647999\n",
      "[1856,     1] loss: 0.004079384729266167\n",
      "[1857,     1] loss: 0.004074282478541136\n",
      "[1858,     1] loss: 0.004069754388183355\n",
      "[1859,     1] loss: 0.004066004883497953\n",
      "[1860,     1] loss: 0.004063029773533344\n",
      "[1861,     1] loss: 0.004060642793774605\n",
      "[1862,     1] loss: 0.004058763384819031\n",
      "[1863,     1] loss: 0.004056980833411217\n",
      "[1864,     1] loss: 0.004055286757647991\n",
      "[1865,     1] loss: 0.0040538315661251545\n",
      "[1866,     1] loss: 0.004052955657243729\n",
      "[1867,     1] loss: 0.0040521882474422455\n",
      "[1868,     1] loss: 0.004052270669490099\n",
      "[1869,     1] loss: 0.004052325617522001\n",
      "[1870,     1] loss: 0.004053602926433086\n",
      "[1871,     1] loss: 0.004054907709360123\n",
      "[1872,     1] loss: 0.00405914057046175\n",
      "[1873,     1] loss: 0.004062175285071135\n",
      "[1874,     1] loss: 0.0040678903460502625\n",
      "[1875,     1] loss: 0.004069448448717594\n",
      "[1876,     1] loss: 0.004072320181876421\n",
      "[1877,     1] loss: 0.004066934809088707\n",
      "[1878,     1] loss: 0.0040574525482952595\n",
      "[1879,     1] loss: 0.0040406733751297\n",
      "[1880,     1] loss: 0.0040213726460933685\n",
      "[1881,     1] loss: 0.004003910347819328\n",
      "[1882,     1] loss: 0.003991727717220783\n",
      "[1883,     1] loss: 0.00398609135299921\n",
      "[1884,     1] loss: 0.0039853258058428764\n",
      "[1885,     1] loss: 0.003988094162195921\n",
      "[1886,     1] loss: 0.003991703037172556\n",
      "[1887,     1] loss: 0.003994893282651901\n",
      "[1888,     1] loss: 0.003995614126324654\n",
      "[1889,     1] loss: 0.003993384074419737\n",
      "[1890,     1] loss: 0.003987290430814028\n",
      "[1891,     1] loss: 0.003978756722062826\n",
      "[1892,     1] loss: 0.003968454897403717\n",
      "[1893,     1] loss: 0.0039591314271092415\n",
      "[1894,     1] loss: 0.003951542545109987\n",
      "[1895,     1] loss: 0.003945915028452873\n",
      "[1896,     1] loss: 0.00394248403608799\n",
      "[1897,     1] loss: 0.0039405315183103085\n",
      "[1898,     1] loss: 0.00393966119736433\n",
      "[1899,     1] loss: 0.003939331509172916\n",
      "[1900,     1] loss: 0.0039397128857672215\n",
      "[1901,     1] loss: 0.003939340822398663\n",
      "[1902,     1] loss: 0.003938641399145126\n",
      "[1903,     1] loss: 0.0039365291595458984\n",
      "[1904,     1] loss: 0.00393386697396636\n",
      "[1905,     1] loss: 0.003929941914975643\n",
      "[1906,     1] loss: 0.00392567366361618\n",
      "[1907,     1] loss: 0.003920926712453365\n",
      "[1908,     1] loss: 0.0039158770814538\n",
      "[1909,     1] loss: 0.003910839091986418\n",
      "[1910,     1] loss: 0.003905918449163437\n",
      "[1911,     1] loss: 0.00390100060030818\n",
      "[1912,     1] loss: 0.0038960264064371586\n",
      "[1913,     1] loss: 0.003891028929501772\n",
      "[1914,     1] loss: 0.0038864435628056526\n",
      "[1915,     1] loss: 0.0038825757801532745\n",
      "[1916,     1] loss: 0.0038793059065937996\n",
      "[1917,     1] loss: 0.0038765924982726574\n",
      "[1918,     1] loss: 0.003874048124998808\n",
      "[1919,     1] loss: 0.003871477209031582\n",
      "[1920,     1] loss: 0.00386865995824337\n",
      "[1921,     1] loss: 0.003865580540150404\n",
      "[1922,     1] loss: 0.0038625593297183514\n",
      "[1923,     1] loss: 0.0038603516295552254\n",
      "[1924,     1] loss: 0.003858833573758602\n",
      "[1925,     1] loss: 0.00385850528255105\n",
      "[1926,     1] loss: 0.003858937183395028\n",
      "[1927,     1] loss: 0.0038613490760326385\n",
      "[1928,     1] loss: 0.003864743746817112\n",
      "[1929,     1] loss: 0.003871586639434099\n",
      "[1930,     1] loss: 0.0038778576999902725\n",
      "[1931,     1] loss: 0.00388655299320817\n",
      "[1932,     1] loss: 0.003891326952725649\n",
      "[1933,     1] loss: 0.003896324662491679\n",
      "[1934,     1] loss: 0.0038931979797780514\n",
      "[1935,     1] loss: 0.0038877795450389385\n",
      "[1936,     1] loss: 0.003873272333294153\n",
      "[1937,     1] loss: 0.003856522962450981\n",
      "[1938,     1] loss: 0.003838406875729561\n",
      "[1939,     1] loss: 0.003824114566668868\n",
      "[1940,     1] loss: 0.003815152682363987\n",
      "[1941,     1] loss: 0.0038116835057735443\n",
      "[1942,     1] loss: 0.0038127806037664413\n",
      "[1943,     1] loss: 0.0038169785402715206\n",
      "[1944,     1] loss: 0.0038235436659306288\n",
      "[1945,     1] loss: 0.003830480854958296\n",
      "[1946,     1] loss: 0.0038370671682059765\n",
      "[1947,     1] loss: 0.0038410923443734646\n",
      "[1948,     1] loss: 0.0038414576556533575\n",
      "[1949,     1] loss: 0.003835266223177314\n",
      "[1950,     1] loss: 0.0038221380673348904\n",
      "[1951,     1] loss: 0.003804287873208523\n",
      "[1952,     1] loss: 0.003787008114159107\n",
      "[1953,     1] loss: 0.003775090677663684\n",
      "[1954,     1] loss: 0.0037700477987527847\n",
      "[1955,     1] loss: 0.003769534407183528\n",
      "[1956,     1] loss: 0.0037702112458646297\n",
      "[1957,     1] loss: 0.003769650822505355\n",
      "[1958,     1] loss: 0.0037673828192055225\n",
      "[1959,     1] loss: 0.003765460103750229\n",
      "[1960,     1] loss: 0.0037644258700311184\n",
      "[1961,     1] loss: 0.0037657369393855333\n",
      "[1962,     1] loss: 0.0037660948000848293\n",
      "[1963,     1] loss: 0.0037657178472727537\n",
      "[1964,     1] loss: 0.003762217005714774\n",
      "[1965,     1] loss: 0.0037574335001409054\n",
      "[1966,     1] loss: 0.0037518725730478764\n",
      "[1967,     1] loss: 0.0037465780042111874\n",
      "[1968,     1] loss: 0.0037410815712064505\n",
      "[1969,     1] loss: 0.0037352736108005047\n",
      "[1970,     1] loss: 0.0037288598250597715\n",
      "[1971,     1] loss: 0.0037228427827358246\n",
      "[1972,     1] loss: 0.003717748448252678\n",
      "[1973,     1] loss: 0.003713574493303895\n",
      "[1974,     1] loss: 0.00371012301184237\n",
      "[1975,     1] loss: 0.003707088530063629\n",
      "[1976,     1] loss: 0.0037043578922748566\n",
      "[1977,     1] loss: 0.003701981157064438\n",
      "[1978,     1] loss: 0.0037001636810600758\n",
      "[1979,     1] loss: 0.003699027933180332\n",
      "[1980,     1] loss: 0.0036989443469792604\n",
      "[1981,     1] loss: 0.0036991992965340614\n",
      "[1982,     1] loss: 0.0037000018637627363\n",
      "[1983,     1] loss: 0.0037007825449109077\n",
      "[1984,     1] loss: 0.003702288493514061\n",
      "[1985,     1] loss: 0.0037032850086688995\n",
      "[1986,     1] loss: 0.0037040975876152515\n",
      "[1987,     1] loss: 0.0037035024724900723\n",
      "[1988,     1] loss: 0.003703575348481536\n",
      "[1989,     1] loss: 0.0037009725347161293\n",
      "[1990,     1] loss: 0.003697639796882868\n",
      "[1991,     1] loss: 0.0036919056437909603\n",
      "[1992,     1] loss: 0.003686432493850589\n",
      "[1993,     1] loss: 0.00367934163659811\n",
      "[1994,     1] loss: 0.0036715958267450333\n",
      "[1995,     1] loss: 0.003662948263809085\n",
      "[1996,     1] loss: 0.003655039705336094\n",
      "[1997,     1] loss: 0.0036487909965217113\n",
      "[1998,     1] loss: 0.0036441537085920572\n",
      "[1999,     1] loss: 0.0036411636974662542\n",
      "[2000,     1] loss: 0.003639349713921547\n",
      "[2001,     1] loss: 0.0036385729908943176\n",
      "[2002,     1] loss: 0.0036390768364071846\n",
      "[2003,     1] loss: 0.003640605602413416\n",
      "[2004,     1] loss: 0.0036434733774513006\n",
      "[2005,     1] loss: 0.003647398203611374\n",
      "[2006,     1] loss: 0.0036515265237540007\n",
      "[2007,     1] loss: 0.0036564453039318323\n",
      "[2008,     1] loss: 0.00366011168807745\n",
      "[2009,     1] loss: 0.0036661589983850718\n",
      "[2010,     1] loss: 0.0036681490018963814\n",
      "[2011,     1] loss: 0.0036678193137049675\n",
      "[2012,     1] loss: 0.00366128608584404\n",
      "[2013,     1] loss: 0.0036515677347779274\n",
      "[2014,     1] loss: 0.0036375392228364944\n",
      "[2015,     1] loss: 0.0036225011572241783\n",
      "[2016,     1] loss: 0.0036089010536670685\n",
      "[2017,     1] loss: 0.00359882740303874\n",
      "[2018,     1] loss: 0.003593365428969264\n",
      "[2019,     1] loss: 0.0035915025509893894\n",
      "[2020,     1] loss: 0.0035923824179917574\n",
      "[2021,     1] loss: 0.0035952008329331875\n",
      "[2022,     1] loss: 0.0035994909703731537\n",
      "[2023,     1] loss: 0.0036038076505064964\n",
      "[2024,     1] loss: 0.0036086293403059244\n",
      "[2025,     1] loss: 0.003611953230574727\n",
      "[2026,     1] loss: 0.0036141257733106613\n",
      "[2027,     1] loss: 0.0036130419466644526\n",
      "[2028,     1] loss: 0.0036093401722609997\n",
      "[2029,     1] loss: 0.0036008975002914667\n",
      "[2030,     1] loss: 0.0035909470170736313\n",
      "[2031,     1] loss: 0.0035794139839708805\n",
      "[2032,     1] loss: 0.0035684409085661173\n",
      "[2033,     1] loss: 0.003559071570634842\n",
      "[2034,     1] loss: 0.003552091773599386\n",
      "[2035,     1] loss: 0.0035477732308208942\n",
      "[2036,     1] loss: 0.0035459480714052916\n",
      "[2037,     1] loss: 0.003546373452991247\n",
      "[2038,     1] loss: 0.0035480386577546597\n",
      "[2039,     1] loss: 0.003550372552126646\n",
      "[2040,     1] loss: 0.0035525672137737274\n",
      "[2041,     1] loss: 0.0035565027501434088\n",
      "[2042,     1] loss: 0.0035593141801655293\n",
      "[2043,     1] loss: 0.0035626129247248173\n",
      "[2044,     1] loss: 0.0035633984953165054\n",
      "[2045,     1] loss: 0.0035640799906104803\n",
      "[2046,     1] loss: 0.0035607265308499336\n",
      "[2047,     1] loss: 0.0035568708553910255\n",
      "[2048,     1] loss: 0.0035484719555824995\n",
      "[2049,     1] loss: 0.0035402001813054085\n",
      "[2050,     1] loss: 0.0035293172113597393\n",
      "[2051,     1] loss: 0.0035190642811357975\n",
      "[2052,     1] loss: 0.0035106386058032513\n",
      "[2053,     1] loss: 0.0035048192366957664\n",
      "[2054,     1] loss: 0.0035013866145163774\n",
      "[2055,     1] loss: 0.003499948652461171\n",
      "[2056,     1] loss: 0.0035000117495656013\n",
      "[2057,     1] loss: 0.003500762628391385\n",
      "[2058,     1] loss: 0.0035025840625166893\n",
      "[2059,     1] loss: 0.0035045547410845757\n",
      "[2060,     1] loss: 0.0035074795596301556\n",
      "[2061,     1] loss: 0.0035092425532639027\n",
      "[2062,     1] loss: 0.003512532217428088\n",
      "[2063,     1] loss: 0.0035135801881551743\n",
      "[2064,     1] loss: 0.0035152817144989967\n",
      "[2065,     1] loss: 0.003513767383992672\n",
      "[2066,     1] loss: 0.0035114241763949394\n",
      "[2067,     1] loss: 0.0035061475355178118\n",
      "[2068,     1] loss: 0.00350112933665514\n",
      "[2069,     1] loss: 0.003492648946121335\n",
      "[2070,     1] loss: 0.0034843028988689184\n",
      "[2071,     1] loss: 0.003474034368991852\n",
      "[2072,     1] loss: 0.0034647739958018064\n",
      "[2073,     1] loss: 0.003457035403698683\n",
      "[2074,     1] loss: 0.0034517343156039715\n",
      "[2075,     1] loss: 0.0034482753835618496\n",
      "[2076,     1] loss: 0.0034462912008166313\n",
      "[2077,     1] loss: 0.0034454779233783484\n",
      "[2078,     1] loss: 0.0034455349668860435\n",
      "[2079,     1] loss: 0.0034469778183847666\n",
      "[2080,     1] loss: 0.0034492993727326393\n",
      "[2081,     1] loss: 0.0034529566764831543\n",
      "[2082,     1] loss: 0.00345650059171021\n",
      "[2083,     1] loss: 0.0034609490539878607\n",
      "[2084,     1] loss: 0.0034645716659724712\n",
      "[2085,     1] loss: 0.0034680161625146866\n",
      "[2086,     1] loss: 0.0034693172201514244\n",
      "[2087,     1] loss: 0.003471109550446272\n",
      "[2088,     1] loss: 0.0034689665772020817\n",
      "[2089,     1] loss: 0.003466802416369319\n",
      "[2090,     1] loss: 0.0034587918780744076\n",
      "[2091,     1] loss: 0.003449260024353862\n",
      "[2092,     1] loss: 0.003436099039390683\n",
      "[2093,     1] loss: 0.0034231182653456926\n",
      "[2094,     1] loss: 0.00341146532446146\n",
      "[2095,     1] loss: 0.003402895759791136\n",
      "[2096,     1] loss: 0.003397424006834626\n",
      "[2097,     1] loss: 0.003394374391064048\n",
      "[2098,     1] loss: 0.0033931832294911146\n",
      "[2099,     1] loss: 0.003393419785425067\n",
      "[2100,     1] loss: 0.003394841682165861\n",
      "[2101,     1] loss: 0.0033973101526498795\n",
      "[2102,     1] loss: 0.0034015171695500612\n",
      "[2103,     1] loss: 0.003405502298846841\n",
      "[2104,     1] loss: 0.003411598037928343\n",
      "[2105,     1] loss: 0.003416153835132718\n",
      "[2106,     1] loss: 0.0034240090753883123\n",
      "[2107,     1] loss: 0.0034281706903129816\n",
      "[2108,     1] loss: 0.0034335891250520945\n",
      "[2109,     1] loss: 0.0034325718879699707\n",
      "[2110,     1] loss: 0.0034296612720936537\n",
      "[2111,     1] loss: 0.0034203161485493183\n",
      "[2112,     1] loss: 0.003408911405131221\n",
      "[2113,     1] loss: 0.0033937504049390554\n",
      "[2114,     1] loss: 0.0033795656636357307\n",
      "[2115,     1] loss: 0.0033680791966617107\n",
      "[2116,     1] loss: 0.0033609133679419756\n",
      "[2117,     1] loss: 0.0033577322028577328\n",
      "[2118,     1] loss: 0.0033576530404388905\n",
      "[2119,     1] loss: 0.003359654452651739\n",
      "[2120,     1] loss: 0.0033628984820097685\n",
      "[2121,     1] loss: 0.0033672829158604145\n",
      "[2122,     1] loss: 0.0033714494202286005\n",
      "[2123,     1] loss: 0.0033751383889466524\n",
      "[2124,     1] loss: 0.0033756650518625975\n",
      "[2125,     1] loss: 0.0033742429222911596\n",
      "[2126,     1] loss: 0.0033692042343318462\n",
      "[2127,     1] loss: 0.0033653422724455595\n",
      "[2128,     1] loss: 0.0033598882146179676\n",
      "[2129,     1] loss: 0.0033570320811122656\n",
      "[2130,     1] loss: 0.003352528903633356\n",
      "[2131,     1] loss: 0.003346972167491913\n",
      "[2132,     1] loss: 0.0033392913173884153\n",
      "[2133,     1] loss: 0.003331673564389348\n",
      "[2134,     1] loss: 0.003323707962408662\n",
      "[2135,     1] loss: 0.003316414076834917\n",
      "[2136,     1] loss: 0.003310498083010316\n",
      "[2137,     1] loss: 0.003306065686047077\n",
      "[2138,     1] loss: 0.0033028258476406336\n",
      "[2139,     1] loss: 0.0033008551690727472\n",
      "[2140,     1] loss: 0.003300255164504051\n",
      "[2141,     1] loss: 0.0033007452730089426\n",
      "[2142,     1] loss: 0.0033029974438250065\n",
      "[2143,     1] loss: 0.003306542756035924\n",
      "[2144,     1] loss: 0.0033148499205708504\n",
      "[2145,     1] loss: 0.0033239847980439663\n",
      "[2146,     1] loss: 0.003337185364216566\n",
      "[2147,     1] loss: 0.003348741214722395\n",
      "[2148,     1] loss: 0.0033631459809839725\n",
      "[2149,     1] loss: 0.0033700454514473677\n",
      "[2150,     1] loss: 0.003375748172402382\n",
      "[2151,     1] loss: 0.003369338344782591\n",
      "[2152,     1] loss: 0.0033575803972780704\n",
      "[2153,     1] loss: 0.0033350372686982155\n",
      "[2154,     1] loss: 0.003310099709779024\n",
      "[2155,     1] loss: 0.003285539336502552\n",
      "[2156,     1] loss: 0.0032678053248673677\n",
      "[2157,     1] loss: 0.0032587999012321234\n",
      "[2158,     1] loss: 0.003257778473198414\n",
      "[2159,     1] loss: 0.0032626616302877665\n",
      "[2160,     1] loss: 0.003270362503826618\n",
      "[2161,     1] loss: 0.0032788882963359356\n",
      "[2162,     1] loss: 0.0032850245479494333\n",
      "[2163,     1] loss: 0.0032899719662964344\n",
      "[2164,     1] loss: 0.0032891228329390287\n",
      "[2165,     1] loss: 0.0032870396971702576\n",
      "[2166,     1] loss: 0.0032794640865176916\n",
      "[2167,     1] loss: 0.0032710013911128044\n",
      "[2168,     1] loss: 0.003259775461629033\n",
      "[2169,     1] loss: 0.003249588655307889\n",
      "[2170,     1] loss: 0.003239766927435994\n",
      "[2171,     1] loss: 0.0032320069149136543\n",
      "[2172,     1] loss: 0.0032262231688946486\n",
      "[2173,     1] loss: 0.0032223425805568695\n",
      "[2174,     1] loss: 0.0032200668938457966\n",
      "[2175,     1] loss: 0.00321918074041605\n",
      "[2176,     1] loss: 0.003219534642994404\n",
      "[2177,     1] loss: 0.0032207919284701347\n",
      "[2178,     1] loss: 0.0032242275774478912\n",
      "[2179,     1] loss: 0.0032282480970025063\n",
      "[2180,     1] loss: 0.0032349620014429092\n",
      "[2181,     1] loss: 0.003242264501750469\n",
      "[2182,     1] loss: 0.003252684138715267\n",
      "[2183,     1] loss: 0.0032607493922114372\n",
      "[2184,     1] loss: 0.0032700246665626764\n",
      "[2185,     1] loss: 0.0032732482068240643\n",
      "[2186,     1] loss: 0.003275992814451456\n",
      "[2187,     1] loss: 0.003270516637712717\n",
      "[2188,     1] loss: 0.0032614502124488354\n",
      "[2189,     1] loss: 0.003244952764362097\n",
      "[2190,     1] loss: 0.0032263314351439476\n",
      "[2191,     1] loss: 0.003207834903150797\n",
      "[2192,     1] loss: 0.0031934394501149654\n",
      "[2193,     1] loss: 0.0031847390346229076\n",
      "[2194,     1] loss: 0.0031814987305551767\n",
      "[2195,     1] loss: 0.003182158339768648\n",
      "[2196,     1] loss: 0.003185122273862362\n",
      "[2197,     1] loss: 0.0031895977444946766\n",
      "[2198,     1] loss: 0.003193699987605214\n",
      "[2199,     1] loss: 0.0031978213228285313\n",
      "[2200,     1] loss: 0.0031990462448447943\n",
      "[2201,     1] loss: 0.003202285384759307\n",
      "[2202,     1] loss: 0.0032032642047852278\n",
      "[2203,     1] loss: 0.0032044381368905306\n",
      "[2204,     1] loss: 0.003200630657374859\n",
      "[2205,     1] loss: 0.003196380101144314\n",
      "[2206,     1] loss: 0.003186906222254038\n",
      "[2207,     1] loss: 0.0031771177891641855\n",
      "[2208,     1] loss: 0.0031654073391109705\n",
      "[2209,     1] loss: 0.0031544577796012163\n",
      "[2210,     1] loss: 0.0031460376922041178\n",
      "[2211,     1] loss: 0.003140869550406933\n",
      "[2212,     1] loss: 0.003138529136776924\n",
      "[2213,     1] loss: 0.003138170810416341\n",
      "[2214,     1] loss: 0.0031395400874316692\n",
      "[2215,     1] loss: 0.0031418935395777225\n",
      "[2216,     1] loss: 0.003145793220028281\n",
      "[2217,     1] loss: 0.003151294309645891\n",
      "[2218,     1] loss: 0.0031595639884471893\n",
      "[2219,     1] loss: 0.003169800154864788\n",
      "[2220,     1] loss: 0.0031833641696721315\n",
      "[2221,     1] loss: 0.003195126773789525\n",
      "[2222,     1] loss: 0.0032102903351187706\n",
      "[2223,     1] loss: 0.00321424868889153\n",
      "[2224,     1] loss: 0.0032151960767805576\n",
      "[2225,     1] loss: 0.003201964544132352\n",
      "[2226,     1] loss: 0.0031849707011133432\n",
      "[2227,     1] loss: 0.0031598578207194805\n",
      "[2228,     1] loss: 0.003136713756248355\n",
      "[2229,     1] loss: 0.0031181734520941973\n",
      "[2230,     1] loss: 0.0031083892099559307\n",
      "[2231,     1] loss: 0.0031068362295627594\n",
      "[2232,     1] loss: 0.0031105210073292255\n",
      "[2233,     1] loss: 0.003117244690656662\n",
      "[2234,     1] loss: 0.0031236158683896065\n",
      "[2235,     1] loss: 0.003131002653390169\n",
      "[2236,     1] loss: 0.0031334382947534323\n",
      "[2237,     1] loss: 0.0031347856856882572\n",
      "[2238,     1] loss: 0.0031307023018598557\n",
      "[2239,     1] loss: 0.0031246659345924854\n",
      "[2240,     1] loss: 0.0031142327934503555\n",
      "[2241,     1] loss: 0.003103504190221429\n",
      "[2242,     1] loss: 0.0030921497382223606\n",
      "[2243,     1] loss: 0.0030835226643830538\n",
      "[2244,     1] loss: 0.00307724392041564\n",
      "[2245,     1] loss: 0.003073712345212698\n",
      "[2246,     1] loss: 0.0030724904499948025\n",
      "[2247,     1] loss: 0.0030725407414138317\n",
      "[2248,     1] loss: 0.003072819672524929\n",
      "[2249,     1] loss: 0.003072815714403987\n",
      "[2250,     1] loss: 0.003073552856221795\n",
      "[2251,     1] loss: 0.003074771026149392\n",
      "[2252,     1] loss: 0.0030787040013819933\n",
      "[2253,     1] loss: 0.0030828858725726604\n",
      "[2254,     1] loss: 0.003088470082730055\n",
      "[2255,     1] loss: 0.003093411447480321\n",
      "[2256,     1] loss: 0.0030994992703199387\n",
      "[2257,     1] loss: 0.0031014527194201946\n",
      "[2258,     1] loss: 0.0031026138458400965\n",
      "[2259,     1] loss: 0.003097856417298317\n",
      "[2260,     1] loss: 0.003092760918661952\n",
      "[2261,     1] loss: 0.0030827911105006933\n",
      "[2262,     1] loss: 0.003072223626077175\n",
      "[2263,     1] loss: 0.0030605641659349203\n",
      "[2264,     1] loss: 0.003049465361982584\n",
      "[2265,     1] loss: 0.003040386363863945\n",
      "[2266,     1] loss: 0.0030341376550495625\n",
      "[2267,     1] loss: 0.0030303250532597303\n",
      "[2268,     1] loss: 0.0030284966342151165\n",
      "[2269,     1] loss: 0.0030283075757324696\n",
      "[2270,     1] loss: 0.003029346000403166\n",
      "[2271,     1] loss: 0.0030328803695738316\n",
      "[2272,     1] loss: 0.0030378333758562803\n",
      "[2273,     1] loss: 0.0030466518364846706\n",
      "[2274,     1] loss: 0.0030567022040486336\n",
      "[2275,     1] loss: 0.0030711551662534475\n",
      "[2276,     1] loss: 0.003081678180024028\n",
      "[2277,     1] loss: 0.0030940407887101173\n",
      "[2278,     1] loss: 0.0030988550279289484\n",
      "[2279,     1] loss: 0.0031018818262964487\n",
      "[2280,     1] loss: 0.0030945162288844585\n",
      "[2281,     1] loss: 0.0030820332467556\n",
      "[2282,     1] loss: 0.003060614690184593\n",
      "[2283,     1] loss: 0.0030382501427084208\n",
      "[2284,     1] loss: 0.003016384318470955\n",
      "[2285,     1] loss: 0.002999585121870041\n",
      "[2286,     1] loss: 0.002989585977047682\n",
      "[2287,     1] loss: 0.002986298408359289\n",
      "[2288,     1] loss: 0.002987982938066125\n",
      "[2289,     1] loss: 0.002992679364979267\n",
      "[2290,     1] loss: 0.003000312950462103\n",
      "[2291,     1] loss: 0.003007792169228196\n",
      "[2292,     1] loss: 0.0030157926958054304\n",
      "[2293,     1] loss: 0.0030211959965527058\n",
      "[2294,     1] loss: 0.0030250363051891327\n",
      "[2295,     1] loss: 0.00302318949252367\n",
      "[2296,     1] loss: 0.0030192164704203606\n",
      "[2297,     1] loss: 0.003009258070960641\n",
      "[2298,     1] loss: 0.0029999068938195705\n",
      "[2299,     1] loss: 0.002988047432154417\n",
      "[2300,     1] loss: 0.002976768184453249\n",
      "[2301,     1] loss: 0.0029666293412446976\n",
      "[2302,     1] loss: 0.002959080506116152\n",
      "[2303,     1] loss: 0.002954459050670266\n",
      "[2304,     1] loss: 0.0029524103738367558\n",
      "[2305,     1] loss: 0.0029524005949497223\n",
      "[2306,     1] loss: 0.002953888615593314\n",
      "[2307,     1] loss: 0.0029578690882772207\n",
      "[2308,     1] loss: 0.0029627869371324778\n",
      "[2309,     1] loss: 0.0029696279671043158\n",
      "[2310,     1] loss: 0.0029751965776085854\n",
      "[2311,     1] loss: 0.002981491619721055\n",
      "[2312,     1] loss: 0.002985375700518489\n",
      "[2313,     1] loss: 0.002990715904161334\n",
      "[2314,     1] loss: 0.0029914446640759706\n",
      "[2315,     1] loss: 0.002991550136357546\n",
      "[2316,     1] loss: 0.0029866660479456186\n",
      "[2317,     1] loss: 0.002981795696541667\n",
      "[2318,     1] loss: 0.002971908077597618\n",
      "[2319,     1] loss: 0.002961130812764168\n",
      "[2320,     1] loss: 0.00294746202416718\n",
      "[2321,     1] loss: 0.002935257740318775\n",
      "[2322,     1] loss: 0.0029242809396237135\n",
      "[2323,     1] loss: 0.002915984485298395\n",
      "[2324,     1] loss: 0.0029109176248311996\n",
      "[2325,     1] loss: 0.0029083776753395796\n",
      "[2326,     1] loss: 0.0029073874466121197\n",
      "[2327,     1] loss: 0.002907943446189165\n",
      "[2328,     1] loss: 0.0029098601080477238\n",
      "[2329,     1] loss: 0.002913213102146983\n",
      "[2330,     1] loss: 0.002917597535997629\n",
      "[2331,     1] loss: 0.0029233088716864586\n",
      "[2332,     1] loss: 0.0029305615462362766\n",
      "[2333,     1] loss: 0.0029378202743828297\n",
      "[2334,     1] loss: 0.0029472941532731056\n",
      "[2335,     1] loss: 0.0029556634835898876\n",
      "[2336,     1] loss: 0.002964584855362773\n",
      "[2337,     1] loss: 0.0029680223669856787\n",
      "[2338,     1] loss: 0.002972965594381094\n",
      "[2339,     1] loss: 0.0029710205271840096\n",
      "[2340,     1] loss: 0.0029668251518160105\n",
      "[2341,     1] loss: 0.0029551300685852766\n",
      "[2342,     1] loss: 0.0029417036566883326\n",
      "[2343,     1] loss: 0.002922931220382452\n",
      "[2344,     1] loss: 0.0029042442329227924\n",
      "[2345,     1] loss: 0.0028878299053758383\n",
      "[2346,     1] loss: 0.0028762691654264927\n",
      "[2347,     1] loss: 0.002870479365810752\n",
      "[2348,     1] loss: 0.0028695384971797466\n",
      "[2349,     1] loss: 0.0028720195405185223\n",
      "[2350,     1] loss: 0.0028765839524567127\n",
      "[2351,     1] loss: 0.0028824293985962868\n",
      "[2352,     1] loss: 0.0028887244407087564\n",
      "[2353,     1] loss: 0.0028972942382097244\n",
      "[2354,     1] loss: 0.002905280562117696\n",
      "[2355,     1] loss: 0.0029136890079826117\n",
      "[2356,     1] loss: 0.0029178964905440807\n",
      "[2357,     1] loss: 0.002919896738603711\n",
      "[2358,     1] loss: 0.0029157917015254498\n",
      "[2359,     1] loss: 0.0029099814128130674\n",
      "[2360,     1] loss: 0.0028999983333051205\n",
      "[2361,     1] loss: 0.002888201270252466\n",
      "[2362,     1] loss: 0.0028744784649461508\n",
      "[2363,     1] loss: 0.00286213424988091\n",
      "[2364,     1] loss: 0.0028494643047451973\n",
      "[2365,     1] loss: 0.002838857239112258\n",
      "[2366,     1] loss: 0.002830782439559698\n",
      "[2367,     1] loss: 0.002826044335961342\n",
      "[2368,     1] loss: 0.0028238659724593163\n",
      "[2369,     1] loss: 0.0028237290680408478\n",
      "[2370,     1] loss: 0.002825571224093437\n",
      "[2371,     1] loss: 0.0028290555346757174\n",
      "[2372,     1] loss: 0.0028340397402644157\n",
      "[2373,     1] loss: 0.0028413133695721626\n",
      "[2374,     1] loss: 0.0028515695594251156\n",
      "[2375,     1] loss: 0.0028636695351451635\n",
      "[2376,     1] loss: 0.00287883123382926\n",
      "[2377,     1] loss: 0.002893920987844467\n",
      "[2378,     1] loss: 0.0029141150880604982\n",
      "[2379,     1] loss: 0.0029288853984326124\n",
      "[2380,     1] loss: 0.0029445230029523373\n",
      "[2381,     1] loss: 0.002943852450698614\n",
      "[2382,     1] loss: 0.002934760181233287\n",
      "[2383,     1] loss: 0.002910091308876872\n",
      "[2384,     1] loss: 0.0028783930465579033\n",
      "[2385,     1] loss: 0.0028433697298169136\n",
      "[2386,     1] loss: 0.0028148700948804617\n",
      "[2387,     1] loss: 0.0027965018525719643\n",
      "[2388,     1] loss: 0.0027886920142918825\n",
      "[2389,     1] loss: 0.0027897809632122517\n",
      "[2390,     1] loss: 0.002796903718262911\n",
      "[2391,     1] loss: 0.002806904027238488\n",
      "[2392,     1] loss: 0.002817037282511592\n",
      "[2393,     1] loss: 0.0028264219872653484\n",
      "[2394,     1] loss: 0.0028320776764303446\n",
      "[2395,     1] loss: 0.0028344783931970596\n",
      "[2396,     1] loss: 0.002830208744853735\n",
      "[2397,     1] loss: 0.0028223562985658646\n",
      "[2398,     1] loss: 0.0028104414232075214\n",
      "[2399,     1] loss: 0.0027967740315943956\n",
      "[2400,     1] loss: 0.0027831867337226868\n",
      "[2401,     1] loss: 0.0027714925818145275\n",
      "[2402,     1] loss: 0.0027633095160126686\n",
      "[2403,     1] loss: 0.002758174203336239\n",
      "[2404,     1] loss: 0.0027558142319321632\n",
      "[2405,     1] loss: 0.0027556568384170532\n",
      "[2406,     1] loss: 0.0027578789740800858\n",
      "[2407,     1] loss: 0.0027622943744063377\n",
      "[2408,     1] loss: 0.002769242972135544\n",
      "[2409,     1] loss: 0.0027774234768003225\n",
      "[2410,     1] loss: 0.002788694342598319\n",
      "[2411,     1] loss: 0.0027986287605017424\n",
      "[2412,     1] loss: 0.002810889622196555\n",
      "[2413,     1] loss: 0.002821058966219425\n",
      "[2414,     1] loss: 0.002835022285580635\n",
      "[2415,     1] loss: 0.0028423501644283533\n",
      "[2416,     1] loss: 0.0028479050379246473\n",
      "[2417,     1] loss: 0.0028412379324436188\n",
      "[2418,     1] loss: 0.0028283207211643457\n",
      "[2419,     1] loss: 0.0028085147496312857\n",
      "[2420,     1] loss: 0.0027863492723554373\n",
      "[2421,     1] loss: 0.002762530231848359\n",
      "[2422,     1] loss: 0.0027427831664681435\n",
      "[2423,     1] loss: 0.0027289018034934998\n",
      "[2424,     1] loss: 0.0027211206033825874\n",
      "[2425,     1] loss: 0.0027185077778995037\n",
      "[2426,     1] loss: 0.002719490323215723\n",
      "[2427,     1] loss: 0.002723678480833769\n",
      "[2428,     1] loss: 0.002729572355747223\n",
      "[2429,     1] loss: 0.0027363160625100136\n",
      "[2430,     1] loss: 0.002743093529716134\n",
      "[2431,     1] loss: 0.002750308020040393\n",
      "[2432,     1] loss: 0.00275596184656024\n",
      "[2433,     1] loss: 0.002763516968116164\n",
      "[2434,     1] loss: 0.0027649570256471634\n",
      "[2435,     1] loss: 0.002768482081592083\n",
      "[2436,     1] loss: 0.002766733756288886\n",
      "[2437,     1] loss: 0.0027627814561128616\n",
      "[2438,     1] loss: 0.002753314794972539\n",
      "[2439,     1] loss: 0.002741970121860504\n",
      "[2440,     1] loss: 0.0027270475402474403\n",
      "[2441,     1] loss: 0.002713174559175968\n",
      "[2442,     1] loss: 0.0027016964741051197\n",
      "[2443,     1] loss: 0.002694090362638235\n",
      "[2444,     1] loss: 0.002690054476261139\n",
      "[2445,     1] loss: 0.0026893424801528454\n",
      "[2446,     1] loss: 0.002691479865461588\n",
      "[2447,     1] loss: 0.002696023788303137\n",
      "[2448,     1] loss: 0.0027024501468986273\n",
      "[2449,     1] loss: 0.0027100888546556234\n",
      "[2450,     1] loss: 0.0027185045182704926\n",
      "[2451,     1] loss: 0.0027257222682237625\n",
      "[2452,     1] loss: 0.0027320964727550745\n",
      "[2453,     1] loss: 0.002736670896410942\n",
      "[2454,     1] loss: 0.0027452639769762754\n",
      "[2455,     1] loss: 0.002753147156909108\n",
      "[2456,     1] loss: 0.002766435034573078\n",
      "[2457,     1] loss: 0.002772650681436062\n",
      "[2458,     1] loss: 0.002780195791274309\n",
      "[2459,     1] loss: 0.0027780786622315645\n",
      "[2460,     1] loss: 0.00277513824403286\n",
      "[2461,     1] loss: 0.002761359792202711\n",
      "[2462,     1] loss: 0.002739743795245886\n",
      "[2463,     1] loss: 0.0027138523291796446\n",
      "[2464,     1] loss: 0.002689340151846409\n",
      "[2465,     1] loss: 0.002668856643140316\n",
      "[2466,     1] loss: 0.002654239535331726\n",
      "[2467,     1] loss: 0.002646584529429674\n",
      "[2468,     1] loss: 0.0026453929021954536\n",
      "[2469,     1] loss: 0.002648778725415468\n",
      "[2470,     1] loss: 0.0026553948409855366\n",
      "[2471,     1] loss: 0.0026638435665518045\n",
      "[2472,     1] loss: 0.0026727733202278614\n",
      "[2473,     1] loss: 0.002681249985471368\n",
      "[2474,     1] loss: 0.002687981352210045\n",
      "[2475,     1] loss: 0.002694013761356473\n",
      "[2476,     1] loss: 0.002696654759347439\n",
      "[2477,     1] loss: 0.0026971036568284035\n",
      "[2478,     1] loss: 0.002691051224246621\n",
      "[2479,     1] loss: 0.0026820264756679535\n",
      "[2480,     1] loss: 0.0026688016951084137\n",
      "[2481,     1] loss: 0.002654836280271411\n",
      "[2482,     1] loss: 0.0026411425787955523\n",
      "[2483,     1] loss: 0.0026290821842849255\n",
      "[2484,     1] loss: 0.0026197582483291626\n",
      "[2485,     1] loss: 0.002613288816064596\n",
      "[2486,     1] loss: 0.0026090708561241627\n",
      "[2487,     1] loss: 0.002606629393994808\n",
      "[2488,     1] loss: 0.0026057546492666006\n",
      "[2489,     1] loss: 0.0026063972618430853\n",
      "[2490,     1] loss: 0.0026086303405463696\n",
      "[2491,     1] loss: 0.0026125863660126925\n",
      "[2492,     1] loss: 0.002618188504129648\n",
      "[2493,     1] loss: 0.0026256951969116926\n",
      "[2494,     1] loss: 0.002636181889101863\n",
      "[2495,     1] loss: 0.0026481295935809612\n",
      "[2496,     1] loss: 0.0026652158703655005\n",
      "[2497,     1] loss: 0.0026798176113516092\n",
      "[2498,     1] loss: 0.0026983392890542746\n",
      "[2499,     1] loss: 0.002710502129048109\n",
      "[2500,     1] loss: 0.002723504090681672\n",
      "[2501,     1] loss: 0.0027238233014941216\n",
      "[2502,     1] loss: 0.0027235914021730423\n",
      "[2503,     1] loss: 0.002709487918764353\n",
      "[2504,     1] loss: 0.0026876702904701233\n",
      "[2505,     1] loss: 0.0026581399142742157\n",
      "[2506,     1] loss: 0.002627923619002104\n",
      "[2507,     1] loss: 0.0026005664840340614\n",
      "[2508,     1] loss: 0.002581410575658083\n",
      "[2509,     1] loss: 0.002571800723671913\n",
      "[2510,     1] loss: 0.0025713182985782623\n",
      "[2511,     1] loss: 0.0025777227710932493\n",
      "[2512,     1] loss: 0.0025880704633891582\n",
      "[2513,     1] loss: 0.0026004547253251076\n",
      "[2514,     1] loss: 0.0026101914700120687\n",
      "[2515,     1] loss: 0.002619838807731867\n",
      "[2516,     1] loss: 0.0026234155520796776\n",
      "[2517,     1] loss: 0.002625454217195511\n",
      "[2518,     1] loss: 0.0026206793263554573\n",
      "[2519,     1] loss: 0.002611708827316761\n",
      "[2520,     1] loss: 0.0025993548333644867\n",
      "[2521,     1] loss: 0.002586426679044962\n",
      "[2522,     1] loss: 0.0025737888645380735\n",
      "[2523,     1] loss: 0.002562312176451087\n",
      "[2524,     1] loss: 0.002553445752710104\n",
      "[2525,     1] loss: 0.0025473281275480986\n",
      "[2526,     1] loss: 0.002543614711612463\n",
      "[2527,     1] loss: 0.002541994210332632\n",
      "[2528,     1] loss: 0.0025416065473109484\n",
      "[2529,     1] loss: 0.002542223082855344\n",
      "[2530,     1] loss: 0.002544482471421361\n",
      "[2531,     1] loss: 0.0025479525793343782\n",
      "[2532,     1] loss: 0.0025545270182192326\n",
      "[2533,     1] loss: 0.002563204849138856\n",
      "[2534,     1] loss: 0.0025761215947568417\n",
      "[2535,     1] loss: 0.0025897768791764975\n",
      "[2536,     1] loss: 0.002609020099043846\n",
      "[2537,     1] loss: 0.002627938287332654\n",
      "[2538,     1] loss: 0.002655982505530119\n",
      "[2539,     1] loss: 0.002678284188732505\n",
      "[2540,     1] loss: 0.0027038624975830317\n",
      "[2541,     1] loss: 0.002713568974286318\n",
      "[2542,     1] loss: 0.002720412565395236\n",
      "[2543,     1] loss: 0.0027035404928028584\n",
      "[2544,     1] loss: 0.0026733314152806997\n",
      "[2545,     1] loss: 0.002627868438139558\n",
      "[2546,     1] loss: 0.002582745160907507\n",
      "[2547,     1] loss: 0.0025438927114009857\n",
      "[2548,     1] loss: 0.0025192706380039454\n",
      "[2549,     1] loss: 0.0025109359994530678\n",
      "[2550,     1] loss: 0.002516180044040084\n",
      "[2551,     1] loss: 0.0025295342784374952\n",
      "[2552,     1] loss: 0.002544242888689041\n",
      "[2553,     1] loss: 0.002558849286288023\n",
      "[2554,     1] loss: 0.0025648162700235844\n",
      "[2555,     1] loss: 0.0025669352617114782\n",
      "[2556,     1] loss: 0.002558913780376315\n",
      "[2557,     1] loss: 0.0025470838882029057\n",
      "[2558,     1] loss: 0.002530957804992795\n",
      "[2559,     1] loss: 0.002517431741580367\n",
      "[2560,     1] loss: 0.002505083568394184\n",
      "[2561,     1] loss: 0.002496823202818632\n",
      "[2562,     1] loss: 0.0024917926639318466\n",
      "[2563,     1] loss: 0.0024893218651413918\n",
      "[2564,     1] loss: 0.0024884664453566074\n",
      "[2565,     1] loss: 0.0024884373415261507\n",
      "[2566,     1] loss: 0.0024896624963730574\n",
      "[2567,     1] loss: 0.0024914296809583902\n",
      "[2568,     1] loss: 0.002494402462616563\n",
      "[2569,     1] loss: 0.0024970832746475935\n",
      "[2570,     1] loss: 0.0025019454769790173\n",
      "[2571,     1] loss: 0.0025054095312952995\n",
      "[2572,     1] loss: 0.0025121646467596292\n",
      "[2573,     1] loss: 0.0025158242788165808\n",
      "[2574,     1] loss: 0.0025227225851267576\n",
      "[2575,     1] loss: 0.002525260439142585\n",
      "[2576,     1] loss: 0.0025301179848611355\n",
      "[2577,     1] loss: 0.0025293140206485987\n",
      "[2578,     1] loss: 0.0025294115766882896\n",
      "[2579,     1] loss: 0.002523851115256548\n",
      "[2580,     1] loss: 0.00251743383705616\n",
      "[2581,     1] loss: 0.002507222583517432\n",
      "[2582,     1] loss: 0.0024966751225292683\n",
      "[2583,     1] loss: 0.002485848730430007\n",
      "[2584,     1] loss: 0.002477093366906047\n",
      "[2585,     1] loss: 0.002470101462677121\n",
      "[2586,     1] loss: 0.0024645188823342323\n",
      "[2587,     1] loss: 0.002460393588989973\n",
      "[2588,     1] loss: 0.002457690192386508\n",
      "[2589,     1] loss: 0.002456303220242262\n",
      "[2590,     1] loss: 0.0024559632875025272\n",
      "[2591,     1] loss: 0.00245670136064291\n",
      "[2592,     1] loss: 0.0024593709968030453\n",
      "[2593,     1] loss: 0.002465301426127553\n",
      "[2594,     1] loss: 0.0024741291999816895\n",
      "[2595,     1] loss: 0.0024881078861653805\n",
      "[2596,     1] loss: 0.0025039149913936853\n",
      "[2597,     1] loss: 0.002525881165638566\n",
      "[2598,     1] loss: 0.0025432356633245945\n",
      "[2599,     1] loss: 0.0025664125569164753\n",
      "[2600,     1] loss: 0.0025796189438551664\n",
      "[2601,     1] loss: 0.00259403046220541\n",
      "[2602,     1] loss: 0.0025914949364960194\n",
      "[2603,     1] loss: 0.002580381464213133\n",
      "[2604,     1] loss: 0.0025521316565573215\n",
      "[2605,     1] loss: 0.0025185937993228436\n",
      "[2606,     1] loss: 0.0024809367023408413\n",
      "[2607,     1] loss: 0.00245065544731915\n",
      "[2608,     1] loss: 0.0024321204982697964\n",
      "[2609,     1] loss: 0.0024265667889267206\n",
      "[2610,     1] loss: 0.0024309928994625807\n",
      "[2611,     1] loss: 0.002440276788547635\n",
      "[2612,     1] loss: 0.0024533383548259735\n",
      "[2613,     1] loss: 0.002462583128362894\n",
      "[2614,     1] loss: 0.002470494480803609\n",
      "[2615,     1] loss: 0.0024692395236343145\n",
      "[2616,     1] loss: 0.0024673601146787405\n",
      "[2617,     1] loss: 0.002457908820360899\n",
      "[2618,     1] loss: 0.002448654267936945\n",
      "[2619,     1] loss: 0.002435932867228985\n",
      "[2620,     1] loss: 0.0024252389557659626\n",
      "[2621,     1] loss: 0.0024152060505002737\n",
      "[2622,     1] loss: 0.002408099826425314\n",
      "[2623,     1] loss: 0.0024031198117882013\n",
      "[2624,     1] loss: 0.0023999284021556377\n",
      "[2625,     1] loss: 0.0023977889213711023\n",
      "[2626,     1] loss: 0.0023969849571585655\n",
      "[2627,     1] loss: 0.0023985423613339663\n",
      "[2628,     1] loss: 0.0024019023403525352\n",
      "[2629,     1] loss: 0.0024077692069113255\n",
      "[2630,     1] loss: 0.002414529677480459\n",
      "[2631,     1] loss: 0.0024248925037682056\n",
      "[2632,     1] loss: 0.002434450201690197\n",
      "[2633,     1] loss: 0.002447911072522402\n",
      "[2634,     1] loss: 0.0024576017167419195\n",
      "[2635,     1] loss: 0.0024704663082957268\n",
      "[2636,     1] loss: 0.0024759271182119846\n",
      "[2637,     1] loss: 0.00248337141238153\n",
      "[2638,     1] loss: 0.0024802032858133316\n",
      "[2639,     1] loss: 0.0024727610871195793\n",
      "[2640,     1] loss: 0.0024563241750001907\n",
      "[2641,     1] loss: 0.002437146846204996\n",
      "[2642,     1] loss: 0.0024138924200087786\n",
      "[2643,     1] loss: 0.0023918678052723408\n",
      "[2644,     1] loss: 0.0023741046898066998\n",
      "[2645,     1] loss: 0.0023628149647265673\n",
      "[2646,     1] loss: 0.0023581134155392647\n",
      "[2647,     1] loss: 0.002358779776841402\n",
      "[2648,     1] loss: 0.0023637167178094387\n",
      "[2649,     1] loss: 0.0023711994290351868\n",
      "[2650,     1] loss: 0.0023808074183762074\n",
      "[2651,     1] loss: 0.0023902449756860733\n",
      "[2652,     1] loss: 0.0023999549448490143\n",
      "[2653,     1] loss: 0.0024065538309514523\n",
      "[2654,     1] loss: 0.002414658898487687\n",
      "[2655,     1] loss: 0.002417356939986348\n",
      "[2656,     1] loss: 0.00242229038849473\n",
      "[2657,     1] loss: 0.0024202032946050167\n",
      "[2658,     1] loss: 0.0024177590385079384\n",
      "[2659,     1] loss: 0.0024086765479296446\n",
      "[2660,     1] loss: 0.0023992592468857765\n",
      "[2661,     1] loss: 0.0023846980184316635\n",
      "[2662,     1] loss: 0.0023703088518232107\n",
      "[2663,     1] loss: 0.0023559932596981525\n",
      "[2664,     1] loss: 0.0023441025987267494\n",
      "[2665,     1] loss: 0.002335319062694907\n",
      "[2666,     1] loss: 0.002329627051949501\n",
      "[2667,     1] loss: 0.0023267590440809727\n",
      "[2668,     1] loss: 0.0023259937297552824\n",
      "[2669,     1] loss: 0.002326725050806999\n",
      "[2670,     1] loss: 0.0023288691882044077\n",
      "[2671,     1] loss: 0.002332923002541065\n",
      "[2672,     1] loss: 0.0023383963853120804\n",
      "[2673,     1] loss: 0.002346639521420002\n",
      "[2674,     1] loss: 0.0023558340035378933\n",
      "[2675,     1] loss: 0.0023697721771895885\n",
      "[2676,     1] loss: 0.0023840260691940784\n",
      "[2677,     1] loss: 0.0024033640511333942\n",
      "[2678,     1] loss: 0.0024205618537962437\n",
      "[2679,     1] loss: 0.0024459175765514374\n",
      "[2680,     1] loss: 0.0024634706787765026\n",
      "[2681,     1] loss: 0.0024888687767088413\n",
      "[2682,     1] loss: 0.0024985980708152056\n",
      "[2683,     1] loss: 0.0025091173592954874\n",
      "[2684,     1] loss: 0.002497088862583041\n",
      "[2685,     1] loss: 0.002481569070369005\n",
      "[2686,     1] loss: 0.0024458658881485462\n",
      "[2687,     1] loss: 0.0024033118970692158\n",
      "[2688,     1] loss: 0.002357606776058674\n",
      "[2689,     1] loss: 0.002321953186765313\n",
      "[2690,     1] loss: 0.002299950225278735\n",
      "[2691,     1] loss: 0.0022936780005693436\n",
      "[2692,     1] loss: 0.002299879677593708\n",
      "[2693,     1] loss: 0.0023135491646826267\n",
      "[2694,     1] loss: 0.002330297604203224\n",
      "[2695,     1] loss: 0.002344167325645685\n",
      "[2696,     1] loss: 0.0023535548243671656\n",
      "[2697,     1] loss: 0.002355108270421624\n",
      "[2698,     1] loss: 0.002352377399802208\n",
      "[2699,     1] loss: 0.0023429589346051216\n",
      "[2700,     1] loss: 0.002333426848053932\n",
      "[2701,     1] loss: 0.002320644212886691\n",
      "[2702,     1] loss: 0.002308980096131563\n",
      "[2703,     1] loss: 0.0022967697586864233\n",
      "[2704,     1] loss: 0.0022861813195049763\n",
      "[2705,     1] loss: 0.002277925843372941\n",
      "[2706,     1] loss: 0.0022725705057382584\n",
      "[2707,     1] loss: 0.0022699092514812946\n",
      "[2708,     1] loss: 0.0022690820042043924\n",
      "[2709,     1] loss: 0.0022694512736052275\n",
      "[2710,     1] loss: 0.002270387951284647\n",
      "[2711,     1] loss: 0.0022728831972926855\n",
      "[2712,     1] loss: 0.0022761004511266947\n",
      "[2713,     1] loss: 0.0022820967715233564\n",
      "[2714,     1] loss: 0.0022886828519403934\n",
      "[2715,     1] loss: 0.002299000509083271\n",
      "[2716,     1] loss: 0.002308440860360861\n",
      "[2717,     1] loss: 0.002320338971912861\n",
      "[2718,     1] loss: 0.0023285045754164457\n",
      "[2719,     1] loss: 0.0023412553127855062\n",
      "[2720,     1] loss: 0.002348842564970255\n",
      "[2721,     1] loss: 0.0023585157468914986\n",
      "[2722,     1] loss: 0.0023601907305419445\n",
      "[2723,     1] loss: 0.002365532796829939\n",
      "[2724,     1] loss: 0.00236048037186265\n",
      "[2725,     1] loss: 0.0023555834777653217\n",
      "[2726,     1] loss: 0.0023394026793539524\n",
      "[2727,     1] loss: 0.002322004409506917\n",
      "[2728,     1] loss: 0.0022995106410235167\n",
      "[2729,     1] loss: 0.002278640866279602\n",
      "[2730,     1] loss: 0.002260071225464344\n",
      "[2731,     1] loss: 0.0022466976661235094\n",
      "[2732,     1] loss: 0.0022386983036994934\n",
      "[2733,     1] loss: 0.002235463820397854\n",
      "[2734,     1] loss: 0.002235925290733576\n",
      "[2735,     1] loss: 0.002239017514511943\n",
      "[2736,     1] loss: 0.0022444522473961115\n",
      "[2737,     1] loss: 0.002251050900667906\n",
      "[2738,     1] loss: 0.002259527798742056\n",
      "[2739,     1] loss: 0.002268028911203146\n",
      "[2740,     1] loss: 0.002280993154272437\n",
      "[2741,     1] loss: 0.002292092191055417\n",
      "[2742,     1] loss: 0.0023088541347533464\n",
      "[2743,     1] loss: 0.002321995794773102\n",
      "[2744,     1] loss: 0.0023437226191163063\n",
      "[2745,     1] loss: 0.0023596291430294514\n",
      "[2746,     1] loss: 0.0023859720677137375\n",
      "[2747,     1] loss: 0.0023979502730071545\n",
      "[2748,     1] loss: 0.002414778107777238\n",
      "[2749,     1] loss: 0.0024083589669317007\n",
      "[2750,     1] loss: 0.002402984071522951\n",
      "[2751,     1] loss: 0.0023714618291705847\n",
      "[2752,     1] loss: 0.0023349039256572723\n",
      "[2753,     1] loss: 0.0022878763265907764\n",
      "[2754,     1] loss: 0.002246817108243704\n",
      "[2755,     1] loss: 0.002215718850493431\n",
      "[2756,     1] loss: 0.0022004132624715567\n",
      "[2757,     1] loss: 0.0021995643619447947\n",
      "[2758,     1] loss: 0.0022085795644670725\n",
      "[2759,     1] loss: 0.0022225796710699797\n",
      "[2760,     1] loss: 0.002236336935311556\n",
      "[2761,     1] loss: 0.0022470923140645027\n",
      "[2762,     1] loss: 0.0022512818686664104\n",
      "[2763,     1] loss: 0.0022513463627547026\n",
      "[2764,     1] loss: 0.002245886716991663\n",
      "[2765,     1] loss: 0.0022382629103958607\n",
      "[2766,     1] loss: 0.0022263508290052414\n",
      "[2767,     1] loss: 0.0022143686655908823\n",
      "[2768,     1] loss: 0.002202174626290798\n",
      "[2769,     1] loss: 0.0021923494059592485\n",
      "[2770,     1] loss: 0.0021847153548151255\n",
      "[2771,     1] loss: 0.0021798796951770782\n",
      "[2772,     1] loss: 0.0021771020255982876\n",
      "[2773,     1] loss: 0.002175847999751568\n",
      "[2774,     1] loss: 0.0021755252964794636\n",
      "[2775,     1] loss: 0.002175861271098256\n",
      "[2776,     1] loss: 0.0021773448679596186\n",
      "[2777,     1] loss: 0.0021798068191856146\n",
      "[2778,     1] loss: 0.0021839921828359365\n",
      "[2779,     1] loss: 0.0021887701004743576\n",
      "[2780,     1] loss: 0.0021965899504721165\n",
      "[2781,     1] loss: 0.002205429133027792\n",
      "[2782,     1] loss: 0.0022189058363437653\n",
      "[2783,     1] loss: 0.0022313902154564857\n",
      "[2784,     1] loss: 0.002249664394184947\n",
      "[2785,     1] loss: 0.002263577887788415\n",
      "[2786,     1] loss: 0.002281461376696825\n",
      "[2787,     1] loss: 0.002291151788085699\n",
      "[2788,     1] loss: 0.002303603570908308\n",
      "[2789,     1] loss: 0.0023020398803055286\n",
      "[2790,     1] loss: 0.0022969981655478477\n",
      "[2791,     1] loss: 0.0022783344611525536\n",
      "[2792,     1] loss: 0.002255822531878948\n",
      "[2793,     1] loss: 0.0022269757464528084\n",
      "[2794,     1] loss: 0.0022007450461387634\n",
      "[2795,     1] loss: 0.0021769911982119083\n",
      "[2796,     1] loss: 0.002159467898309231\n",
      "[2797,     1] loss: 0.0021498478017747402\n",
      "[2798,     1] loss: 0.0021480133291333914\n",
      "[2799,     1] loss: 0.002152096014469862\n",
      "[2800,     1] loss: 0.002160037634894252\n",
      "[2801,     1] loss: 0.002169713145121932\n",
      "[2802,     1] loss: 0.0021789404563605785\n",
      "[2803,     1] loss: 0.0021898027043789625\n",
      "[2804,     1] loss: 0.0021980139426887035\n",
      "[2805,     1] loss: 0.0022098098415881395\n",
      "[2806,     1] loss: 0.0022180217783898115\n",
      "[2807,     1] loss: 0.002232121769338846\n",
      "[2808,     1] loss: 0.0022417884320020676\n",
      "[2809,     1] loss: 0.0022575294133275747\n",
      "[2810,     1] loss: 0.002265865681692958\n",
      "[2811,     1] loss: 0.0022762406151741743\n",
      "[2812,     1] loss: 0.0022745979949831963\n",
      "[2813,     1] loss: 0.0022716005332767963\n",
      "[2814,     1] loss: 0.002253187820315361\n",
      "[2815,     1] loss: 0.00223079277202487\n",
      "[2816,     1] loss: 0.0021987557411193848\n",
      "[2817,     1] loss: 0.002167024649679661\n",
      "[2818,     1] loss: 0.0021400917321443558\n",
      "[2819,     1] loss: 0.0021228697150945663\n",
      "[2820,     1] loss: 0.002115960931405425\n",
      "[2821,     1] loss: 0.0021180021576583385\n",
      "[2822,     1] loss: 0.002126015955582261\n",
      "[2823,     1] loss: 0.0021363168489187956\n",
      "[2824,     1] loss: 0.0021467432379722595\n",
      "[2825,     1] loss: 0.0021552718244493008\n",
      "[2826,     1] loss: 0.0021634725853800774\n",
      "[2827,     1] loss: 0.0021672211587429047\n",
      "[2828,     1] loss: 0.0021707869600504637\n",
      "[2829,     1] loss: 0.0021699806675314903\n",
      "[2830,     1] loss: 0.002170347375795245\n",
      "[2831,     1] loss: 0.0021659948397427797\n",
      "[2832,     1] loss: 0.002161845564842224\n",
      "[2833,     1] loss: 0.002153744688257575\n",
      "[2834,     1] loss: 0.002144221216440201\n",
      "[2835,     1] loss: 0.00213355990126729\n",
      "[2836,     1] loss: 0.002122560515999794\n",
      "[2837,     1] loss: 0.002111559733748436\n",
      "[2838,     1] loss: 0.002102443715557456\n",
      "[2839,     1] loss: 0.002095605246722698\n",
      "[2840,     1] loss: 0.002091243164613843\n",
      "[2841,     1] loss: 0.002089115558192134\n",
      "[2842,     1] loss: 0.0020887742284685373\n",
      "[2843,     1] loss: 0.00208976399153471\n",
      "[2844,     1] loss: 0.0020918874070048332\n",
      "[2845,     1] loss: 0.0020954736974090338\n",
      "[2846,     1] loss: 0.0021004369482398033\n",
      "[2847,     1] loss: 0.0021088081412017345\n",
      "[2848,     1] loss: 0.0021187900565564632\n",
      "[2849,     1] loss: 0.002134401351213455\n",
      "[2850,     1] loss: 0.0021525234915316105\n",
      "[2851,     1] loss: 0.0021859435364603996\n",
      "[2852,     1] loss: 0.002222079783678055\n",
      "[2853,     1] loss: 0.0022801479790359735\n",
      "[2854,     1] loss: 0.0023399055935442448\n",
      "[2855,     1] loss: 0.002437691669911146\n",
      "[2856,     1] loss: 0.0025195872876793146\n",
      "[2857,     1] loss: 0.0026313276030123234\n",
      "[2858,     1] loss: 0.0026744462084025145\n",
      "[2859,     1] loss: 0.0027063414454460144\n",
      "[2860,     1] loss: 0.0026169721968472004\n",
      "[2861,     1] loss: 0.00247171800583601\n",
      "[2862,     1] loss: 0.0022755013778805733\n",
      "[2863,     1] loss: 0.0021276723127812147\n",
      "[2864,     1] loss: 0.002070516115054488\n",
      "[2865,     1] loss: 0.002104457700625062\n",
      "[2866,     1] loss: 0.0021866410970687866\n",
      "[2867,     1] loss: 0.0022584348917007446\n",
      "[2868,     1] loss: 0.00228532194159925\n",
      "[2869,     1] loss: 0.0022481975611299276\n",
      "[2870,     1] loss: 0.002179389586672187\n",
      "[2871,     1] loss: 0.0021092777606099844\n",
      "[2872,     1] loss: 0.0020715268328785896\n",
      "[2873,     1] loss: 0.0020743533968925476\n",
      "[2874,     1] loss: 0.0021060761064291\n",
      "[2875,     1] loss: 0.0021448794286698103\n",
      "[2876,     1] loss: 0.0021674600429832935\n",
      "[2877,     1] loss: 0.002167053986340761\n",
      "[2878,     1] loss: 0.0021425546146929264\n",
      "[2879,     1] loss: 0.002110309898853302\n",
      "[2880,     1] loss: 0.0020804605446755886\n",
      "[2881,     1] loss: 0.0020634811371564865\n",
      "[2882,     1] loss: 0.0020610790234059095\n",
      "[2883,     1] loss: 0.002068547299131751\n",
      "[2884,     1] loss: 0.0020799501799046993\n",
      "[2885,     1] loss: 0.00208590691909194\n",
      "[2886,     1] loss: 0.0020858231000602245\n",
      "[2887,     1] loss: 0.0020759208127856255\n",
      "[2888,     1] loss: 0.002062197308987379\n",
      "[2889,     1] loss: 0.0020487834699451923\n",
      "[2890,     1] loss: 0.0020402853842824697\n",
      "[2891,     1] loss: 0.00203781109303236\n",
      "[2892,     1] loss: 0.0020400218199938536\n",
      "[2893,     1] loss: 0.0020438407082110643\n",
      "[2894,     1] loss: 0.002046247012913227\n",
      "[2895,     1] loss: 0.002046358771622181\n",
      "[2896,     1] loss: 0.0020441249944269657\n",
      "[2897,     1] loss: 0.0020410215947777033\n",
      "[2898,     1] loss: 0.0020369533449411392\n",
      "[2899,     1] loss: 0.00203313329257071\n",
      "[2900,     1] loss: 0.0020290557295084\n",
      "[2901,     1] loss: 0.002025384921580553\n",
      "[2902,     1] loss: 0.0020223483443260193\n",
      "[2903,     1] loss: 0.002020204206928611\n",
      "[2904,     1] loss: 0.002018940169364214\n",
      "[2905,     1] loss: 0.0020186174660921097\n",
      "[2906,     1] loss: 0.002019265666604042\n",
      "[2907,     1] loss: 0.002020377665758133\n",
      "[2908,     1] loss: 0.0020220475271344185\n",
      "[2909,     1] loss: 0.002023084321990609\n",
      "[2910,     1] loss: 0.0020236531272530556\n",
      "[2911,     1] loss: 0.002022873144596815\n",
      "[2912,     1] loss: 0.0020218484569340944\n",
      "[2913,     1] loss: 0.0020202388986945152\n",
      "[2914,     1] loss: 0.0020183755550533533\n",
      "[2915,     1] loss: 0.0020160565618425608\n",
      "[2916,     1] loss: 0.002014217199757695\n",
      "[2917,     1] loss: 0.0020116923842579126\n",
      "[2918,     1] loss: 0.002009166404604912\n",
      "[2919,     1] loss: 0.002006402239203453\n",
      "[2920,     1] loss: 0.002004040405154228\n",
      "[2921,     1] loss: 0.002002100460231304\n",
      "[2922,     1] loss: 0.0020007097627967596\n",
      "[2923,     1] loss: 0.0019998003263026476\n",
      "[2924,     1] loss: 0.0019994480535387993\n",
      "[2925,     1] loss: 0.0019991090521216393\n",
      "[2926,     1] loss: 0.0019989758729934692\n",
      "[2927,     1] loss: 0.0019990704022347927\n",
      "[2928,     1] loss: 0.001999635249376297\n",
      "[2929,     1] loss: 0.002000663662329316\n",
      "[2930,     1] loss: 0.002002245280891657\n",
      "[2931,     1] loss: 0.002004204085096717\n",
      "[2932,     1] loss: 0.0020076946821063757\n",
      "[2933,     1] loss: 0.0020123454742133617\n",
      "[2934,     1] loss: 0.002020821440964937\n",
      "[2935,     1] loss: 0.0020302345510572195\n",
      "[2936,     1] loss: 0.002046413253992796\n",
      "[2937,     1] loss: 0.002062304178252816\n",
      "[2938,     1] loss: 0.002087297383695841\n",
      "[2939,     1] loss: 0.0021082425955682993\n",
      "[2940,     1] loss: 0.0021396134980022907\n",
      "[2941,     1] loss: 0.002158855088055134\n",
      "[2942,     1] loss: 0.002186910714954138\n",
      "[2943,     1] loss: 0.0021934998221695423\n",
      "[2944,     1] loss: 0.002198719186708331\n",
      "[2945,     1] loss: 0.002179123228415847\n",
      "[2946,     1] loss: 0.002150434534996748\n",
      "[2947,     1] loss: 0.002104333834722638\n",
      "[2948,     1] loss: 0.002056043827906251\n",
      "[2949,     1] loss: 0.002012250479310751\n",
      "[2950,     1] loss: 0.0019826472271233797\n",
      "[2951,     1] loss: 0.0019701067358255386\n",
      "[2952,     1] loss: 0.001972421770915389\n",
      "[2953,     1] loss: 0.0019847119692713022\n",
      "[2954,     1] loss: 0.0020008417777717113\n",
      "[2955,     1] loss: 0.0020168833434581757\n",
      "[2956,     1] loss: 0.0020282426849007607\n",
      "[2957,     1] loss: 0.00203696102835238\n",
      "[2958,     1] loss: 0.002037488389760256\n",
      "[2959,     1] loss: 0.0020355316810309887\n",
      "[2960,     1] loss: 0.002026289002969861\n",
      "[2961,     1] loss: 0.0020163110457360744\n",
      "[2962,     1] loss: 0.002001754939556122\n",
      "[2963,     1] loss: 0.0019872840493917465\n",
      "[2964,     1] loss: 0.0019731875509023666\n",
      "[2965,     1] loss: 0.001961648464202881\n",
      "[2966,     1] loss: 0.0019535997416824102\n",
      "[2967,     1] loss: 0.0019491194980219007\n",
      "[2968,     1] loss: 0.001947843818925321\n",
      "[2969,     1] loss: 0.00194881996139884\n",
      "[2970,     1] loss: 0.0019511276623234153\n",
      "[2971,     1] loss: 0.0019544255919754505\n",
      "[2972,     1] loss: 0.001958270091563463\n",
      "[2973,     1] loss: 0.0019625292625278234\n",
      "[2974,     1] loss: 0.001966898562386632\n",
      "[2975,     1] loss: 0.0019715281669050455\n",
      "[2976,     1] loss: 0.0019775202963501215\n",
      "[2977,     1] loss: 0.0019822334870696068\n",
      "[2978,     1] loss: 0.0019898926839232445\n",
      "[2979,     1] loss: 0.0019964035600423813\n",
      "[2980,     1] loss: 0.002007909119129181\n",
      "[2981,     1] loss: 0.0020163683220744133\n",
      "[2982,     1] loss: 0.00202950625680387\n",
      "[2983,     1] loss: 0.002037018071860075\n",
      "[2984,     1] loss: 0.002045715693384409\n",
      "[2985,     1] loss: 0.0020467648282647133\n",
      "[2986,     1] loss: 0.0020473592448979616\n",
      "[2987,     1] loss: 0.002039871411398053\n",
      "[2988,     1] loss: 0.002029282506555319\n",
      "[2989,     1] loss: 0.0020125899463891983\n",
      "[2990,     1] loss: 0.0019944384694099426\n",
      "[2991,     1] loss: 0.0019746061880141497\n",
      "[2992,     1] loss: 0.0019570481963455677\n",
      "[2993,     1] loss: 0.001941762981005013\n",
      "[2994,     1] loss: 0.0019304226152598858\n",
      "[2995,     1] loss: 0.001923611736856401\n",
      "[2996,     1] loss: 0.0019211540929973125\n",
      "[2997,     1] loss: 0.0019222463015466928\n",
      "[2998,     1] loss: 0.0019260321278125048\n",
      "[2999,     1] loss: 0.0019322854932397604\n",
      "[3000,     1] loss: 0.0019407233921810985\n",
      "[3001,     1] loss: 0.0019526786636561155\n",
      "[3002,     1] loss: 0.0019660501275211573\n",
      "[3003,     1] loss: 0.0019862535409629345\n",
      "[3004,     1] loss: 0.0020066979341208935\n",
      "[3005,     1] loss: 0.0020400830544531345\n",
      "[3006,     1] loss: 0.002072404371574521\n",
      "[3007,     1] loss: 0.002118122298270464\n",
      "[3008,     1] loss: 0.0021569549571722746\n",
      "[3009,     1] loss: 0.002209909027442336\n",
      "[3010,     1] loss: 0.002241882961243391\n",
      "[3011,     1] loss: 0.002285693073645234\n",
      "[3012,     1] loss: 0.002288972260430455\n",
      "[3013,     1] loss: 0.002276788232848048\n",
      "[3014,     1] loss: 0.002214775886386633\n",
      "[3015,     1] loss: 0.002130888868123293\n",
      "[3016,     1] loss: 0.0020338152535259724\n",
      "[3017,     1] loss: 0.001956481486558914\n",
      "[3018,     1] loss: 0.0019120166543871164\n",
      "[3019,     1] loss: 0.0019042545463889837\n",
      "[3020,     1] loss: 0.0019244509749114513\n",
      "[3021,     1] loss: 0.0019581210799515247\n",
      "[3022,     1] loss: 0.001990834716707468\n",
      "[3023,     1] loss: 0.00201014312915504\n",
      "[3024,     1] loss: 0.002017287304624915\n",
      "[3025,     1] loss: 0.0020042392425239086\n",
      "[3026,     1] loss: 0.0019824118353426456\n",
      "[3027,     1] loss: 0.0019519389607012272\n",
      "[3028,     1] loss: 0.0019221680704504251\n",
      "[3029,     1] loss: 0.0018992535769939423\n",
      "[3030,     1] loss: 0.0018873829394578934\n",
      "[3031,     1] loss: 0.001886510057374835\n",
      "[3032,     1] loss: 0.0018936332780867815\n",
      "[3033,     1] loss: 0.0019045883091166615\n",
      "[3034,     1] loss: 0.0019154745386913419\n",
      "[3035,     1] loss: 0.0019246097654104233\n",
      "[3036,     1] loss: 0.0019281601998955011\n",
      "[3037,     1] loss: 0.001929325982928276\n",
      "[3038,     1] loss: 0.0019245562143623829\n",
      "[3039,     1] loss: 0.0019180624512955546\n",
      "[3040,     1] loss: 0.0019081525970250368\n",
      "[3041,     1] loss: 0.00189732457511127\n",
      "[3042,     1] loss: 0.0018870898056775331\n",
      "[3043,     1] loss: 0.0018782583065330982\n",
      "[3044,     1] loss: 0.0018720931839197874\n",
      "[3045,     1] loss: 0.0018689665012061596\n",
      "[3046,     1] loss: 0.0018684419337660074\n",
      "[3047,     1] loss: 0.001869692699983716\n",
      "[3048,     1] loss: 0.001872263033874333\n",
      "[3049,     1] loss: 0.001875196467153728\n",
      "[3050,     1] loss: 0.0018788366578519344\n",
      "[3051,     1] loss: 0.0018825471634045243\n",
      "[3052,     1] loss: 0.0018880796851590276\n",
      "[3053,     1] loss: 0.0018930360674858093\n",
      "[3054,     1] loss: 0.0018998077139258385\n",
      "[3055,     1] loss: 0.0019051707349717617\n",
      "[3056,     1] loss: 0.001912382198497653\n",
      "[3057,     1] loss: 0.0019169829320162535\n",
      "[3058,     1] loss: 0.001924197538755834\n",
      "[3059,     1] loss: 0.0019272484350949526\n",
      "[3060,     1] loss: 0.0019312333315610886\n",
      "[3061,     1] loss: 0.0019300737185403705\n",
      "[3062,     1] loss: 0.0019272593781352043\n",
      "[3063,     1] loss: 0.0019191706087440252\n",
      "[3064,     1] loss: 0.0019110471475869417\n",
      "[3065,     1] loss: 0.0019004815258085728\n",
      "[3066,     1] loss: 0.0018889143830165267\n",
      "[3067,     1] loss: 0.001877057016827166\n",
      "[3068,     1] loss: 0.0018660789355635643\n",
      "[3069,     1] loss: 0.0018566937651485205\n",
      "[3070,     1] loss: 0.0018497217679396272\n",
      "[3071,     1] loss: 0.0018450707430019975\n",
      "[3072,     1] loss: 0.0018421869026497006\n",
      "[3073,     1] loss: 0.0018405613955110312\n",
      "[3074,     1] loss: 0.001839829026721418\n",
      "[3075,     1] loss: 0.001839662785641849\n",
      "[3076,     1] loss: 0.0018402060959488153\n",
      "[3077,     1] loss: 0.0018418305553495884\n",
      "[3078,     1] loss: 0.0018448656192049384\n",
      "[3079,     1] loss: 0.0018500946462154388\n",
      "[3080,     1] loss: 0.0018570335814729333\n",
      "[3081,     1] loss: 0.0018682591617107391\n",
      "[3082,     1] loss: 0.001882823184132576\n",
      "[3083,     1] loss: 0.001905759098008275\n",
      "[3084,     1] loss: 0.0019327763002365828\n",
      "[3085,     1] loss: 0.0019750199280679226\n",
      "[3086,     1] loss: 0.0020199264399707317\n",
      "[3087,     1] loss: 0.002098008058965206\n",
      "[3088,     1] loss: 0.002172039123252034\n",
      "[3089,     1] loss: 0.0022828509099781513\n",
      "[3090,     1] loss: 0.0023644021712243557\n",
      "[3091,     1] loss: 0.00245868437923491\n",
      "[3092,     1] loss: 0.0024692933075129986\n",
      "[3093,     1] loss: 0.002444836078211665\n",
      "[3094,     1] loss: 0.0023070857860147953\n",
      "[3095,     1] loss: 0.002130709355697036\n",
      "[3096,     1] loss: 0.0019517240580171347\n",
      "[3097,     1] loss: 0.001847730833105743\n",
      "[3098,     1] loss: 0.0018401918932795525\n",
      "[3099,     1] loss: 0.001904709031805396\n",
      "[3100,     1] loss: 0.0019917613826692104\n",
      "[3101,     1] loss: 0.002044722903519869\n",
      "[3102,     1] loss: 0.002050458686426282\n",
      "[3103,     1] loss: 0.0019968245178461075\n",
      "[3104,     1] loss: 0.0019230638863518834\n",
      "[3105,     1] loss: 0.0018562127370387316\n",
      "[3106,     1] loss: 0.0018234283197671175\n",
      "[3107,     1] loss: 0.0018295577028766274\n",
      "[3108,     1] loss: 0.0018608053214848042\n",
      "[3109,     1] loss: 0.0018978400621563196\n",
      "[3110,     1] loss: 0.0019170930609107018\n",
      "[3111,     1] loss: 0.0019177794456481934\n",
      "[3112,     1] loss: 0.0018939697183668613\n",
      "[3113,     1] loss: 0.0018608546815812588\n",
      "[3114,     1] loss: 0.0018288263818249106\n",
      "[3115,     1] loss: 0.0018103602342307568\n",
      "[3116,     1] loss: 0.0018088958458974957\n",
      "[3117,     1] loss: 0.0018198384204879403\n",
      "[3118,     1] loss: 0.0018346905708312988\n",
      "[3119,     1] loss: 0.001844586106017232\n",
      "[3120,     1] loss: 0.0018469842616468668\n",
      "[3121,     1] loss: 0.0018387788441032171\n",
      "[3122,     1] loss: 0.0018259745556861162\n",
      "[3123,     1] loss: 0.00181101995985955\n",
      "[3124,     1] loss: 0.0017990078777074814\n",
      "[3125,     1] loss: 0.0017930421745404601\n",
      "[3126,     1] loss: 0.001792795374058187\n",
      "[3127,     1] loss: 0.0017964045982807875\n",
      "[3128,     1] loss: 0.0018010693602263927\n",
      "[3129,     1] loss: 0.001804893254302442\n",
      "[3130,     1] loss: 0.0018058217829093337\n",
      "[3131,     1] loss: 0.0018052533268928528\n",
      "[3132,     1] loss: 0.0018024557502940297\n",
      "[3133,     1] loss: 0.0017986421007663012\n",
      "[3134,     1] loss: 0.001793907955288887\n",
      "[3135,     1] loss: 0.0017892614705488086\n",
      "[3136,     1] loss: 0.0017849954310804605\n",
      "[3137,     1] loss: 0.0017819837667047977\n",
      "[3138,     1] loss: 0.0017803579103201628\n",
      "[3139,     1] loss: 0.0017800383502617478\n",
      "[3140,     1] loss: 0.001780794933438301\n",
      "[3141,     1] loss: 0.0017822196241468191\n",
      "[3142,     1] loss: 0.0017842809902504086\n",
      "[3143,     1] loss: 0.0017863460816442966\n",
      "[3144,     1] loss: 0.0017887076828628778\n",
      "[3145,     1] loss: 0.001790856709703803\n",
      "[3146,     1] loss: 0.0017936417134478688\n",
      "[3147,     1] loss: 0.001795083750039339\n",
      "[3148,     1] loss: 0.0017971682827919722\n",
      "[3149,     1] loss: 0.0017976330127567053\n",
      "[3150,     1] loss: 0.0017992611974477768\n",
      "[3151,     1] loss: 0.0017997859977185726\n",
      "[3152,     1] loss: 0.0018002516590058804\n",
      "[3153,     1] loss: 0.0017996437381953\n",
      "[3154,     1] loss: 0.0017979627009481192\n",
      "[3155,     1] loss: 0.0017952534835785627\n",
      "[3156,     1] loss: 0.0017919164383783937\n",
      "[3157,     1] loss: 0.001788413617759943\n",
      "[3158,     1] loss: 0.0017842056695371866\n",
      "[3159,     1] loss: 0.001779228332452476\n",
      "[3160,     1] loss: 0.0017739379545673728\n",
      "[3161,     1] loss: 0.0017685572383925319\n",
      "[3162,     1] loss: 0.0017636787379160523\n",
      "[3163,     1] loss: 0.00175988778937608\n",
      "[3164,     1] loss: 0.0017574625089764595\n",
      "[3165,     1] loss: 0.0017567159375175834\n",
      "[3166,     1] loss: 0.0017581036081537604\n",
      "[3167,     1] loss: 0.0017617251724004745\n",
      "[3168,     1] loss: 0.0017672720132395625\n",
      "[3169,     1] loss: 0.0017758223693817854\n",
      "[3170,     1] loss: 0.0017871411982923746\n",
      "[3171,     1] loss: 0.001804053201340139\n",
      "[3172,     1] loss: 0.0018237880431115627\n",
      "[3173,     1] loss: 0.0018562156474217772\n",
      "[3174,     1] loss: 0.0018909770296886563\n",
      "[3175,     1] loss: 0.0019456036388874054\n",
      "[3176,     1] loss: 0.0019956189207732677\n",
      "[3177,     1] loss: 0.0020628273487091064\n",
      "[3178,     1] loss: 0.0021079322323203087\n",
      "[3179,     1] loss: 0.0021607442758977413\n",
      "[3180,     1] loss: 0.002165324054658413\n",
      "[3181,     1] loss: 0.0021428214386105537\n",
      "[3182,     1] loss: 0.0020670066587626934\n",
      "[3183,     1] loss: 0.001967458054423332\n",
      "[3184,     1] loss: 0.0018604304641485214\n",
      "[3185,     1] loss: 0.0017804020317271352\n",
      "[3186,     1] loss: 0.0017431306187063456\n",
      "[3187,     1] loss: 0.0017491490580141544\n",
      "[3188,     1] loss: 0.001784000894986093\n",
      "[3189,     1] loss: 0.0018271640874445438\n",
      "[3190,     1] loss: 0.0018626844976097345\n",
      "[3191,     1] loss: 0.0018751519965007901\n",
      "[3192,     1] loss: 0.0018692400772124529\n",
      "[3193,     1] loss: 0.0018407366005703807\n",
      "[3194,     1] loss: 0.0018045851029455662\n",
      "[3195,     1] loss: 0.0017679372103884816\n",
      "[3196,     1] loss: 0.0017415970796719193\n",
      "[3197,     1] loss: 0.0017293719574809074\n",
      "[3198,     1] loss: 0.00173089315649122\n",
      "[3199,     1] loss: 0.0017416378250345588\n",
      "[3200,     1] loss: 0.00175617600325495\n",
      "[3201,     1] loss: 0.0017699403688311577\n",
      "[3202,     1] loss: 0.0017775591695681214\n",
      "[3203,     1] loss: 0.0017803761875256896\n",
      "[3204,     1] loss: 0.0017750696279108524\n",
      "[3205,     1] loss: 0.0017663434846326709\n",
      "[3206,     1] loss: 0.0017535388469696045\n",
      "[3207,     1] loss: 0.0017408428248018026\n",
      "[3208,     1] loss: 0.0017291621770709753\n",
      "[3209,     1] loss: 0.0017206871416419744\n",
      "[3210,     1] loss: 0.001716183964163065\n",
      "[3211,     1] loss: 0.0017154933884739876\n",
      "[3212,     1] loss: 0.0017177164554595947\n",
      "[3213,     1] loss: 0.0017215354600921273\n",
      "[3214,     1] loss: 0.001726136775687337\n",
      "[3215,     1] loss: 0.0017304352950304747\n",
      "[3216,     1] loss: 0.0017351371934637427\n",
      "[3217,     1] loss: 0.001738805789500475\n",
      "[3218,     1] loss: 0.0017434285255149007\n",
      "[3219,     1] loss: 0.0017464545089751482\n",
      "[3220,     1] loss: 0.001750241732224822\n",
      "[3221,     1] loss: 0.0017518182285130024\n",
      "[3222,     1] loss: 0.0017526886658743024\n",
      "[3223,     1] loss: 0.0017506980802863836\n",
      "[3224,     1] loss: 0.0017473656916990876\n",
      "[3225,     1] loss: 0.00174192083068192\n",
      "[3226,     1] loss: 0.0017354761948809028\n",
      "[3227,     1] loss: 0.0017280930187553167\n",
      "[3228,     1] loss: 0.001720984699204564\n",
      "[3229,     1] loss: 0.0017143803415820003\n",
      "[3230,     1] loss: 0.001708822324872017\n",
      "[3231,     1] loss: 0.0017043801490217447\n",
      "[3232,     1] loss: 0.0017010275041684508\n",
      "[3233,     1] loss: 0.0016986349364742637\n",
      "[3234,     1] loss: 0.0016971416771411896\n",
      "[3235,     1] loss: 0.0016964086098596454\n",
      "[3236,     1] loss: 0.0016964002279564738\n",
      "[3237,     1] loss: 0.001697377534583211\n",
      "[3238,     1] loss: 0.0016994973411783576\n",
      "[3239,     1] loss: 0.0017038054065778852\n",
      "[3240,     1] loss: 0.00171052070800215\n",
      "[3241,     1] loss: 0.0017219786532223225\n",
      "[3242,     1] loss: 0.0017385655082762241\n",
      "[3243,     1] loss: 0.0017651563975960016\n",
      "[3244,     1] loss: 0.0017994517693296075\n",
      "[3245,     1] loss: 0.0018527943175286055\n",
      "[3246,     1] loss: 0.0019152836175635457\n",
      "[3247,     1] loss: 0.002010027877986431\n",
      "[3248,     1] loss: 0.0021063575986772776\n",
      "[3249,     1] loss: 0.0022370906081050634\n",
      "[3250,     1] loss: 0.0023411973379552364\n",
      "[3251,     1] loss: 0.0024546245113015175\n",
      "[3252,     1] loss: 0.0024690337013453245\n",
      "[3253,     1] loss: 0.002437578048557043\n",
      "[3254,     1] loss: 0.0022708717733621597\n",
      "[3255,     1] loss: 0.0020556668750941753\n",
      "[3256,     1] loss: 0.0018365711439400911\n",
      "[3257,     1] loss: 0.0017064346466213465\n",
      "[3258,     1] loss: 0.0016961670480668545\n",
      "[3259,     1] loss: 0.001776382327079773\n",
      "[3260,     1] loss: 0.0018820782424882054\n",
      "[3261,     1] loss: 0.001946375472471118\n",
      "[3262,     1] loss: 0.0019492696737870574\n",
      "[3263,     1] loss: 0.0018798848614096642\n",
      "[3264,     1] loss: 0.0017859655199572444\n",
      "[3265,     1] loss: 0.0017059185774996877\n",
      "[3266,     1] loss: 0.001673365943133831\n",
      "[3267,     1] loss: 0.0016906347591429949\n",
      "[3268,     1] loss: 0.0017360411584377289\n",
      "[3269,     1] loss: 0.0017791046993806958\n",
      "[3270,     1] loss: 0.0017938717501237988\n",
      "[3271,     1] loss: 0.0017779504414647818\n",
      "[3272,     1] loss: 0.0017377275507897139\n",
      "[3273,     1] loss: 0.0016955123282968998\n",
      "[3274,     1] loss: 0.0016678168904036283\n",
      "[3275,     1] loss: 0.0016629111487418413\n",
      "[3276,     1] loss: 0.0016761478036642075\n",
      "[3277,     1] loss: 0.0016954843886196613\n",
      "[3278,     1] loss: 0.0017105743754655123\n",
      "[3279,     1] loss: 0.001713286153972149\n",
      "[3280,     1] loss: 0.0017066472209990025\n",
      "[3281,     1] loss: 0.0016908353427425027\n",
      "[3282,     1] loss: 0.001673986203968525\n",
      "[3283,     1] loss: 0.0016603781841695309\n",
      "[3284,     1] loss: 0.0016535844188183546\n",
      "[3285,     1] loss: 0.0016543015372008085\n",
      "[3286,     1] loss: 0.0016596512869000435\n",
      "[3287,     1] loss: 0.0016659829998388886\n",
      "[3288,     1] loss: 0.0016697307582944632\n",
      "[3289,     1] loss: 0.0016704649897292256\n",
      "[3290,     1] loss: 0.0016671449411660433\n",
      "[3291,     1] loss: 0.001661808928474784\n",
      "[3292,     1] loss: 0.0016555199399590492\n",
      "[3293,     1] loss: 0.0016500783385708928\n",
      "[3294,     1] loss: 0.0016460681799799204\n",
      "[3295,     1] loss: 0.0016437493031844497\n",
      "[3296,     1] loss: 0.0016430581454187632\n",
      "[3297,     1] loss: 0.0016437433660030365\n",
      "[3298,     1] loss: 0.0016452553682029247\n",
      "[3299,     1] loss: 0.0016469088150188327\n",
      "[3300,     1] loss: 0.0016487652901560068\n",
      "[3301,     1] loss: 0.0016500884667038918\n",
      "[3302,     1] loss: 0.0016520170029252768\n",
      "[3303,     1] loss: 0.0016528766136616468\n",
      "[3304,     1] loss: 0.0016536301700398326\n",
      "[3305,     1] loss: 0.0016528540290892124\n",
      "[3306,     1] loss: 0.0016519997734576464\n",
      "[3307,     1] loss: 0.0016505075618624687\n",
      "[3308,     1] loss: 0.0016485757660120726\n",
      "[3309,     1] loss: 0.0016462563071399927\n",
      "[3310,     1] loss: 0.0016445732908323407\n",
      "[3311,     1] loss: 0.0016436567530035973\n",
      "[3312,     1] loss: 0.001643460476770997\n",
      "[3313,     1] loss: 0.001643870840780437\n",
      "[3314,     1] loss: 0.0016445801593363285\n",
      "[3315,     1] loss: 0.0016453462885692716\n",
      "[3316,     1] loss: 0.0016454447759315372\n",
      "[3317,     1] loss: 0.0016443913336843252\n",
      "[3318,     1] loss: 0.001642016228288412\n",
      "[3319,     1] loss: 0.0016383768524974585\n",
      "[3320,     1] loss: 0.0016341233858838677\n",
      "[3321,     1] loss: 0.0016298822592943907\n",
      "[3322,     1] loss: 0.001626559067517519\n",
      "[3323,     1] loss: 0.0016248724423348904\n",
      "[3324,     1] loss: 0.001624719356186688\n",
      "[3325,     1] loss: 0.0016257597599178553\n",
      "[3326,     1] loss: 0.0016274191439151764\n",
      "[3327,     1] loss: 0.0016296848189085722\n",
      "[3328,     1] loss: 0.0016329230275005102\n",
      "[3329,     1] loss: 0.0016381836030632257\n",
      "[3330,     1] loss: 0.0016460157930850983\n",
      "[3331,     1] loss: 0.0016601328970864415\n",
      "[3332,     1] loss: 0.0016779652796685696\n",
      "[3333,     1] loss: 0.00170761882327497\n",
      "[3334,     1] loss: 0.0017395105678588152\n",
      "[3335,     1] loss: 0.0017794223967939615\n",
      "[3336,     1] loss: 0.001815639203414321\n",
      "[3337,     1] loss: 0.0018600373296067119\n",
      "[3338,     1] loss: 0.0018902374431490898\n",
      "[3339,     1] loss: 0.0019212518818676472\n",
      "[3340,     1] loss: 0.0019229984609410167\n",
      "[3341,     1] loss: 0.0019121121149510145\n",
      "[3342,     1] loss: 0.0018665448296815157\n",
      "[3343,     1] loss: 0.0018073574174195528\n",
      "[3344,     1] loss: 0.001736809965223074\n",
      "[3345,     1] loss: 0.0016747983172535896\n",
      "[3346,     1] loss: 0.0016294901724904776\n",
      "[3347,     1] loss: 0.001607078593224287\n",
      "[3348,     1] loss: 0.001606629346497357\n",
      "[3349,     1] loss: 0.0016225611325353384\n",
      "[3350,     1] loss: 0.0016462249914184213\n",
      "[3351,     1] loss: 0.0016693738289177418\n",
      "[3352,     1] loss: 0.0016887772362679243\n",
      "[3353,     1] loss: 0.0016975640319287777\n",
      "[3354,     1] loss: 0.0017026013229042292\n",
      "[3355,     1] loss: 0.0016955169849097729\n",
      "[3356,     1] loss: 0.001686950447037816\n",
      "[3357,     1] loss: 0.0016702462453395128\n",
      "[3358,     1] loss: 0.0016523810336366296\n",
      "[3359,     1] loss: 0.001632894854992628\n",
      "[3360,     1] loss: 0.0016158033395186067\n",
      "[3361,     1] loss: 0.0016022312920540571\n",
      "[3362,     1] loss: 0.0015937015414237976\n",
      "[3363,     1] loss: 0.0015899575082585216\n",
      "[3364,     1] loss: 0.0015903376042842865\n",
      "[3365,     1] loss: 0.0015933882677927613\n",
      "[3366,     1] loss: 0.0015978643205016851\n",
      "[3367,     1] loss: 0.0016036401502788067\n",
      "[3368,     1] loss: 0.0016091594006866217\n",
      "[3369,     1] loss: 0.001615403569303453\n",
      "[3370,     1] loss: 0.00162068463396281\n",
      "[3371,     1] loss: 0.0016286298632621765\n",
      "[3372,     1] loss: 0.0016350415535271168\n",
      "[3373,     1] loss: 0.0016437363810837269\n",
      "[3374,     1] loss: 0.0016511660069227219\n",
      "[3375,     1] loss: 0.0016609292943030596\n",
      "[3376,     1] loss: 0.0016685156151652336\n",
      "[3377,     1] loss: 0.001678605331107974\n",
      "[3378,     1] loss: 0.001685021910816431\n",
      "[3379,     1] loss: 0.00169204524718225\n",
      "[3380,     1] loss: 0.001694010803475976\n",
      "[3381,     1] loss: 0.0016931621357798576\n",
      "[3382,     1] loss: 0.0016854377463459969\n",
      "[3383,     1] loss: 0.0016751614166423678\n",
      "[3384,     1] loss: 0.0016601781826466322\n",
      "[3385,     1] loss: 0.0016436774749308825\n",
      "[3386,     1] loss: 0.001625207718461752\n",
      "[3387,     1] loss: 0.001608321093954146\n",
      "[3388,     1] loss: 0.0015943406615406275\n",
      "[3389,     1] loss: 0.0015851638745516539\n",
      "[3390,     1] loss: 0.0015804909635335207\n",
      "[3391,     1] loss: 0.0015796137740835547\n",
      "[3392,     1] loss: 0.0015812122728675604\n",
      "[3393,     1] loss: 0.0015839794650673866\n",
      "[3394,     1] loss: 0.00158707145601511\n",
      "[3395,     1] loss: 0.0015904400497674942\n",
      "[3396,     1] loss: 0.0015946757048368454\n",
      "[3397,     1] loss: 0.001600084942765534\n",
      "[3398,     1] loss: 0.0016099021304398775\n",
      "[3399,     1] loss: 0.0016236957162618637\n",
      "[3400,     1] loss: 0.0016459382604807615\n",
      "[3401,     1] loss: 0.0016709626652300358\n",
      "[3402,     1] loss: 0.0017094515496864915\n",
      "[3403,     1] loss: 0.0017477462533861399\n",
      "[3404,     1] loss: 0.0018078176071867347\n",
      "[3405,     1] loss: 0.001862675417214632\n",
      "[3406,     1] loss: 0.0019452995620667934\n",
      "[3407,     1] loss: 0.0020065365824848413\n",
      "[3408,     1] loss: 0.002073362935334444\n",
      "[3409,     1] loss: 0.002087492262944579\n",
      "[3410,     1] loss: 0.0020630641374737024\n",
      "[3411,     1] loss: 0.0019688219763338566\n",
      "[3412,     1] loss: 0.0018423814326524734\n",
      "[3413,     1] loss: 0.0017078828532248735\n",
      "[3414,     1] loss: 0.0016063544899225235\n",
      "[3415,     1] loss: 0.0015572516713291407\n",
      "[3416,     1] loss: 0.0015607615932822227\n",
      "[3417,     1] loss: 0.0016009509563446045\n",
      "[3418,     1] loss: 0.0016542596276849508\n",
      "[3419,     1] loss: 0.0017011690651997924\n",
      "[3420,     1] loss: 0.0017219304572790861\n",
      "[3421,     1] loss: 0.0017200426664203405\n",
      "[3422,     1] loss: 0.0016892150742933154\n",
      "[3423,     1] loss: 0.0016481336206197739\n",
      "[3424,     1] loss: 0.0016021737828850746\n",
      "[3425,     1] loss: 0.00156590121332556\n",
      "[3426,     1] loss: 0.0015459741698578\n",
      "[3427,     1] loss: 0.0015431985957548022\n",
      "[3428,     1] loss: 0.0015532856341451406\n",
      "[3429,     1] loss: 0.0015696799382567406\n",
      "[3430,     1] loss: 0.001585857244208455\n",
      "[3431,     1] loss: 0.0015959847951307893\n",
      "[3432,     1] loss: 0.001599061768501997\n",
      "[3433,     1] loss: 0.0015927706845104694\n",
      "[3434,     1] loss: 0.0015824539586901665\n",
      "[3435,     1] loss: 0.0015679043717682362\n",
      "[3436,     1] loss: 0.0015543821500614285\n",
      "[3437,     1] loss: 0.0015423812437802553\n",
      "[3438,     1] loss: 0.0015342351980507374\n",
      "[3439,     1] loss: 0.0015303022228181362\n",
      "[3440,     1] loss: 0.001530140871182084\n",
      "[3441,     1] loss: 0.0015326810535043478\n",
      "[3442,     1] loss: 0.001536912051960826\n",
      "[3443,     1] loss: 0.001542196492664516\n",
      "[3444,     1] loss: 0.001547008752822876\n",
      "[3445,     1] loss: 0.0015519001754000783\n",
      "[3446,     1] loss: 0.001555108930915594\n",
      "[3447,     1] loss: 0.0015585593646392226\n",
      "[3448,     1] loss: 0.0015597778838127851\n",
      "[3449,     1] loss: 0.0015602536732330918\n",
      "[3450,     1] loss: 0.0015586009249091148\n",
      "[3451,     1] loss: 0.0015570467803627253\n",
      "[3452,     1] loss: 0.0015535822603851557\n",
      "[3453,     1] loss: 0.0015484931645914912\n",
      "[3454,     1] loss: 0.0015420345589518547\n",
      "[3455,     1] loss: 0.001535407966002822\n",
      "[3456,     1] loss: 0.0015294485492631793\n",
      "[3457,     1] loss: 0.0015241936780512333\n",
      "[3458,     1] loss: 0.0015200843336060643\n",
      "[3459,     1] loss: 0.001517054159194231\n",
      "[3460,     1] loss: 0.0015150172403082252\n",
      "[3461,     1] loss: 0.0015136973233893514\n",
      "[3462,     1] loss: 0.0015128192026168108\n",
      "[3463,     1] loss: 0.0015121870674192905\n",
      "[3464,     1] loss: 0.0015116942813619971\n",
      "[3465,     1] loss: 0.0015114278066903353\n",
      "[3466,     1] loss: 0.001511431997641921\n",
      "[3467,     1] loss: 0.001511937822215259\n",
      "[3468,     1] loss: 0.0015131526160985231\n",
      "[3469,     1] loss: 0.0015157060697674751\n",
      "[3470,     1] loss: 0.00152023381087929\n",
      "[3471,     1] loss: 0.0015279494691640139\n",
      "[3472,     1] loss: 0.0015415770467370749\n",
      "[3473,     1] loss: 0.0015613025752827525\n",
      "[3474,     1] loss: 0.0015944414772093296\n",
      "[3475,     1] loss: 0.0016370319062843919\n",
      "[3476,     1] loss: 0.0017052164766937494\n",
      "[3477,     1] loss: 0.0017843792447820306\n",
      "[3478,     1] loss: 0.001900168601423502\n",
      "[3479,     1] loss: 0.0020170246716588736\n",
      "[3480,     1] loss: 0.0021700579673051834\n",
      "[3481,     1] loss: 0.0022787144407629967\n",
      "[3482,     1] loss: 0.0023882798850536346\n",
      "[3483,     1] loss: 0.002370681846514344\n",
      "[3484,     1] loss: 0.0022599585354328156\n",
      "[3485,     1] loss: 0.0020219869911670685\n",
      "[3486,     1] loss: 0.001772080548107624\n",
      "[3487,     1] loss: 0.001586016034707427\n",
      "[3488,     1] loss: 0.0015199983026832342\n",
      "[3489,     1] loss: 0.0015635623130947351\n",
      "[3490,     1] loss: 0.0016631109174340963\n",
      "[3491,     1] loss: 0.001759229926392436\n",
      "[3492,     1] loss: 0.0017993070650845766\n",
      "[3493,     1] loss: 0.0017811934230849147\n",
      "[3494,     1] loss: 0.001705882721580565\n",
      "[3495,     1] loss: 0.0016151906456798315\n",
      "[3496,     1] loss: 0.0015384620055556297\n",
      "[3497,     1] loss: 0.001503007602877915\n",
      "[3498,     1] loss: 0.0015122093027457595\n",
      "[3499,     1] loss: 0.001551003661006689\n",
      "[3500,     1] loss: 0.001595181180164218\n",
      "[3501,     1] loss: 0.0016172106843441725\n",
      "[3502,     1] loss: 0.0016120170475915074\n",
      "[3503,     1] loss: 0.0015765639254823327\n",
      "[3504,     1] loss: 0.001533510279841721\n",
      "[3505,     1] loss: 0.001498416648246348\n",
      "[3506,     1] loss: 0.0014836641494184732\n",
      "[3507,     1] loss: 0.0014884425327181816\n",
      "[3508,     1] loss: 0.0015038596466183662\n",
      "[3509,     1] loss: 0.0015193605795502663\n",
      "[3510,     1] loss: 0.0015277888160198927\n",
      "[3511,     1] loss: 0.0015288942959159613\n",
      "[3512,     1] loss: 0.0015217381296679378\n",
      "[3513,     1] loss: 0.0015102156903594732\n",
      "[3514,     1] loss: 0.0014963592402637005\n",
      "[3515,     1] loss: 0.001483708736486733\n",
      "[3516,     1] loss: 0.0014755341690033674\n",
      "[3517,     1] loss: 0.0014736396260559559\n",
      "[3518,     1] loss: 0.0014772937865927815\n",
      "[3519,     1] loss: 0.001484028180129826\n",
      "[3520,     1] loss: 0.0014902495313435793\n",
      "[3521,     1] loss: 0.0014928866876289248\n",
      "[3522,     1] loss: 0.0014922089176252484\n",
      "[3523,     1] loss: 0.0014877839712426066\n",
      "[3524,     1] loss: 0.0014827314298599958\n",
      "[3525,     1] loss: 0.0014770312700420618\n",
      "[3526,     1] loss: 0.001472504111006856\n",
      "[3527,     1] loss: 0.0014686720678582788\n",
      "[3528,     1] loss: 0.001465918612666428\n",
      "[3529,     1] loss: 0.0014645878691226244\n",
      "[3530,     1] loss: 0.0014646068448200822\n",
      "[3531,     1] loss: 0.0014656089479103684\n",
      "[3532,     1] loss: 0.0014673525001853704\n",
      "[3533,     1] loss: 0.0014693111879751086\n",
      "[3534,     1] loss: 0.0014708718517795205\n",
      "[3535,     1] loss: 0.0014722697669640183\n",
      "[3536,     1] loss: 0.00147281086537987\n",
      "[3537,     1] loss: 0.001473908545449376\n",
      "[3538,     1] loss: 0.0014741430059075356\n",
      "[3539,     1] loss: 0.0014742407947778702\n",
      "[3540,     1] loss: 0.0014732854906469584\n",
      "[3541,     1] loss: 0.0014723495114594698\n",
      "[3542,     1] loss: 0.0014705106150358915\n",
      "[3543,     1] loss: 0.0014688274823129177\n",
      "[3544,     1] loss: 0.0014662991743534803\n",
      "[3545,     1] loss: 0.001464025815948844\n",
      "[3546,     1] loss: 0.0014619684079661965\n",
      "[3547,     1] loss: 0.0014606029726564884\n",
      "[3548,     1] loss: 0.0014597399858757854\n",
      "[3549,     1] loss: 0.001459423452615738\n",
      "[3550,     1] loss: 0.001459564664401114\n",
      "[3551,     1] loss: 0.001460168743506074\n",
      "[3552,     1] loss: 0.0014610406942665577\n",
      "[3553,     1] loss: 0.001461890758946538\n",
      "[3554,     1] loss: 0.0014623587485402822\n",
      "[3555,     1] loss: 0.0014619342982769012\n",
      "[3556,     1] loss: 0.0014603746822103858\n",
      "[3557,     1] loss: 0.0014581663999706507\n",
      "[3558,     1] loss: 0.0014562265714630485\n",
      "[3559,     1] loss: 0.0014561859425157309\n",
      "[3560,     1] loss: 0.0014587568584829569\n",
      "[3561,     1] loss: 0.001465489505790174\n",
      "[3562,     1] loss: 0.0014754703734070063\n",
      "[3563,     1] loss: 0.0014923951821401715\n",
      "[3564,     1] loss: 0.0015125321224331856\n",
      "[3565,     1] loss: 0.0015442112926393747\n",
      "[3566,     1] loss: 0.0015789801254868507\n",
      "[3567,     1] loss: 0.0016309882048517466\n",
      "[3568,     1] loss: 0.0016824067570269108\n",
      "[3569,     1] loss: 0.0017472866456955671\n",
      "[3570,     1] loss: 0.0018000183627009392\n",
      "[3571,     1] loss: 0.0018594800494611263\n",
      "[3572,     1] loss: 0.0018844896694645286\n",
      "[3573,     1] loss: 0.0019053533906117082\n",
      "[3574,     1] loss: 0.0018658123444765806\n",
      "[3575,     1] loss: 0.001793653704226017\n",
      "[3576,     1] loss: 0.0016863723285496235\n",
      "[3577,     1] loss: 0.001581577816978097\n",
      "[3578,     1] loss: 0.0014957115054130554\n",
      "[3579,     1] loss: 0.0014466129941865802\n",
      "[3580,     1] loss: 0.0014363606460392475\n",
      "[3581,     1] loss: 0.001456567901186645\n",
      "[3582,     1] loss: 0.001492606708779931\n",
      "[3583,     1] loss: 0.00152904586866498\n",
      "[3584,     1] loss: 0.0015570030082017183\n",
      "[3585,     1] loss: 0.00156499189324677\n",
      "[3586,     1] loss: 0.0015577151207253337\n",
      "[3587,     1] loss: 0.0015320201637223363\n",
      "[3588,     1] loss: 0.001502264873124659\n",
      "[3589,     1] loss: 0.0014692811528220773\n",
      "[3590,     1] loss: 0.0014422951499000192\n",
      "[3591,     1] loss: 0.0014259704621508718\n",
      "[3592,     1] loss: 0.0014213749673217535\n",
      "[3593,     1] loss: 0.0014261524192988873\n",
      "[3594,     1] loss: 0.0014359327033162117\n",
      "[3595,     1] loss: 0.0014471871545538306\n",
      "[3596,     1] loss: 0.0014565680176019669\n",
      "[3597,     1] loss: 0.001464109169319272\n",
      "[3598,     1] loss: 0.0014671457465738058\n",
      "[3599,     1] loss: 0.0014681005850434303\n",
      "[3600,     1] loss: 0.0014641196466982365\n",
      "[3601,     1] loss: 0.0014587607001885772\n",
      "[3602,     1] loss: 0.0014499459648504853\n",
      "[3603,     1] loss: 0.001440142747014761\n",
      "[3604,     1] loss: 0.0014300752663984895\n",
      "[3605,     1] loss: 0.0014218399301171303\n",
      "[3606,     1] loss: 0.001415369682945311\n",
      "[3607,     1] loss: 0.0014112114440649748\n",
      "[3608,     1] loss: 0.0014090706827118993\n",
      "[3609,     1] loss: 0.0014085047878324986\n",
      "[3610,     1] loss: 0.00140883750282228\n",
      "[3611,     1] loss: 0.0014099462423473597\n",
      "[3612,     1] loss: 0.0014115370577201247\n",
      "[3613,     1] loss: 0.0014134598895907402\n",
      "[3614,     1] loss: 0.001416306826286018\n",
      "[3615,     1] loss: 0.0014200799632817507\n",
      "[3616,     1] loss: 0.0014257286675274372\n",
      "[3617,     1] loss: 0.001432177610695362\n",
      "[3618,     1] loss: 0.001441869419068098\n",
      "[3619,     1] loss: 0.0014521785778924823\n",
      "[3620,     1] loss: 0.0014693227130919695\n",
      "[3621,     1] loss: 0.0014870534650981426\n",
      "[3622,     1] loss: 0.0015123751945793629\n",
      "[3623,     1] loss: 0.0015362614067271352\n",
      "[3624,     1] loss: 0.0015700472285971045\n",
      "[3625,     1] loss: 0.0015979447634890676\n",
      "[3626,     1] loss: 0.0016352715902030468\n",
      "[3627,     1] loss: 0.0016581807285547256\n",
      "[3628,     1] loss: 0.0016872920095920563\n",
      "[3629,     1] loss: 0.001689176307991147\n",
      "[3630,     1] loss: 0.0016772942617535591\n",
      "[3631,     1] loss: 0.001638233894482255\n",
      "[3632,     1] loss: 0.0015882521402090788\n",
      "[3633,     1] loss: 0.0015289498260244727\n",
      "[3634,     1] loss: 0.001474494463764131\n",
      "[3635,     1] loss: 0.0014313050778582692\n",
      "[3636,     1] loss: 0.0014047401491552591\n",
      "[3637,     1] loss: 0.0013952443841844797\n",
      "[3638,     1] loss: 0.00139903137460351\n",
      "[3639,     1] loss: 0.0014115404337644577\n",
      "[3640,     1] loss: 0.0014287563972175121\n",
      "[3641,     1] loss: 0.0014473219634965062\n",
      "[3642,     1] loss: 0.0014638975262641907\n",
      "[3643,     1] loss: 0.001481583109125495\n",
      "[3644,     1] loss: 0.0014931889018043876\n",
      "[3645,     1] loss: 0.0015051658265292645\n",
      "[3646,     1] loss: 0.0015073268441483378\n",
      "[3647,     1] loss: 0.0015063297469168901\n",
      "[3648,     1] loss: 0.0014943636488169432\n",
      "[3649,     1] loss: 0.001479575177654624\n",
      "[3650,     1] loss: 0.0014589069178327918\n",
      "[3651,     1] loss: 0.0014391022268682718\n",
      "[3652,     1] loss: 0.0014201747253537178\n",
      "[3653,     1] loss: 0.0014047299046069384\n",
      "[3654,     1] loss: 0.0013937352923676372\n",
      "[3655,     1] loss: 0.0013870777329429984\n",
      "[3656,     1] loss: 0.0013839681632816792\n",
      "[3657,     1] loss: 0.0013834881829097867\n",
      "[3658,     1] loss: 0.001384950359351933\n",
      "[3659,     1] loss: 0.001387884491123259\n",
      "[3660,     1] loss: 0.0013921026838943362\n",
      "[3661,     1] loss: 0.0013967975974082947\n",
      "[3662,     1] loss: 0.001402593799866736\n",
      "[3663,     1] loss: 0.0014077425003051758\n",
      "[3664,     1] loss: 0.001415635459125042\n",
      "[3665,     1] loss: 0.0014227046631276608\n",
      "[3666,     1] loss: 0.0014349408447742462\n",
      "[3667,     1] loss: 0.0014470148598775268\n",
      "[3668,     1] loss: 0.0014675746206194162\n",
      "[3669,     1] loss: 0.0014864546246826649\n",
      "[3670,     1] loss: 0.0015155165456235409\n",
      "[3671,     1] loss: 0.001539943739771843\n",
      "[3672,     1] loss: 0.001577394432388246\n",
      "[3673,     1] loss: 0.0016059002373367548\n",
      "[3674,     1] loss: 0.0016408232040703297\n",
      "[3675,     1] loss: 0.0016572554595768452\n",
      "[3676,     1] loss: 0.001667544711381197\n",
      "[3677,     1] loss: 0.0016517052426934242\n",
      "[3678,     1] loss: 0.0016220076940953732\n",
      "[3679,     1] loss: 0.0015717365313321352\n",
      "[3680,     1] loss: 0.001517060911282897\n",
      "[3681,     1] loss: 0.0014610069338232279\n",
      "[3682,     1] loss: 0.0014147661859169602\n",
      "[3683,     1] loss: 0.0013825679197907448\n",
      "[3684,     1] loss: 0.0013667140156030655\n",
      "[3685,     1] loss: 0.001365218311548233\n",
      "[3686,     1] loss: 0.0013743463205173612\n",
      "[3687,     1] loss: 0.0013899561017751694\n",
      "[3688,     1] loss: 0.001407693955115974\n",
      "[3689,     1] loss: 0.001426464063115418\n",
      "[3690,     1] loss: 0.0014413102762773633\n",
      "[3691,     1] loss: 0.0014558184193447232\n",
      "[3692,     1] loss: 0.0014628355856984854\n",
      "[3693,     1] loss: 0.0014698955928906798\n",
      "[3694,     1] loss: 0.0014677373692393303\n",
      "[3695,     1] loss: 0.0014658484142273664\n",
      "[3696,     1] loss: 0.0014551958302035928\n",
      "[3697,     1] loss: 0.0014426137786358595\n",
      "[3698,     1] loss: 0.0014249468222260475\n",
      "[3699,     1] loss: 0.0014074677601456642\n",
      "[3700,     1] loss: 0.0013899138430133462\n",
      "[3701,     1] loss: 0.0013744549360126257\n",
      "[3702,     1] loss: 0.001362547161988914\n",
      "[3703,     1] loss: 0.0013548997230827808\n",
      "[3704,     1] loss: 0.0013512246077880263\n",
      "[3705,     1] loss: 0.0013505977112799883\n",
      "[3706,     1] loss: 0.0013521126238629222\n",
      "[3707,     1] loss: 0.0013549942523241043\n",
      "[3708,     1] loss: 0.0013588082510977983\n",
      "[3709,     1] loss: 0.0013630285393446684\n",
      "[3710,     1] loss: 0.0013682175194844604\n",
      "[3711,     1] loss: 0.0013732583029195666\n",
      "[3712,     1] loss: 0.0013810747768729925\n",
      "[3713,     1] loss: 0.0013891533017158508\n",
      "[3714,     1] loss: 0.001402342808432877\n",
      "[3715,     1] loss: 0.0014159918064251542\n",
      "[3716,     1] loss: 0.0014397648628801107\n",
      "[3717,     1] loss: 0.001464513479731977\n",
      "[3718,     1] loss: 0.0015022935112938285\n",
      "[3719,     1] loss: 0.0015390680637210608\n",
      "[3720,     1] loss: 0.0015972035471349955\n",
      "[3721,     1] loss: 0.0016475915908813477\n",
      "[3722,     1] loss: 0.0017206124030053616\n",
      "[3723,     1] loss: 0.0017656558193266392\n",
      "[3724,     1] loss: 0.001821541809476912\n",
      "[3725,     1] loss: 0.0018276572227478027\n",
      "[3726,     1] loss: 0.0018008581828325987\n",
      "[3727,     1] loss: 0.0017193451058119535\n",
      "[3728,     1] loss: 0.0016147415153682232\n",
      "[3729,     1] loss: 0.0015025148168206215\n",
      "[3730,     1] loss: 0.0014134935336187482\n",
      "[3731,     1] loss: 0.0013615526258945465\n",
      "[3732,     1] loss: 0.001351041253656149\n",
      "[3733,     1] loss: 0.0013729326892644167\n",
      "[3734,     1] loss: 0.001411808654665947\n",
      "[3735,     1] loss: 0.001453022938221693\n",
      "[3736,     1] loss: 0.001480643404647708\n",
      "[3737,     1] loss: 0.0014910551253706217\n",
      "[3738,     1] loss: 0.001478581689298153\n",
      "[3739,     1] loss: 0.0014554837252944708\n",
      "[3740,     1] loss: 0.0014204747276380658\n",
      "[3741,     1] loss: 0.0013851217227056623\n",
      "[3742,     1] loss: 0.0013550829607993364\n",
      "[3743,     1] loss: 0.0013360569719225168\n",
      "[3744,     1] loss: 0.001329472754150629\n",
      "[3745,     1] loss: 0.0013327818596735597\n",
      "[3746,     1] loss: 0.0013422179035842419\n",
      "[3747,     1] loss: 0.0013536377809941769\n",
      "[3748,     1] loss: 0.0013640137622132897\n",
      "[3749,     1] loss: 0.0013703774893656373\n",
      "[3750,     1] loss: 0.0013750456273555756\n",
      "[3751,     1] loss: 0.0013741825241595507\n",
      "[3752,     1] loss: 0.0013724870514124632\n",
      "[3753,     1] loss: 0.0013660588301718235\n",
      "[3754,     1] loss: 0.0013593953335657716\n",
      "[3755,     1] loss: 0.0013502815272659063\n",
      "[3756,     1] loss: 0.001341804163530469\n",
      "[3757,     1] loss: 0.00133354717399925\n",
      "[3758,     1] loss: 0.0013268430484458804\n",
      "[3759,     1] loss: 0.0013214928330853581\n",
      "[3760,     1] loss: 0.0013177035143598914\n",
      "[3761,     1] loss: 0.0013152153696864843\n",
      "[3762,     1] loss: 0.0013138495851308107\n",
      "[3763,     1] loss: 0.0013134429464116693\n",
      "[3764,     1] loss: 0.0013140991795808077\n",
      "[3765,     1] loss: 0.0013156156055629253\n",
      "[3766,     1] loss: 0.0013181838439777493\n",
      "[3767,     1] loss: 0.0013221915578469634\n",
      "[3768,     1] loss: 0.001327583217062056\n",
      "[3769,     1] loss: 0.001335772918537259\n",
      "[3770,     1] loss: 0.0013457275927066803\n",
      "[3771,     1] loss: 0.0013612608890980482\n",
      "[3772,     1] loss: 0.0013787481002509594\n",
      "[3773,     1] loss: 0.001405707560479641\n",
      "[3774,     1] loss: 0.0014343693619593978\n",
      "[3775,     1] loss: 0.0014783983351662755\n",
      "[3776,     1] loss: 0.0015214928425848484\n",
      "[3777,     1] loss: 0.0015865317545831203\n",
      "[3778,     1] loss: 0.0016441082116216421\n",
      "[3779,     1] loss: 0.0017289654351770878\n",
      "[3780,     1] loss: 0.0017811614088714123\n",
      "[3781,     1] loss: 0.0018336829962208867\n",
      "[3782,     1] loss: 0.0018176884623244405\n",
      "[3783,     1] loss: 0.0017720031319186091\n",
      "[3784,     1] loss: 0.0016623642295598984\n",
      "[3785,     1] loss: 0.001538451062515378\n",
      "[3786,     1] loss: 0.0014184456085786223\n",
      "[3787,     1] loss: 0.0013374456902965903\n",
      "[3788,     1] loss: 0.0013080285862088203\n",
      "[3789,     1] loss: 0.0013255743542686105\n",
      "[3790,     1] loss: 0.0013717012479901314\n",
      "[3791,     1] loss: 0.0014216562267392874\n",
      "[3792,     1] loss: 0.001459497376345098\n",
      "[3793,     1] loss: 0.0014688251540064812\n",
      "[3794,     1] loss: 0.0014548545004799962\n",
      "[3795,     1] loss: 0.0014171316288411617\n",
      "[3796,     1] loss: 0.0013720933347940445\n",
      "[3797,     1] loss: 0.0013307193294167519\n",
      "[3798,     1] loss: 0.0013043032959103584\n",
      "[3799,     1] loss: 0.001295850845053792\n",
      "[3800,     1] loss: 0.0013028965331614017\n",
      "[3801,     1] loss: 0.001319006085395813\n",
      "[3802,     1] loss: 0.001336386427283287\n",
      "[3803,     1] loss: 0.001349943340755999\n",
      "[3804,     1] loss: 0.0013559468789026141\n",
      "[3805,     1] loss: 0.0013566449051722884\n",
      "[3806,     1] loss: 0.0013496712781488895\n",
      "[3807,     1] loss: 0.0013406533980742097\n",
      "[3808,     1] loss: 0.0013278065016493201\n",
      "[3809,     1] loss: 0.0013148840516805649\n",
      "[3810,     1] loss: 0.0013024145737290382\n",
      "[3811,     1] loss: 0.0012927548959851265\n",
      "[3812,     1] loss: 0.0012869407655671239\n",
      "[3813,     1] loss: 0.0012850707862526178\n",
      "[3814,     1] loss: 0.001286077662371099\n",
      "[3815,     1] loss: 0.0012886561453342438\n",
      "[3816,     1] loss: 0.0012916199630126357\n",
      "[3817,     1] loss: 0.0012940698070451617\n",
      "[3818,     1] loss: 0.0012961162719875574\n",
      "[3819,     1] loss: 0.001297270180657506\n",
      "[3820,     1] loss: 0.0012983159394934773\n",
      "[3821,     1] loss: 0.0012982164043933153\n",
      "[3822,     1] loss: 0.001298355171456933\n",
      "[3823,     1] loss: 0.0012972201220691204\n",
      "[3824,     1] loss: 0.0012969000963494182\n",
      "[3825,     1] loss: 0.0012960481690242887\n",
      "[3826,     1] loss: 0.001295953756198287\n",
      "[3827,     1] loss: 0.0012951564276590943\n",
      "[3828,     1] loss: 0.0012941340683028102\n",
      "[3829,     1] loss: 0.0012926141498610377\n",
      "[3830,     1] loss: 0.0012912290403619409\n",
      "[3831,     1] loss: 0.0012894351966679096\n",
      "[3832,     1] loss: 0.001287738443352282\n",
      "[3833,     1] loss: 0.0012860457645729184\n",
      "[3834,     1] loss: 0.0012847882462665439\n",
      "[3835,     1] loss: 0.001283843070268631\n",
      "[3836,     1] loss: 0.0012839767150580883\n",
      "[3837,     1] loss: 0.0012841850984841585\n",
      "[3838,     1] loss: 0.001286523649469018\n",
      "[3839,     1] loss: 0.0012895262334495783\n",
      "[3840,     1] loss: 0.0012957978760823607\n",
      "[3841,     1] loss: 0.0013030945556238294\n",
      "[3842,     1] loss: 0.0013158991932868958\n",
      "[3843,     1] loss: 0.0013291483046486974\n",
      "[3844,     1] loss: 0.0013502852525562048\n",
      "[3845,     1] loss: 0.0013713904190808535\n",
      "[3846,     1] loss: 0.0014056272339075804\n",
      "[3847,     1] loss: 0.0014399498468264937\n",
      "[3848,     1] loss: 0.0014959820546209812\n",
      "[3849,     1] loss: 0.0015501317102462053\n",
      "[3850,     1] loss: 0.0016358497086912394\n",
      "[3851,     1] loss: 0.00170726771466434\n",
      "[3852,     1] loss: 0.0018016556277871132\n",
      "[3853,     1] loss: 0.001851912122219801\n",
      "[3854,     1] loss: 0.0019018419552594423\n",
      "[3855,     1] loss: 0.0018660086207091808\n",
      "[3856,     1] loss: 0.0017860319931060076\n",
      "[3857,     1] loss: 0.0016425589565187693\n",
      "[3858,     1] loss: 0.0014899829402565956\n",
      "[3859,     1] loss: 0.0013596812495961785\n",
      "[3860,     1] loss: 0.0012849763734266162\n",
      "[3861,     1] loss: 0.0012722763931378722\n",
      "[3862,     1] loss: 0.0013077716575935483\n",
      "[3863,     1] loss: 0.0013655704678967595\n",
      "[3864,     1] loss: 0.0014180555008351803\n",
      "[3865,     1] loss: 0.001454853219911456\n",
      "[3866,     1] loss: 0.0014564984012395144\n",
      "[3867,     1] loss: 0.0014372257282957435\n",
      "[3868,     1] loss: 0.0013911204878240824\n",
      "[3869,     1] loss: 0.0013397620059549809\n",
      "[3870,     1] loss: 0.0012923779431730509\n",
      "[3871,     1] loss: 0.0012615832965821028\n",
      "[3872,     1] loss: 0.0012518828734755516\n",
      "[3873,     1] loss: 0.001260407269001007\n",
      "[3874,     1] loss: 0.0012792858760803938\n",
      "[3875,     1] loss: 0.0012990327086299658\n",
      "[3876,     1] loss: 0.001313523855060339\n",
      "[3877,     1] loss: 0.001317135989665985\n",
      "[3878,     1] loss: 0.0013117025373503566\n",
      "[3879,     1] loss: 0.001297340146265924\n",
      "[3880,     1] loss: 0.0012801372213289142\n",
      "[3881,     1] loss: 0.0012630484998226166\n",
      "[3882,     1] loss: 0.0012501628370955586\n",
      "[3883,     1] loss: 0.0012426883913576603\n",
      "[3884,     1] loss: 0.0012409844202920794\n",
      "[3885,     1] loss: 0.0012438023695722222\n",
      "[3886,     1] loss: 0.0012490191729739308\n",
      "[3887,     1] loss: 0.0012551065301522613\n",
      "[3888,     1] loss: 0.0012598253088071942\n",
      "[3889,     1] loss: 0.001263809041120112\n",
      "[3890,     1] loss: 0.0012648866977542639\n",
      "[3891,     1] loss: 0.0012645692331716418\n",
      "[3892,     1] loss: 0.0012618314940482378\n",
      "[3893,     1] loss: 0.001258436474017799\n",
      "[3894,     1] loss: 0.001253753900527954\n",
      "[3895,     1] loss: 0.0012489724904298782\n",
      "[3896,     1] loss: 0.0012438948033377528\n",
      "[3897,     1] loss: 0.0012394393561407924\n",
      "[3898,     1] loss: 0.0012357563246041536\n",
      "[3899,     1] loss: 0.00123319192789495\n",
      "[3900,     1] loss: 0.0012314217165112495\n",
      "[3901,     1] loss: 0.0012303809635341167\n",
      "[3902,     1] loss: 0.0012299229856580496\n",
      "[3903,     1] loss: 0.0012299353256821632\n",
      "[3904,     1] loss: 0.0012303866678848863\n",
      "[3905,     1] loss: 0.0012313657207414508\n",
      "[3906,     1] loss: 0.001233080867677927\n",
      "[3907,     1] loss: 0.0012357570230960846\n",
      "[3908,     1] loss: 0.001240360550582409\n",
      "[3909,     1] loss: 0.0012465488398447633\n",
      "[3910,     1] loss: 0.0012569304089993238\n",
      "[3911,     1] loss: 0.0012698101345449686\n",
      "[3912,     1] loss: 0.0012896371772512794\n",
      "[3913,     1] loss: 0.0013126363046467304\n",
      "[3914,     1] loss: 0.001350641017779708\n",
      "[3915,     1] loss: 0.001392541453242302\n",
      "[3916,     1] loss: 0.0014637761050835252\n",
      "[3917,     1] loss: 0.0015350265894085169\n",
      "[3918,     1] loss: 0.0016425920184701681\n",
      "[3919,     1] loss: 0.0017338163452222943\n",
      "[3920,     1] loss: 0.0018671166617423296\n",
      "[3921,     1] loss: 0.0019494795706123114\n",
      "[3922,     1] loss: 0.002044213470071554\n",
      "[3923,     1] loss: 0.002027227310463786\n",
      "[3924,     1] loss: 0.0019654741045087576\n",
      "[3925,     1] loss: 0.001779069541953504\n",
      "[3926,     1] loss: 0.0015627348329871893\n",
      "[3927,     1] loss: 0.0013636420480906963\n",
      "[3928,     1] loss: 0.001251410460099578\n",
      "[3929,     1] loss: 0.001243997598066926\n",
      "[3930,     1] loss: 0.0013141054660081863\n",
      "[3931,     1] loss: 0.0014108901377767324\n",
      "[3932,     1] loss: 0.0014809186104685068\n",
      "[3933,     1] loss: 0.0015040262369439006\n",
      "[3934,     1] loss: 0.0014615054242312908\n",
      "[3935,     1] loss: 0.0013850757386535406\n",
      "[3936,     1] loss: 0.0012989295646548271\n",
      "[3937,     1] loss: 0.0012381360866129398\n",
      "[3938,     1] loss: 0.0012182672508060932\n",
      "[3939,     1] loss: 0.0012358082458376884\n",
      "[3940,     1] loss: 0.00127227243501693\n",
      "[3941,     1] loss: 0.001304779201745987\n",
      "[3942,     1] loss: 0.0013189278542995453\n",
      "[3943,     1] loss: 0.0013084599049761891\n",
      "[3944,     1] loss: 0.0012823084834963083\n",
      "[3945,     1] loss: 0.0012498394353315234\n",
      "[3946,     1] loss: 0.0012238824274390936\n",
      "[3947,     1] loss: 0.0012112458935007453\n",
      "[3948,     1] loss: 0.001212438102811575\n",
      "[3949,     1] loss: 0.0012227860279381275\n",
      "[3950,     1] loss: 0.0012354524806141853\n",
      "[3951,     1] loss: 0.001245662453584373\n",
      "[3952,     1] loss: 0.0012487481581047177\n",
      "[3953,     1] loss: 0.0012460562866181135\n",
      "[3954,     1] loss: 0.001236847136169672\n",
      "[3955,     1] loss: 0.0012253914028406143\n",
      "[3956,     1] loss: 0.0012137697776779532\n",
      "[3957,     1] loss: 0.00120523851364851\n",
      "[3958,     1] loss: 0.0012008254416286945\n",
      "[3959,     1] loss: 0.001200620667077601\n",
      "[3960,     1] loss: 0.0012033908860757947\n",
      "[3961,     1] loss: 0.001207596156746149\n",
      "[3962,     1] loss: 0.0012117965379729867\n",
      "[3963,     1] loss: 0.0012145941145718098\n",
      "[3964,     1] loss: 0.0012162382481619716\n",
      "[3965,     1] loss: 0.0012155710719525814\n",
      "[3966,     1] loss: 0.0012137391604483128\n",
      "[3967,     1] loss: 0.0012101131724193692\n",
      "[3968,     1] loss: 0.0012063870672136545\n",
      "[3969,     1] loss: 0.0012020475696772337\n",
      "[3970,     1] loss: 0.0011980764102190733\n",
      "[3971,     1] loss: 0.0011947611346840858\n",
      "[3972,     1] loss: 0.0011925125727429986\n",
      "[3973,     1] loss: 0.0011912414338439703\n",
      "[3974,     1] loss: 0.0011909158201888204\n",
      "[3975,     1] loss: 0.001191318267956376\n",
      "[3976,     1] loss: 0.001192182651720941\n",
      "[3977,     1] loss: 0.0011935126967728138\n",
      "[3978,     1] loss: 0.0011949461186304688\n",
      "[3979,     1] loss: 0.001196571858599782\n",
      "[3980,     1] loss: 0.001198147190734744\n",
      "[3981,     1] loss: 0.00120013568084687\n",
      "[3982,     1] loss: 0.0012020624708384275\n",
      "[3983,     1] loss: 0.0012051468947902322\n",
      "[3984,     1] loss: 0.0012082066386938095\n",
      "[3985,     1] loss: 0.0012137540616095066\n",
      "[3986,     1] loss: 0.0012192706344649196\n",
      "[3987,     1] loss: 0.0012281723320484161\n",
      "[3988,     1] loss: 0.0012366409646347165\n",
      "[3989,     1] loss: 0.0012486014747992158\n",
      "[3990,     1] loss: 0.0012587095843628049\n",
      "[3991,     1] loss: 0.0012719584628939629\n",
      "[3992,     1] loss: 0.0012807977618649602\n",
      "[3993,     1] loss: 0.001290192361921072\n",
      "[3994,     1] loss: 0.0012929722433909774\n",
      "[3995,     1] loss: 0.0012961365282535553\n",
      "[3996,     1] loss: 0.0012918930733576417\n",
      "[3997,     1] loss: 0.001286255195736885\n",
      "[3998,     1] loss: 0.0012754453346133232\n",
      "[3999,     1] loss: 0.0012662146473303437\n",
      "[4000,     1] loss: 0.0012549272505566478\n",
      "[4001,     1] loss: 0.0012455959804356098\n",
      "[4002,     1] loss: 0.0012360853143036366\n",
      "[4003,     1] loss: 0.0012296292698010802\n",
      "[4004,     1] loss: 0.0012230784632265568\n",
      "[4005,     1] loss: 0.0012172067072242498\n",
      "[4006,     1] loss: 0.0012107575312256813\n",
      "[4007,     1] loss: 0.0012043289607390761\n",
      "[4008,     1] loss: 0.0011974648805335164\n",
      "[4009,     1] loss: 0.0011906696017831564\n",
      "[4010,     1] loss: 0.0011840228689834476\n",
      "[4011,     1] loss: 0.0011784619418904185\n",
      "[4012,     1] loss: 0.0011739813489839435\n",
      "[4013,     1] loss: 0.0011709877289831638\n",
      "[4014,     1] loss: 0.0011694224085658789\n",
      "[4015,     1] loss: 0.0011689704842865467\n",
      "[4016,     1] loss: 0.001169116934761405\n",
      "[4017,     1] loss: 0.0011694710701704025\n",
      "[4018,     1] loss: 0.0011695963330566883\n",
      "[4019,     1] loss: 0.0011693311389535666\n",
      "[4020,     1] loss: 0.0011686633806675673\n",
      "[4021,     1] loss: 0.0011678143637254834\n",
      "[4022,     1] loss: 0.0011669537052512169\n",
      "[4023,     1] loss: 0.0011664882767945528\n",
      "[4024,     1] loss: 0.0011667698854580522\n",
      "[4025,     1] loss: 0.0011687112273648381\n",
      "[4026,     1] loss: 0.0011728222016245127\n",
      "[4027,     1] loss: 0.0011813483433797956\n",
      "[4028,     1] loss: 0.0011951576452702284\n",
      "[4029,     1] loss: 0.0012225034879520535\n",
      "[4030,     1] loss: 0.001263520447537303\n",
      "[4031,     1] loss: 0.0013463011709973216\n",
      "[4032,     1] loss: 0.0014681515749543905\n",
      "[4033,     1] loss: 0.0016968066338449717\n",
      "[4034,     1] loss: 0.0020026396960020065\n",
      "[4035,     1] loss: 0.002568349475041032\n",
      "[4036,     1] loss: 0.003167372429743409\n",
      "[4037,     1] loss: 0.004079122561961412\n",
      "[4038,     1] loss: 0.004438087344169617\n",
      "[4039,     1] loss: 0.004387258552014828\n",
      "[4040,     1] loss: 0.003175361081957817\n",
      "[4041,     1] loss: 0.0018373860511928797\n",
      "[4042,     1] loss: 0.001253405585885048\n",
      "[4043,     1] loss: 0.0016895558219403028\n",
      "[4044,     1] loss: 0.002430533291772008\n",
      "[4045,     1] loss: 0.002578320447355509\n",
      "[4046,     1] loss: 0.002068349625915289\n",
      "[4047,     1] loss: 0.0014016266213729978\n",
      "[4048,     1] loss: 0.0012611632701009512\n",
      "[4049,     1] loss: 0.001628201687708497\n",
      "[4050,     1] loss: 0.0019362103193998337\n",
      "[4051,     1] loss: 0.001821089768782258\n",
      "[4052,     1] loss: 0.0014048127923160791\n",
      "[4053,     1] loss: 0.001189026515930891\n",
      "[4054,     1] loss: 0.0013484798837453127\n",
      "[4055,     1] loss: 0.001585521036759019\n",
      "[4056,     1] loss: 0.0015784287825226784\n",
      "[4057,     1] loss: 0.0013336967676877975\n",
      "[4058,     1] loss: 0.0011686201905831695\n",
      "[4059,     1] loss: 0.0012445289175957441\n",
      "[4060,     1] loss: 0.0013995766639709473\n",
      "[4061,     1] loss: 0.0014076309744268656\n",
      "[4062,     1] loss: 0.0012617745669558644\n",
      "[4063,     1] loss: 0.0011590321082621813\n",
      "[4064,     1] loss: 0.0012012890074402094\n",
      "[4065,     1] loss: 0.0012891062069684267\n",
      "[4066,     1] loss: 0.0012961766915395856\n",
      "[4067,     1] loss: 0.001222869846969843\n",
      "[4068,     1] loss: 0.0011620274744927883\n",
      "[4069,     1] loss: 0.00116764847189188\n",
      "[4070,     1] loss: 0.001213153824210167\n",
      "[4071,     1] loss: 0.001235715695656836\n",
      "[4072,     1] loss: 0.0012031581718474627\n",
      "[4073,     1] loss: 0.001155821606516838\n",
      "[4074,     1] loss: 0.0011457714717835188\n",
      "[4075,     1] loss: 0.0011741304770112038\n",
      "[4076,     1] loss: 0.0011956781381741166\n",
      "[4077,     1] loss: 0.0011815604520961642\n",
      "[4078,     1] loss: 0.0011525368317961693\n",
      "[4079,     1] loss: 0.0011394156608730555\n",
      "[4080,     1] loss: 0.001151205156929791\n",
      "[4081,     1] loss: 0.0011683054035529494\n",
      "[4082,     1] loss: 0.0011669753585010767\n",
      "[4083,     1] loss: 0.0011505447328090668\n",
      "[4084,     1] loss: 0.0011369771091267467\n",
      "[4085,     1] loss: 0.001138127874583006\n",
      "[4086,     1] loss: 0.0011470699682831764\n",
      "[4087,     1] loss: 0.001151168835349381\n",
      "[4088,     1] loss: 0.0011471424950286746\n",
      "[4089,     1] loss: 0.0011378828203305602\n",
      "[4090,     1] loss: 0.0011320437770336866\n",
      "[4091,     1] loss: 0.0011336947791278362\n",
      "[4092,     1] loss: 0.001138716354034841\n",
      "[4093,     1] loss: 0.0011404321994632483\n",
      "[4094,     1] loss: 0.001136187231168151\n",
      "[4095,     1] loss: 0.0011307020904496312\n",
      "[4096,     1] loss: 0.0011283474741503596\n",
      "[4097,     1] loss: 0.0011299168691039085\n",
      "[4098,     1] loss: 0.0011326519306749105\n",
      "[4099,     1] loss: 0.0011328964028507471\n",
      "[4100,     1] loss: 0.0011302530765533447\n",
      "[4101,     1] loss: 0.001126916497014463\n",
      "[4102,     1] loss: 0.0011252578115090728\n",
      "[4103,     1] loss: 0.0011255413992330432\n",
      "[4104,     1] loss: 0.0011266174260526896\n",
      "[4105,     1] loss: 0.001127163297496736\n",
      "[4106,     1] loss: 0.0011259946040809155\n",
      "[4107,     1] loss: 0.0011239158920943737\n",
      "[4108,     1] loss: 0.001122016808949411\n",
      "[4109,     1] loss: 0.0011214425321668386\n",
      "[4110,     1] loss: 0.0011218063300475478\n",
      "[4111,     1] loss: 0.001122135203331709\n",
      "[4112,     1] loss: 0.0011217964347451925\n",
      "[4113,     1] loss: 0.0011207457864657044\n",
      "[4114,     1] loss: 0.0011194247053936124\n",
      "[4115,     1] loss: 0.0011183498427271843\n",
      "[4116,     1] loss: 0.001117802457883954\n",
      "[4117,     1] loss: 0.0011176120024174452\n",
      "[4118,     1] loss: 0.0011174840619787574\n",
      "[4119,     1] loss: 0.0011172322556376457\n",
      "[4120,     1] loss: 0.0011166459880769253\n",
      "[4121,     1] loss: 0.001115894876420498\n",
      "[4122,     1] loss: 0.0011150301434099674\n",
      "[4123,     1] loss: 0.0011142698349431157\n",
      "[4124,     1] loss: 0.0011137209367007017\n",
      "[4125,     1] loss: 0.0011133700609207153\n",
      "[4126,     1] loss: 0.0011131193023175001\n",
      "[4127,     1] loss: 0.0011127348989248276\n",
      "[4128,     1] loss: 0.001112197176553309\n",
      "[4129,     1] loss: 0.0011115407105535269\n",
      "[4130,     1] loss: 0.0011108756298199296\n",
      "[4131,     1] loss: 0.0011102636344730854\n",
      "[4132,     1] loss: 0.0011097218375653028\n",
      "[4133,     1] loss: 0.0011092349886894226\n",
      "[4134,     1] loss: 0.0011087609454989433\n",
      "[4135,     1] loss: 0.0011083552381023765\n",
      "[4136,     1] loss: 0.0011079292744398117\n",
      "[4137,     1] loss: 0.001107467687688768\n",
      "[4138,     1] loss: 0.0011069664033129811\n",
      "[4139,     1] loss: 0.0011064267018809915\n",
      "[4140,     1] loss: 0.0011058624368160963\n",
      "[4141,     1] loss: 0.0011053059715777636\n",
      "[4142,     1] loss: 0.0011047741863876581\n",
      "[4143,     1] loss: 0.0011042861733585596\n",
      "[4144,     1] loss: 0.001103785471059382\n",
      "[4145,     1] loss: 0.001103272894397378\n",
      "[4146,     1] loss: 0.0011027844157069921\n",
      "[4147,     1] loss: 0.0011023023398593068\n",
      "[4148,     1] loss: 0.001101830042898655\n",
      "[4149,     1] loss: 0.0011013387702405453\n",
      "[4150,     1] loss: 0.0011008749715983868\n",
      "[4151,     1] loss: 0.0011003892868757248\n",
      "[4152,     1] loss: 0.0010999033693224192\n",
      "[4153,     1] loss: 0.001099408371374011\n",
      "[4154,     1] loss: 0.001098905224353075\n",
      "[4155,     1] loss: 0.0010984130203723907\n",
      "[4156,     1] loss: 0.001097949454560876\n",
      "[4157,     1] loss: 0.0010974835604429245\n",
      "[4158,     1] loss: 0.0010969946160912514\n",
      "[4159,     1] loss: 0.001096536056138575\n",
      "[4160,     1] loss: 0.0010960852960124612\n",
      "[4161,     1] loss: 0.0010955978650599718\n",
      "[4162,     1] loss: 0.0010951670119538903\n",
      "[4163,     1] loss: 0.0010947241680696607\n",
      "[4164,     1] loss: 0.0010942701483145356\n",
      "[4165,     1] loss: 0.0010938100749626756\n",
      "[4166,     1] loss: 0.0010933488374575973\n",
      "[4167,     1] loss: 0.0010928874835371971\n",
      "[4168,     1] loss: 0.0010924580274149776\n",
      "[4169,     1] loss: 0.0010920680360868573\n",
      "[4170,     1] loss: 0.0010916981846094131\n",
      "[4171,     1] loss: 0.0010912889847531915\n",
      "[4172,     1] loss: 0.0010909647680819035\n",
      "[4173,     1] loss: 0.0010906709358096123\n",
      "[4174,     1] loss: 0.0010903486981987953\n",
      "[4175,     1] loss: 0.0010899121407419443\n",
      "[4176,     1] loss: 0.0010894141159951687\n",
      "[4177,     1] loss: 0.0010888584656640887\n",
      "[4178,     1] loss: 0.0010883680079132318\n",
      "[4179,     1] loss: 0.0010879337787628174\n",
      "[4180,     1] loss: 0.0010875801090151072\n",
      "[4181,     1] loss: 0.0010873186402022839\n",
      "[4182,     1] loss: 0.0010872388957068324\n",
      "[4183,     1] loss: 0.001087270793505013\n",
      "[4184,     1] loss: 0.001087527140043676\n",
      "[4185,     1] loss: 0.001088026794604957\n",
      "[4186,     1] loss: 0.0010888490360230207\n",
      "[4187,     1] loss: 0.0010900762863457203\n",
      "[4188,     1] loss: 0.0010917556937783957\n",
      "[4189,     1] loss: 0.0010939543135464191\n",
      "[4190,     1] loss: 0.0010969473514705896\n",
      "[4191,     1] loss: 0.001100341323763132\n",
      "[4192,     1] loss: 0.0011039460077881813\n",
      "[4193,     1] loss: 0.0011070204200223088\n",
      "[4194,     1] loss: 0.0011091988999396563\n",
      "[4195,     1] loss: 0.0011093151988461614\n",
      "[4196,     1] loss: 0.0011079818941652775\n",
      "[4197,     1] loss: 0.0011047223815694451\n",
      "[4198,     1] loss: 0.001101375324651599\n",
      "[4199,     1] loss: 0.0010975112672895193\n",
      "[4200,     1] loss: 0.0010949296411126852\n",
      "[4201,     1] loss: 0.001092545222491026\n",
      "[4202,     1] loss: 0.0010911502176895738\n",
      "[4203,     1] loss: 0.0010890873381868005\n",
      "[4204,     1] loss: 0.0010872246930375695\n",
      "[4205,     1] loss: 0.0010845535434782505\n",
      "[4206,     1] loss: 0.0010817910078912973\n",
      "[4207,     1] loss: 0.0010790405794978142\n",
      "[4208,     1] loss: 0.001076808082871139\n",
      "[4209,     1] loss: 0.00107526034116745\n",
      "[4210,     1] loss: 0.00107451225630939\n",
      "[4211,     1] loss: 0.0010743937455117702\n",
      "[4212,     1] loss: 0.0010746920015662909\n",
      "[4213,     1] loss: 0.0010751753579825163\n",
      "[4214,     1] loss: 0.0010756613919511437\n",
      "[4215,     1] loss: 0.0010760003933683038\n",
      "[4216,     1] loss: 0.0010762318270280957\n",
      "[4217,     1] loss: 0.0010767478961497545\n",
      "[4218,     1] loss: 0.0010776963317766786\n",
      "[4219,     1] loss: 0.001079923240467906\n",
      "[4220,     1] loss: 0.001083120470866561\n",
      "[4221,     1] loss: 0.0010891635902225971\n",
      "[4222,     1] loss: 0.0010963869281113148\n",
      "[4223,     1] loss: 0.0011075458023697138\n",
      "[4224,     1] loss: 0.0011189061915501952\n",
      "[4225,     1] loss: 0.001137544633820653\n",
      "[4226,     1] loss: 0.0011546423193067312\n",
      "[4227,     1] loss: 0.001180659863166511\n",
      "[4228,     1] loss: 0.001201252918690443\n",
      "[4229,     1] loss: 0.0012322505936026573\n",
      "[4230,     1] loss: 0.0012514041736721992\n",
      "[4231,     1] loss: 0.0012766396393999457\n",
      "[4232,     1] loss: 0.0012817390961572528\n",
      "[4233,     1] loss: 0.0012853151420131326\n",
      "[4234,     1] loss: 0.0012664920650422573\n",
      "[4235,     1] loss: 0.0012389831244945526\n",
      "[4236,     1] loss: 0.0011983603471890092\n",
      "[4237,     1] loss: 0.0011558046098798513\n",
      "[4238,     1] loss: 0.0011166479671373963\n",
      "[4239,     1] loss: 0.0010875897714868188\n",
      "[4240,     1] loss: 0.0010704526212066412\n",
      "[4241,     1] loss: 0.0010649999603629112\n",
      "[4242,     1] loss: 0.001068647252395749\n",
      "[4243,     1] loss: 0.0010778523283079267\n",
      "[4244,     1] loss: 0.001089470461010933\n",
      "[4245,     1] loss: 0.0011008423753082752\n",
      "[4246,     1] loss: 0.0011120145209133625\n",
      "[4247,     1] loss: 0.0011202206369489431\n",
      "[4248,     1] loss: 0.0011259503662586212\n",
      "[4249,     1] loss: 0.0011270237155258656\n",
      "[4250,     1] loss: 0.0011257316218689084\n",
      "[4251,     1] loss: 0.0011198795400559902\n",
      "[4252,     1] loss: 0.0011125447927042842\n",
      "[4253,     1] loss: 0.001102781854569912\n",
      "[4254,     1] loss: 0.0010926617542281747\n",
      "[4255,     1] loss: 0.0010826605139300227\n",
      "[4256,     1] loss: 0.001074235886335373\n",
      "[4257,     1] loss: 0.0010669766925275326\n",
      "[4258,     1] loss: 0.0010614005150273442\n",
      "[4259,     1] loss: 0.0010572928003966808\n",
      "[4260,     1] loss: 0.0010547260753810406\n",
      "[4261,     1] loss: 0.0010536606423556805\n",
      "[4262,     1] loss: 0.0010540314251556993\n",
      "[4263,     1] loss: 0.0010557774221524596\n",
      "[4264,     1] loss: 0.00105886475648731\n",
      "[4265,     1] loss: 0.001063405186869204\n",
      "[4266,     1] loss: 0.0010692838113754988\n",
      "[4267,     1] loss: 0.0010766842169687152\n",
      "[4268,     1] loss: 0.0010850607650354505\n",
      "[4269,     1] loss: 0.001094964100047946\n",
      "[4270,     1] loss: 0.0011051069013774395\n",
      "[4271,     1] loss: 0.0011195038678124547\n",
      "[4272,     1] loss: 0.001135984668508172\n",
      "[4273,     1] loss: 0.0011657488066703081\n",
      "[4274,     1] loss: 0.0012029706267639995\n",
      "[4275,     1] loss: 0.0012693380704149604\n",
      "[4276,     1] loss: 0.0013461533235386014\n",
      "[4277,     1] loss: 0.0014784408267587423\n",
      "[4278,     1] loss: 0.0016142481472343206\n",
      "[4279,     1] loss: 0.0018359895329922438\n",
      "[4280,     1] loss: 0.00201228354126215\n",
      "[4281,     1] loss: 0.0022489537950605154\n",
      "[4282,     1] loss: 0.0022999022621661425\n",
      "[4283,     1] loss: 0.0022795728873461485\n",
      "[4284,     1] loss: 0.00200326694175601\n",
      "[4285,     1] loss: 0.0016423732740804553\n",
      "[4286,     1] loss: 0.0012855040840804577\n",
      "[4287,     1] loss: 0.0010926310205832124\n",
      "[4288,     1] loss: 0.0011028415756300092\n",
      "[4289,     1] loss: 0.0012490905355662107\n",
      "[4290,     1] loss: 0.0014131972566246986\n",
      "[4291,     1] loss: 0.001481923507526517\n",
      "[4292,     1] loss: 0.0014325324445962906\n",
      "[4293,     1] loss: 0.0012873958330601454\n",
      "[4294,     1] loss: 0.0011412567691877484\n",
      "[4295,     1] loss: 0.0010625642025843263\n",
      "[4296,     1] loss: 0.0010746337939053774\n",
      "[4297,     1] loss: 0.0011437288485467434\n",
      "[4298,     1] loss: 0.0012106476351618767\n",
      "[4299,     1] loss: 0.00123625248670578\n",
      "[4300,     1] loss: 0.0012015653774142265\n",
      "[4301,     1] loss: 0.0011343060759827495\n",
      "[4302,     1] loss: 0.0010705497115850449\n",
      "[4303,     1] loss: 0.001041507232002914\n",
      "[4304,     1] loss: 0.00105289148632437\n",
      "[4305,     1] loss: 0.0010869839461520314\n",
      "[4306,     1] loss: 0.0011176102561876178\n",
      "[4307,     1] loss: 0.0011239597806707025\n",
      "[4308,     1] loss: 0.0011063077254220843\n",
      "[4309,     1] loss: 0.0010733692906796932\n",
      "[4310,     1] loss: 0.0010443272767588496\n",
      "[4311,     1] loss: 0.001031737308949232\n",
      "[4312,     1] loss: 0.0010374030098319054\n",
      "[4313,     1] loss: 0.0010529564460739493\n",
      "[4314,     1] loss: 0.0010667437454685569\n",
      "[4315,     1] loss: 0.0010710346978157759\n",
      "[4316,     1] loss: 0.0010638872627168894\n",
      "[4317,     1] loss: 0.0010511991567909718\n",
      "[4318,     1] loss: 0.0010379698360338807\n",
      "[4319,     1] loss: 0.001029424136504531\n",
      "[4320,     1] loss: 0.0010275756940245628\n",
      "[4321,     1] loss: 0.0010309721110388637\n",
      "[4322,     1] loss: 0.0010362782049924135\n",
      "[4323,     1] loss: 0.0010405658977106214\n",
      "[4324,     1] loss: 0.001042485237121582\n",
      "[4325,     1] loss: 0.0010409790556877851\n",
      "[4326,     1] loss: 0.0010375315323472023\n",
      "[4327,     1] loss: 0.0010323987808078527\n",
      "[4328,     1] loss: 0.0010276536922901869\n",
      "[4329,     1] loss: 0.0010238413233309984\n",
      "[4330,     1] loss: 0.0010217614471912384\n",
      "[4331,     1] loss: 0.0010214056819677353\n",
      "[4332,     1] loss: 0.0010222932323813438\n",
      "[4333,     1] loss: 0.0010237577371299267\n",
      "[4334,     1] loss: 0.0010250794002786279\n",
      "[4335,     1] loss: 0.001026021782308817\n",
      "[4336,     1] loss: 0.001026255777105689\n",
      "[4337,     1] loss: 0.0010262368014082313\n",
      "[4338,     1] loss: 0.001025384641252458\n",
      "[4339,     1] loss: 0.001024408033117652\n",
      "[4340,     1] loss: 0.0010229309555143118\n",
      "[4341,     1] loss: 0.0010214056819677353\n",
      "[4342,     1] loss: 0.0010196180082857609\n",
      "[4343,     1] loss: 0.0010178819065913558\n",
      "[4344,     1] loss: 0.0010163031984120607\n",
      "[4345,     1] loss: 0.0010150710586458445\n",
      "[4346,     1] loss: 0.0010141778038814664\n",
      "[4347,     1] loss: 0.0010136066703125834\n",
      "[4348,     1] loss: 0.0010132044553756714\n",
      "[4349,     1] loss: 0.001012917491607368\n",
      "[4350,     1] loss: 0.0010127252899110317\n",
      "[4351,     1] loss: 0.0010127151617780328\n",
      "[4352,     1] loss: 0.0010128782596439123\n",
      "[4353,     1] loss: 0.0010133777977898717\n",
      "[4354,     1] loss: 0.001014413544908166\n",
      "[4355,     1] loss: 0.0010157405631616712\n",
      "[4356,     1] loss: 0.0010175920324400067\n",
      "[4357,     1] loss: 0.0010195891372859478\n",
      "[4358,     1] loss: 0.0010220465483143926\n",
      "[4359,     1] loss: 0.0010243698488920927\n",
      "[4360,     1] loss: 0.0010278471745550632\n",
      "[4361,     1] loss: 0.0010308829369023442\n",
      "[4362,     1] loss: 0.0010355293052271008\n",
      "[4363,     1] loss: 0.0010388841619715095\n",
      "[4364,     1] loss: 0.00104364356957376\n",
      "[4365,     1] loss: 0.0010462516220286489\n",
      "[4366,     1] loss: 0.001049647107720375\n",
      "[4367,     1] loss: 0.001050298335030675\n",
      "[4368,     1] loss: 0.0010506459511816502\n",
      "[4369,     1] loss: 0.0010482711950317025\n",
      "[4370,     1] loss: 0.0010457797907292843\n",
      "[4371,     1] loss: 0.0010412868577986956\n",
      "[4372,     1] loss: 0.0010371943935751915\n",
      "[4373,     1] loss: 0.0010315632680431008\n",
      "[4374,     1] loss: 0.0010254509979858994\n",
      "[4375,     1] loss: 0.0010193267371505499\n",
      "[4376,     1] loss: 0.001014033448882401\n",
      "[4377,     1] loss: 0.001009601866826415\n",
      "[4378,     1] loss: 0.0010064485250040889\n",
      "[4379,     1] loss: 0.0010042014764621854\n",
      "[4380,     1] loss: 0.001002713106572628\n",
      "[4381,     1] loss: 0.0010017772438004613\n",
      "[4382,     1] loss: 0.0010012647835537791\n",
      "[4383,     1] loss: 0.0010011125123128295\n",
      "[4384,     1] loss: 0.0010012229904532433\n",
      "[4385,     1] loss: 0.0010017335880547762\n",
      "[4386,     1] loss: 0.0010027241660282016\n",
      "[4387,     1] loss: 0.0010043185902759433\n",
      "[4388,     1] loss: 0.0010067366529256105\n",
      "[4389,     1] loss: 0.0010104607790708542\n",
      "[4390,     1] loss: 0.0010157922515645623\n",
      "[4391,     1] loss: 0.001025118981488049\n",
      "[4392,     1] loss: 0.001037801499478519\n",
      "[4393,     1] loss: 0.0010600349633023143\n",
      "[4394,     1] loss: 0.0010892030550166965\n",
      "[4395,     1] loss: 0.0011406767880544066\n",
      "[4396,     1] loss: 0.001204796601086855\n",
      "[4397,     1] loss: 0.0013119187206029892\n",
      "[4398,     1] loss: 0.0014352586586028337\n",
      "[4399,     1] loss: 0.0016327304765582085\n",
      "[4400,     1] loss: 0.001825937768444419\n",
      "[4401,     1] loss: 0.0021036523394286633\n",
      "[4402,     1] loss: 0.002287158276885748\n",
      "[4403,     1] loss: 0.002503793453797698\n",
      "[4404,     1] loss: 0.0024338983930647373\n",
      "[4405,     1] loss: 0.0022216872312128544\n",
      "[4406,     1] loss: 0.0017569412011653185\n",
      "[4407,     1] loss: 0.0013102779630571604\n",
      "[4408,     1] loss: 0.0010439028264954686\n",
      "[4409,     1] loss: 0.0010470948182046413\n",
      "[4410,     1] loss: 0.0012385742738842964\n",
      "[4411,     1] loss: 0.0014446364948526025\n",
      "[4412,     1] loss: 0.0015373008791357279\n",
      "[4413,     1] loss: 0.0014461982063949108\n",
      "[4414,     1] loss: 0.0012585259974002838\n",
      "[4415,     1] loss: 0.0010782232275232673\n",
      "[4416,     1] loss: 0.0010077106999233365\n",
      "[4417,     1] loss: 0.001057629007846117\n",
      "[4418,     1] loss: 0.0011599218705669045\n",
      "[4419,     1] loss: 0.0012289447477087379\n",
      "[4420,     1] loss: 0.0012141104089096189\n",
      "[4421,     1] loss: 0.001134700607508421\n",
      "[4422,     1] loss: 0.0010443131905049086\n",
      "[4423,     1] loss: 0.0009977732552215457\n",
      "[4424,     1] loss: 0.0010100870858877897\n",
      "[4425,     1] loss: 0.0010561100207269192\n",
      "[4426,     1] loss: 0.0010953701566904783\n",
      "[4427,     1] loss: 0.0010994861368089914\n",
      "[4428,     1] loss: 0.0010727887274697423\n",
      "[4429,     1] loss: 0.0010294420644640923\n",
      "[4430,     1] loss: 0.0009961590403690934\n",
      "[4431,     1] loss: 0.0009871210204437375\n",
      "[4432,     1] loss: 0.0010001810733228922\n",
      "[4433,     1] loss: 0.0010206680744886398\n",
      "[4434,     1] loss: 0.0010328090284019709\n",
      "[4435,     1] loss: 0.001030940213240683\n",
      "[4436,     1] loss: 0.0010156335774809122\n",
      "[4437,     1] loss: 0.0009970079408958554\n",
      "[4438,     1] loss: 0.0009839896811172366\n",
      "[4439,     1] loss: 0.0009812721982598305\n",
      "[4440,     1] loss: 0.0009869469795376062\n",
      "[4441,     1] loss: 0.0009950839448720217\n",
      "[4442,     1] loss: 0.0010000853799283504\n",
      "[4443,     1] loss: 0.0009988504461944103\n",
      "[4444,     1] loss: 0.0009934279369190335\n",
      "[4445,     1] loss: 0.000985788065008819\n",
      "[4446,     1] loss: 0.0009798191022127867\n",
      "[4447,     1] loss: 0.0009766665752977133\n",
      "[4448,     1] loss: 0.0009764358401298523\n",
      "[4449,     1] loss: 0.0009780852124094963\n",
      "[4450,     1] loss: 0.0009801826672628522\n",
      "[4451,     1] loss: 0.000981703633442521\n",
      "[4452,     1] loss: 0.0009818789549171925\n",
      "[4453,     1] loss: 0.0009811377385631204\n",
      "[4454,     1] loss: 0.0009791799820959568\n",
      "[4455,     1] loss: 0.000976883340626955\n",
      "[4456,     1] loss: 0.0009748049778863788\n",
      "[4457,     1] loss: 0.0009735910571180284\n",
      "[4458,     1] loss: 0.0009735036292113364\n",
      "[4459,     1] loss: 0.0009744645794853568\n",
      "[4460,     1] loss: 0.000976399052888155\n",
      "[4461,     1] loss: 0.0009789331816136837\n",
      "[4462,     1] loss: 0.000982006429694593\n",
      "[4463,     1] loss: 0.0009848104091361165\n",
      "[4464,     1] loss: 0.000987139530479908\n",
      "[4465,     1] loss: 0.0009883546736091375\n",
      "[4466,     1] loss: 0.0009883890161290765\n",
      "[4467,     1] loss: 0.0009867221815511584\n",
      "[4468,     1] loss: 0.000983559642918408\n",
      "[4469,     1] loss: 0.0009791161864995956\n",
      "[4470,     1] loss: 0.0009743015980347991\n",
      "[4471,     1] loss: 0.0009697575587779284\n",
      "[4472,     1] loss: 0.0009663703967817128\n",
      "[4473,     1] loss: 0.0009642528020776808\n",
      "[4474,     1] loss: 0.0009633732843212783\n",
      "[4475,     1] loss: 0.0009634661255404353\n",
      "[4476,     1] loss: 0.0009642270742915571\n",
      "[4477,     1] loss: 0.0009654894820414484\n",
      "[4478,     1] loss: 0.0009669153369031847\n",
      "[4479,     1] loss: 0.000968464242760092\n",
      "[4480,     1] loss: 0.0009696852066554129\n",
      "[4481,     1] loss: 0.0009705690899863839\n",
      "[4482,     1] loss: 0.0009709711885079741\n",
      "[4483,     1] loss: 0.000971567234955728\n",
      "[4484,     1] loss: 0.0009717881912365556\n",
      "[4485,     1] loss: 0.0009721707319840789\n",
      "[4486,     1] loss: 0.0009723798139020801\n",
      "[4487,     1] loss: 0.000973447400610894\n",
      "[4488,     1] loss: 0.0009740357054397464\n",
      "[4489,     1] loss: 0.0009749414166435599\n",
      "[4490,     1] loss: 0.0009751400211825967\n",
      "[4491,     1] loss: 0.0009758356027305126\n",
      "[4492,     1] loss: 0.0009757971856743097\n",
      "[4493,     1] loss: 0.0009756385115906596\n",
      "[4494,     1] loss: 0.0009747908916324377\n",
      "[4495,     1] loss: 0.0009743799455463886\n",
      "[4496,     1] loss: 0.0009733046172186732\n",
      "[4497,     1] loss: 0.0009723067050799727\n",
      "[4498,     1] loss: 0.0009710974991321564\n",
      "[4499,     1] loss: 0.0009708597790449858\n",
      "[4500,     1] loss: 0.0009704606491141021\n",
      "[4501,     1] loss: 0.0009710713056847453\n",
      "[4502,     1] loss: 0.0009715714259073138\n",
      "[4503,     1] loss: 0.0009734091581776738\n",
      "[4504,     1] loss: 0.0009748393204063177\n",
      "[4505,     1] loss: 0.0009776744991540909\n",
      "[4506,     1] loss: 0.0009798709070309997\n",
      "[4507,     1] loss: 0.0009845244931057096\n",
      "[4508,     1] loss: 0.0009881140431389213\n",
      "[4509,     1] loss: 0.0009947067592293024\n",
      "[4510,     1] loss: 0.0009998694295063615\n",
      "[4511,     1] loss: 0.0010102435480803251\n",
      "[4512,     1] loss: 0.0010182764381170273\n",
      "[4513,     1] loss: 0.0010304020252078772\n",
      "[4514,     1] loss: 0.001039512688294053\n",
      "[4515,     1] loss: 0.0010550344595685601\n",
      "[4516,     1] loss: 0.0010655248770490289\n",
      "[4517,     1] loss: 0.0010778512805700302\n",
      "[4518,     1] loss: 0.0010833098785951734\n",
      "[4519,     1] loss: 0.0010908611584454775\n",
      "[4520,     1] loss: 0.0010905333328992128\n",
      "[4521,     1] loss: 0.0010890787234529853\n",
      "[4522,     1] loss: 0.0010795576963573694\n",
      "[4523,     1] loss: 0.0010683557484298944\n",
      "[4524,     1] loss: 0.0010511350119486451\n",
      "[4525,     1] loss: 0.0010329352226108313\n",
      "[4526,     1] loss: 0.0010131546296179295\n",
      "[4527,     1] loss: 0.00099601736292243\n",
      "[4528,     1] loss: 0.0009808996692299843\n",
      "[4529,     1] loss: 0.0009696201886981726\n",
      "[4530,     1] loss: 0.0009619365446269512\n",
      "[4531,     1] loss: 0.0009579712641425431\n",
      "[4532,     1] loss: 0.0009568606037646532\n",
      "[4533,     1] loss: 0.0009577731252647936\n",
      "[4534,     1] loss: 0.00095987762324512\n",
      "[4535,     1] loss: 0.0009626687970012426\n",
      "[4536,     1] loss: 0.0009664077078923583\n",
      "[4537,     1] loss: 0.0009708635043352842\n",
      "[4538,     1] loss: 0.0009785126894712448\n",
      "[4539,     1] loss: 0.0009882604936137795\n",
      "[4540,     1] loss: 0.0010039202170446515\n",
      "[4541,     1] loss: 0.0010221173288300633\n",
      "[4542,     1] loss: 0.0010513991583138704\n",
      "[4543,     1] loss: 0.0010838322341442108\n",
      "[4544,     1] loss: 0.0011392964515835047\n",
      "[4545,     1] loss: 0.001196549041196704\n",
      "[4546,     1] loss: 0.0012914841063320637\n",
      "[4547,     1] loss: 0.0013807680224999785\n",
      "[4548,     1] loss: 0.0015131133841350675\n",
      "[4549,     1] loss: 0.00161193055100739\n",
      "[4550,     1] loss: 0.0017515525687485933\n",
      "[4551,     1] loss: 0.0018003028817474842\n",
      "[4552,     1] loss: 0.0018248315900564194\n",
      "[4553,     1] loss: 0.0017117426032200456\n",
      "[4554,     1] loss: 0.0015287541318684816\n",
      "[4555,     1] loss: 0.0012896375264972448\n",
      "[4556,     1] loss: 0.0010846997611224651\n",
      "[4557,     1] loss: 0.0009635643800720572\n",
      "[4558,     1] loss: 0.0009478310821577907\n",
      "[4559,     1] loss: 0.001013557892292738\n",
      "[4560,     1] loss: 0.0011103784199804068\n",
      "[4561,     1] loss: 0.0011887240689247847\n",
      "[4562,     1] loss: 0.0012113222619518638\n",
      "[4563,     1] loss: 0.0011821514926850796\n",
      "[4564,     1] loss: 0.0011080773547291756\n",
      "[4565,     1] loss: 0.0010266529861837626\n",
      "[4566,     1] loss: 0.0009638682240620255\n",
      "[4567,     1] loss: 0.0009381446288898587\n",
      "[4568,     1] loss: 0.0009486974449828267\n",
      "[4569,     1] loss: 0.0009806198067963123\n",
      "[4570,     1] loss: 0.001015217276290059\n",
      "[4571,     1] loss: 0.0010355416452512145\n",
      "[4572,     1] loss: 0.0010382599430158734\n",
      "[4573,     1] loss: 0.001020702882669866\n",
      "[4574,     1] loss: 0.0009939345763996243\n",
      "[4575,     1] loss: 0.0009643059456720948\n",
      "[4576,     1] loss: 0.0009417766705155373\n",
      "[4577,     1] loss: 0.0009304503910243511\n",
      "[4578,     1] loss: 0.0009306472493335605\n",
      "[4579,     1] loss: 0.0009388889884576201\n",
      "[4580,     1] loss: 0.0009499779553152621\n",
      "[4581,     1] loss: 0.0009601351921446621\n",
      "[4582,     1] loss: 0.0009651011205278337\n",
      "[4583,     1] loss: 0.0009652907028794289\n",
      "[4584,     1] loss: 0.0009593272116035223\n",
      "[4585,     1] loss: 0.000950891524553299\n",
      "[4586,     1] loss: 0.0009406449971720576\n",
      "[4587,     1] loss: 0.0009316887590102851\n",
      "[4588,     1] loss: 0.0009250418515875936\n",
      "[4589,     1] loss: 0.000921758939512074\n",
      "[4590,     1] loss: 0.0009216539328917861\n",
      "[4591,     1] loss: 0.0009238931233994663\n",
      "[4592,     1] loss: 0.0009276302298530936\n",
      "[4593,     1] loss: 0.0009317001677118242\n",
      "[4594,     1] loss: 0.0009360555559396744\n",
      "[4595,     1] loss: 0.0009396501118317246\n",
      "[4596,     1] loss: 0.0009434689418412745\n",
      "[4597,     1] loss: 0.0009461946319788694\n",
      "[4598,     1] loss: 0.0009496127022430301\n",
      "[4599,     1] loss: 0.0009516284335404634\n",
      "[4600,     1] loss: 0.0009548580273985863\n",
      "[4601,     1] loss: 0.000955818104557693\n",
      "[4602,     1] loss: 0.0009578114259056747\n",
      "[4603,     1] loss: 0.0009567328379489481\n",
      "[4604,     1] loss: 0.0009555881842970848\n",
      "[4605,     1] loss: 0.0009518784354440868\n",
      "[4606,     1] loss: 0.0009475137921981514\n",
      "[4607,     1] loss: 0.0009416879620403051\n",
      "[4608,     1] loss: 0.0009357304079458117\n",
      "[4609,     1] loss: 0.0009297006763517857\n",
      "[4610,     1] loss: 0.0009242305532097816\n",
      "[4611,     1] loss: 0.0009194836020469666\n",
      "[4612,     1] loss: 0.0009160736808553338\n",
      "[4613,     1] loss: 0.0009136217413470149\n",
      "[4614,     1] loss: 0.0009121033363044262\n",
      "[4615,     1] loss: 0.0009112764382734895\n",
      "[4616,     1] loss: 0.000910947797819972\n",
      "[4617,     1] loss: 0.0009109859820455313\n",
      "[4618,     1] loss: 0.0009112951229326427\n",
      "[4619,     1] loss: 0.0009119163150899112\n",
      "[4620,     1] loss: 0.000912986695766449\n",
      "[4621,     1] loss: 0.0009149014949798584\n",
      "[4622,     1] loss: 0.0009178539039567113\n",
      "[4623,     1] loss: 0.0009227676782757044\n",
      "[4624,     1] loss: 0.0009298257646150887\n",
      "[4625,     1] loss: 0.0009416700922884047\n",
      "[4626,     1] loss: 0.0009575122967362404\n",
      "[4627,     1] loss: 0.000983808538876474\n",
      "[4628,     1] loss: 0.0010158239165320992\n",
      "[4629,     1] loss: 0.0010685219895094633\n",
      "[4630,     1] loss: 0.0011276733130216599\n",
      "[4631,     1] loss: 0.0012216696050018072\n",
      "[4632,     1] loss: 0.001316920737735927\n",
      "[4633,     1] loss: 0.0014541496057063341\n",
      "[4634,     1] loss: 0.0015657399781048298\n",
      "[4635,     1] loss: 0.001720651052892208\n",
      "[4636,     1] loss: 0.0017913611372932792\n",
      "[4637,     1] loss: 0.0018694119062274694\n",
      "[4638,     1] loss: 0.0017988064792007208\n",
      "[4639,     1] loss: 0.0016629785532131791\n",
      "[4640,     1] loss: 0.0014201592421159148\n",
      "[4641,     1] loss: 0.0011758952168747783\n",
      "[4642,     1] loss: 0.000992078217677772\n",
      "[4643,     1] loss: 0.0009189513511955738\n",
      "[4644,     1] loss: 0.0009527907241135836\n",
      "[4645,     1] loss: 0.0010490937856957316\n",
      "[4646,     1] loss: 0.0011523658176884055\n",
      "[4647,     1] loss: 0.0012094166595488787\n",
      "[4648,     1] loss: 0.001212289440445602\n",
      "[4649,     1] loss: 0.0011493887286633253\n",
      "[4650,     1] loss: 0.0010614950442686677\n",
      "[4651,     1] loss: 0.0009740523528307676\n",
      "[4652,     1] loss: 0.0009200443746522069\n",
      "[4653,     1] loss: 0.0009106047218665481\n",
      "[4654,     1] loss: 0.0009364918223582208\n",
      "[4655,     1] loss: 0.0009755606297403574\n",
      "[4656,     1] loss: 0.0010050467681139708\n",
      "[4657,     1] loss: 0.0010136158671230078\n",
      "[4658,     1] loss: 0.0009979296009987593\n",
      "[4659,     1] loss: 0.0009688581340014935\n",
      "[4660,     1] loss: 0.0009360251715406775\n",
      "[4661,     1] loss: 0.0009114568820223212\n",
      "[4662,     1] loss: 0.0009004056919366121\n",
      "[4663,     1] loss: 0.0009030920336954296\n",
      "[4664,     1] loss: 0.0009150168625637889\n",
      "[4665,     1] loss: 0.0009295413037762046\n",
      "[4666,     1] loss: 0.0009419064735993743\n",
      "[4667,     1] loss: 0.000946132349781692\n",
      "[4668,     1] loss: 0.000942971499171108\n",
      "[4669,     1] loss: 0.0009320950484834611\n",
      "[4670,     1] loss: 0.0009188448311761022\n",
      "[4671,     1] loss: 0.0009058834984898567\n",
      "[4672,     1] loss: 0.0008967812755145133\n",
      "[4673,     1] loss: 0.0008925991132855415\n",
      "[4674,     1] loss: 0.000892914249561727\n",
      "[4675,     1] loss: 0.000896192854270339\n",
      "[4676,     1] loss: 0.0009007896296679974\n",
      "[4677,     1] loss: 0.0009056535200215876\n",
      "[4678,     1] loss: 0.0009095329442061484\n",
      "[4679,     1] loss: 0.0009127858793362975\n",
      "[4680,     1] loss: 0.0009143208735622466\n",
      "[4681,     1] loss: 0.0009156859014183283\n",
      "[4682,     1] loss: 0.0009151851409114897\n",
      "[4683,     1] loss: 0.0009149536490440369\n",
      "[4684,     1] loss: 0.000912750605493784\n",
      "[4685,     1] loss: 0.0009104595519602299\n",
      "[4686,     1] loss: 0.0009063953184522688\n",
      "[4687,     1] loss: 0.0009022740414366126\n",
      "[4688,     1] loss: 0.000897493096999824\n",
      "[4689,     1] loss: 0.0008929072646424174\n",
      "[4690,     1] loss: 0.0008892717305570841\n",
      "[4691,     1] loss: 0.0008868849254213274\n",
      "[4692,     1] loss: 0.0008856374770402908\n",
      "[4693,     1] loss: 0.0008851679740473628\n",
      "[4694,     1] loss: 0.0008852242026478052\n",
      "[4695,     1] loss: 0.0008855856722220778\n",
      "[4696,     1] loss: 0.0008862970862537622\n",
      "[4697,     1] loss: 0.0008874445338733494\n",
      "[4698,     1] loss: 0.0008893994963727891\n",
      "[4699,     1] loss: 0.0008919259998947382\n",
      "[4700,     1] loss: 0.0008955290541052818\n",
      "[4701,     1] loss: 0.000899835373274982\n",
      "[4702,     1] loss: 0.00090643553994596\n",
      "[4703,     1] loss: 0.0009139303583651781\n",
      "[4704,     1] loss: 0.000925385276786983\n",
      "[4705,     1] loss: 0.0009374705259688199\n",
      "[4706,     1] loss: 0.0009559333557263017\n",
      "[4707,     1] loss: 0.0009741170797497034\n",
      "[4708,     1] loss: 0.0010014125145971775\n",
      "[4709,     1] loss: 0.0010259209666401148\n",
      "[4710,     1] loss: 0.0010610215831547976\n",
      "[4711,     1] loss: 0.0010864888317883015\n",
      "[4712,     1] loss: 0.0011172882514074445\n",
      "[4713,     1] loss: 0.0011308174580335617\n",
      "[4714,     1] loss: 0.001139527652412653\n",
      "[4715,     1] loss: 0.0011264100903645158\n",
      "[4716,     1] loss: 0.0011020884849131107\n",
      "[4717,     1] loss: 0.0010602116817608476\n",
      "[4718,     1] loss: 0.0010145512642338872\n",
      "[4719,     1] loss: 0.0009670452564023435\n",
      "[4720,     1] loss: 0.0009272649185732007\n",
      "[4721,     1] loss: 0.000899776816368103\n",
      "[4722,     1] loss: 0.0008859919616952538\n",
      "[4723,     1] loss: 0.0008841389208100736\n",
      "[4724,     1] loss: 0.0008906523580662906\n",
      "[4725,     1] loss: 0.0009015249088406563\n",
      "[4726,     1] loss: 0.0009132757550105453\n",
      "[4727,     1] loss: 0.0009244715911336243\n",
      "[4728,     1] loss: 0.0009322984260506928\n",
      "[4729,     1] loss: 0.0009373126085847616\n",
      "[4730,     1] loss: 0.0009378959657624364\n",
      "[4731,     1] loss: 0.0009363265708088875\n",
      "[4732,     1] loss: 0.0009323807898908854\n",
      "[4733,     1] loss: 0.0009300606325268745\n",
      "[4734,     1] loss: 0.0009281969396397471\n",
      "[4735,     1] loss: 0.0009293208131566644\n",
      "[4736,     1] loss: 0.0009314832277595997\n",
      "[4737,     1] loss: 0.0009362846612930298\n",
      "[4738,     1] loss: 0.0009408124606125057\n",
      "[4739,     1] loss: 0.0009465878829360008\n",
      "[4740,     1] loss: 0.000949799781665206\n",
      "[4741,     1] loss: 0.0009514816338196397\n",
      "[4742,     1] loss: 0.0009493825491517782\n",
      "[4743,     1] loss: 0.0009465256007388234\n",
      "[4744,     1] loss: 0.000941298552788794\n",
      "[4745,     1] loss: 0.0009383985307067633\n",
      "[4746,     1] loss: 0.0009365866426378489\n",
      "[4747,     1] loss: 0.0009427648037672043\n",
      "[4748,     1] loss: 0.0009508014773018658\n",
      "[4749,     1] loss: 0.0009691350860521197\n",
      "[4750,     1] loss: 0.0009863815503194928\n",
      "[4751,     1] loss: 0.0010111527517437935\n",
      "[4752,     1] loss: 0.0010312009835615754\n",
      "[4753,     1] loss: 0.0010574986226856709\n",
      "[4754,     1] loss: 0.0010754719842225313\n",
      "[4755,     1] loss: 0.0010997963836416602\n",
      "[4756,     1] loss: 0.0011138742556795478\n",
      "[4757,     1] loss: 0.0011355592869222164\n",
      "[4758,     1] loss: 0.0011435718042775989\n",
      "[4759,     1] loss: 0.00115003134123981\n",
      "[4760,     1] loss: 0.0011396388290449977\n",
      "[4761,     1] loss: 0.001121078385040164\n",
      "[4762,     1] loss: 0.0010861789342015982\n",
      "[4763,     1] loss: 0.0010444128420203924\n",
      "[4764,     1] loss: 0.00099696044344455\n",
      "[4765,     1] loss: 0.0009527013171464205\n",
      "[4766,     1] loss: 0.0009148446260951459\n",
      "[4767,     1] loss: 0.0008874861523509026\n",
      "[4768,     1] loss: 0.0008714417926967144\n",
      "[4769,     1] loss: 0.0008656420395709574\n",
      "[4770,     1] loss: 0.0008677014266140759\n",
      "[4771,     1] loss: 0.0008750540437176824\n",
      "[4772,     1] loss: 0.0008857695502229035\n",
      "[4773,     1] loss: 0.0008979680715128779\n",
      "[4774,     1] loss: 0.0009123186464421451\n",
      "[4775,     1] loss: 0.0009269876172766089\n",
      "[4776,     1] loss: 0.0009460215223953128\n",
      "[4777,     1] loss: 0.0009652086300775409\n",
      "[4778,     1] loss: 0.0009915368864312768\n",
      "[4779,     1] loss: 0.0010163297411054373\n",
      "[4780,     1] loss: 0.0010491199791431427\n",
      "[4781,     1] loss: 0.0010755030671134591\n",
      "[4782,     1] loss: 0.0011139169801026583\n",
      "[4783,     1] loss: 0.0011395571054890752\n",
      "[4784,     1] loss: 0.0011753117432817817\n",
      "[4785,     1] loss: 0.0011877815704792738\n",
      "[4786,     1] loss: 0.0011955518275499344\n",
      "[4787,     1] loss: 0.0011753226863220334\n",
      "[4788,     1] loss: 0.001146095572039485\n",
      "[4789,     1] loss: 0.0010956069454550743\n",
      "[4790,     1] loss: 0.0010391916148364544\n",
      "[4791,     1] loss: 0.000979326432570815\n",
      "[4792,     1] loss: 0.0009267394198104739\n",
      "[4793,     1] loss: 0.0008867456344887614\n",
      "[4794,     1] loss: 0.0008633913239464164\n",
      "[4795,     1] loss: 0.0008561295690014958\n",
      "[4796,     1] loss: 0.0008619112195447087\n",
      "[4797,     1] loss: 0.0008762392681092024\n",
      "[4798,     1] loss: 0.0008944625733420253\n",
      "[4799,     1] loss: 0.0009133778512477875\n",
      "[4800,     1] loss: 0.0009287666762247682\n",
      "[4801,     1] loss: 0.0009404922602698207\n",
      "[4802,     1] loss: 0.000945641309954226\n",
      "[4803,     1] loss: 0.0009483566973358393\n",
      "[4804,     1] loss: 0.0009440913563594222\n",
      "[4805,     1] loss: 0.0009370672632940114\n",
      "[4806,     1] loss: 0.0009253172902390361\n",
      "[4807,     1] loss: 0.0009116298169828951\n",
      "[4808,     1] loss: 0.0008969540940597653\n",
      "[4809,     1] loss: 0.0008833410684019327\n",
      "[4810,     1] loss: 0.0008713359711691737\n",
      "[4811,     1] loss: 0.0008617379935458302\n",
      "[4812,     1] loss: 0.0008545155869796872\n",
      "[4813,     1] loss: 0.0008497351664118469\n",
      "[4814,     1] loss: 0.000847088813316077\n",
      "[4815,     1] loss: 0.0008460758253931999\n",
      "[4816,     1] loss: 0.0008462948026135564\n",
      "[4817,     1] loss: 0.0008476095972582698\n",
      "[4818,     1] loss: 0.000849962409120053\n",
      "[4819,     1] loss: 0.0008533961954526603\n",
      "[4820,     1] loss: 0.000858849030919373\n",
      "[4821,     1] loss: 0.0008661628235131502\n",
      "[4822,     1] loss: 0.0008773472509346902\n",
      "[4823,     1] loss: 0.0008920863037928939\n",
      "[4824,     1] loss: 0.000916382297873497\n",
      "[4825,     1] loss: 0.0009468048810958862\n",
      "[4826,     1] loss: 0.0009968876838684082\n",
      "[4827,     1] loss: 0.0010549305006861687\n",
      "[4828,     1] loss: 0.0011469197925180197\n",
      "[4829,     1] loss: 0.0012449049390852451\n",
      "[4830,     1] loss: 0.0014022140530869365\n",
      "[4831,     1] loss: 0.0015480928122997284\n",
      "[4832,     1] loss: 0.001781955361366272\n",
      "[4833,     1] loss: 0.0019376716809347272\n",
      "[4834,     1] loss: 0.0021240017376840115\n",
      "[4835,     1] loss: 0.0021084954496473074\n",
      "[4836,     1] loss: 0.0019987071864306927\n",
      "[4837,     1] loss: 0.0016751916846260428\n",
      "[4838,     1] loss: 0.0013037193566560745\n",
      "[4839,     1] loss: 0.0009937905706465244\n",
      "[4840,     1] loss: 0.0008602991001680493\n",
      "[4841,     1] loss: 0.0009118521120399237\n",
      "[4842,     1] loss: 0.0010703314328566194\n",
      "[4843,     1] loss: 0.001225717132911086\n",
      "[4844,     1] loss: 0.0012851629871875048\n",
      "[4845,     1] loss: 0.0012347418814897537\n",
      "[4846,     1] loss: 0.0010954635217785835\n",
      "[4847,     1] loss: 0.0009497840655967593\n",
      "[4848,     1] loss: 0.0008613620884716511\n",
      "[4849,     1] loss: 0.0008575974497944117\n",
      "[4850,     1] loss: 0.0009161373018287122\n",
      "[4851,     1] loss: 0.0009871366200968623\n",
      "[4852,     1] loss: 0.0010292179649695754\n",
      "[4853,     1] loss: 0.001016721478663385\n",
      "[4854,     1] loss: 0.0009662669617682695\n",
      "[4855,     1] loss: 0.0009000725694932044\n",
      "[4856,     1] loss: 0.0008524564327672124\n",
      "[4857,     1] loss: 0.0008405696717090905\n",
      "[4858,     1] loss: 0.0008600772125646472\n",
      "[4859,     1] loss: 0.0008914604550227523\n",
      "[4860,     1] loss: 0.0009130091639235616\n",
      "[4861,     1] loss: 0.0009149378165602684\n",
      "[4862,     1] loss: 0.0008964956505224109\n",
      "[4863,     1] loss: 0.0008696192526258528\n",
      "[4864,     1] loss: 0.000846613256726414\n",
      "[4865,     1] loss: 0.000835939310491085\n",
      "[4866,     1] loss: 0.0008382475934922695\n",
      "[4867,     1] loss: 0.0008486367296427488\n",
      "[4868,     1] loss: 0.0008604167960584164\n",
      "[4869,     1] loss: 0.0008673738338984549\n",
      "[4870,     1] loss: 0.0008681860635988414\n",
      "[4871,     1] loss: 0.00086192786693573\n",
      "[4872,     1] loss: 0.0008524139411747456\n",
      "[4873,     1] loss: 0.0008421175880357623\n",
      "[4874,     1] loss: 0.0008343936642631888\n",
      "[4875,     1] loss: 0.0008307794923894107\n",
      "[4876,     1] loss: 0.0008311588317155838\n",
      "[4877,     1] loss: 0.000834069971460849\n",
      "[4878,     1] loss: 0.0008376730256713927\n",
      "[4879,     1] loss: 0.0008407965069636703\n",
      "[4880,     1] loss: 0.0008420184021815658\n",
      "[4881,     1] loss: 0.0008418067591264844\n",
      "[4882,     1] loss: 0.0008396346820518374\n",
      "[4883,     1] loss: 0.0008366107940673828\n",
      "[4884,     1] loss: 0.0008328664698638022\n",
      "[4885,     1] loss: 0.0008295432198792696\n",
      "[4886,     1] loss: 0.0008267834200523794\n",
      "[4887,     1] loss: 0.0008250429527834058\n",
      "[4888,     1] loss: 0.0008243434131145477\n",
      "[4889,     1] loss: 0.0008245069766417146\n",
      "[4890,     1] loss: 0.0008253494743257761\n",
      "[4891,     1] loss: 0.0008265792275778949\n",
      "[4892,     1] loss: 0.0008284022333100438\n",
      "[4893,     1] loss: 0.0008302094647660851\n",
      "[4894,     1] loss: 0.0008322957437485456\n",
      "[4895,     1] loss: 0.0008339699706993997\n",
      "[4896,     1] loss: 0.0008360440842807293\n",
      "[4897,     1] loss: 0.0008374431636184454\n",
      "[4898,     1] loss: 0.0008393617463298142\n",
      "[4899,     1] loss: 0.000840264605358243\n",
      "[4900,     1] loss: 0.0008411728776991367\n",
      "[4901,     1] loss: 0.000840824912302196\n",
      "[4902,     1] loss: 0.0008408831199631095\n",
      "[4903,     1] loss: 0.0008395884069614112\n",
      "[4904,     1] loss: 0.0008380874060094357\n",
      "[4905,     1] loss: 0.0008355873287655413\n",
      "[4906,     1] loss: 0.0008331008721143007\n",
      "[4907,     1] loss: 0.0008301176712848246\n",
      "[4908,     1] loss: 0.0008274008287116885\n",
      "[4909,     1] loss: 0.0008246778743341565\n",
      "[4910,     1] loss: 0.0008225170895457268\n",
      "[4911,     1] loss: 0.0008205264457501471\n",
      "[4912,     1] loss: 0.000819000881165266\n",
      "[4913,     1] loss: 0.0008177752606570721\n",
      "[4914,     1] loss: 0.0008169132634066045\n",
      "[4915,     1] loss: 0.0008163320599123836\n",
      "[4916,     1] loss: 0.0008159161079674959\n",
      "[4917,     1] loss: 0.0008156237890943885\n",
      "[4918,     1] loss: 0.0008153943344950676\n",
      "[4919,     1] loss: 0.0008152214577421546\n",
      "[4920,     1] loss: 0.0008151374640874565\n",
      "[4921,     1] loss: 0.0008151859510689974\n",
      "[4922,     1] loss: 0.0008154104580171406\n",
      "[4923,     1] loss: 0.0008159771095961332\n",
      "[4924,     1] loss: 0.0008170688524842262\n",
      "[4925,     1] loss: 0.0008191196830011904\n",
      "[4926,     1] loss: 0.0008225885103456676\n",
      "[4927,     1] loss: 0.0008282779017463326\n",
      "[4928,     1] loss: 0.0008378869388252497\n",
      "[4929,     1] loss: 0.0008520766859874129\n",
      "[4930,     1] loss: 0.0008755988674238324\n",
      "[4931,     1] loss: 0.0009058977011591196\n",
      "[4932,     1] loss: 0.0009547463851049542\n",
      "[4933,     1] loss: 0.0010123027022928\n",
      "[4934,     1] loss: 0.0010999887017533183\n",
      "[4935,     1] loss: 0.0011923194397240877\n",
      "[4936,     1] loss: 0.0013149192091077566\n",
      "[4937,     1] loss: 0.001423370442353189\n",
      "[4938,     1] loss: 0.0015702866949141026\n",
      "[4939,     1] loss: 0.0016583827091380954\n",
      "[4940,     1] loss: 0.0017600294668227434\n",
      "[4941,     1] loss: 0.0017377901822328568\n",
      "[4942,     1] loss: 0.0016531822038814425\n",
      "[4943,     1] loss: 0.0014455022756010294\n",
      "[4944,     1] loss: 0.001204826170578599\n",
      "[4945,     1] loss: 0.0009792804485186934\n",
      "[4946,     1] loss: 0.0008420983795076609\n",
      "[4947,     1] loss: 0.000817432883195579\n",
      "[4948,     1] loss: 0.0008833006722852588\n",
      "[4949,     1] loss: 0.0009894391987472773\n",
      "[4950,     1] loss: 0.0010785716585814953\n",
      "[4951,     1] loss: 0.0011211750097572803\n",
      "[4952,     1] loss: 0.0010937349870800972\n",
      "[4953,     1] loss: 0.0010215842630714178\n",
      "[4954,     1] loss: 0.0009269905276596546\n",
      "[4955,     1] loss: 0.0008491878397762775\n",
      "[4956,     1] loss: 0.0008104734588414431\n",
      "[4957,     1] loss: 0.0008152361842803657\n",
      "[4958,     1] loss: 0.0008496367954649031\n",
      "[4959,     1] loss: 0.0008906653383746743\n",
      "[4960,     1] loss: 0.0009192040888592601\n",
      "[4961,     1] loss: 0.0009225012036040425\n",
      "[4962,     1] loss: 0.0009048850042745471\n",
      "[4963,     1] loss: 0.0008716289885342121\n",
      "[4964,     1] loss: 0.0008378502097912133\n",
      "[4965,     1] loss: 0.0008126990287564695\n",
      "[4966,     1] loss: 0.0008025605930015445\n",
      "[4967,     1] loss: 0.000806579424533993\n",
      "[4968,     1] loss: 0.0008193350513465703\n",
      "[4969,     1] loss: 0.0008346486138179898\n",
      "[4970,     1] loss: 0.0008457773947156966\n",
      "[4971,     1] loss: 0.0008514728397130966\n",
      "[4972,     1] loss: 0.0008484703721478581\n",
      "[4973,     1] loss: 0.0008408123976550996\n",
      "[4974,     1] loss: 0.0008286364027298987\n",
      "[4975,     1] loss: 0.0008166394545696676\n",
      "[4976,     1] loss: 0.0008064674912020564\n",
      "[4977,     1] loss: 0.0008003425318747759\n",
      "[4978,     1] loss: 0.000798503402620554\n",
      "[4979,     1] loss: 0.0008002360700629652\n",
      "[4980,     1] loss: 0.000804054201580584\n",
      "[4981,     1] loss: 0.0008083856082521379\n",
      "[4982,     1] loss: 0.0008123298175632954\n",
      "[4983,     1] loss: 0.0008147278567776084\n",
      "[4984,     1] loss: 0.0008162621525116265\n",
      "[4985,     1] loss: 0.00081571628106758\n",
      "[4986,     1] loss: 0.0008146009058691561\n",
      "[4987,     1] loss: 0.0008118408150039613\n",
      "[4988,     1] loss: 0.0008090599440038204\n",
      "[4989,     1] loss: 0.0008055496145971119\n",
      "[4990,     1] loss: 0.0008021116955205798\n",
      "[4991,     1] loss: 0.0007989864679984748\n",
      "[4992,     1] loss: 0.0007966444827616215\n",
      "[4993,     1] loss: 0.0007951889419928193\n",
      "[4994,     1] loss: 0.0007946022669784725\n",
      "[4995,     1] loss: 0.0007945990073494613\n",
      "[4996,     1] loss: 0.0007950115250423551\n",
      "[4997,     1] loss: 0.0007957502384670079\n",
      "[4998,     1] loss: 0.000796804204583168\n",
      "[4999,     1] loss: 0.0007982206298038363\n",
      "[5000,     1] loss: 0.0007999337394721806\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "epochs      = 5_000\n",
    "batch_size  = 500\n",
    "num_batches = N_train // batch_size\n",
    "\n",
    "losses = []\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    rolling_loss = 0\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        theta_batch, (A_batch, B_batch) = thetas_train[i*batch_size:(i+1)*batch_size], (As_train[i*batch_size:(i+1)*batch_size], Bs_train[i*batch_size:(i+1)*batch_size])\n",
    "        A_hat_batch, B_hat_batch = net(theta_batch)\n",
    "        \n",
    "        loss = criterion(A_hat_batch, A_batch) + criterion(B_hat_batch, B_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        rolling_loss += loss.item()\n",
    "    losses.append(rolling_loss)\n",
    "    print(f'[{epoch + 1}, {i + 1:5d}] loss: {rolling_loss}')\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_scores(net, num_samples, get_true_dynamics=False):\n",
    "    if get_true_dynamics:\n",
    "        xs, (As, Bs), _ = generate_data(num_samples)\n",
    "    else:\n",
    "        xs, _, (As, Bs) = generate_data(num_samples)\n",
    "    A_hat, B_hat = net(xs)\n",
    "\n",
    "    C = torch.cat([As, Bs], axis=-1).cpu().detach().numpy()\n",
    "    C_hat = torch.cat([A_hat, B_hat], axis=-1).cpu().detach().numpy()\n",
    "    diff = C - C_hat\n",
    "    return (C, C_hat), np.linalg.norm(diff, ord=2, axis=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 7675289.1869149. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2958523162.5911446. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2235614453418.448. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6.044427895294081e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 668113526.0209218. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2976403587.1581073. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1445025439.2356176. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1505712007.09401. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 236050.1803345298. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4.0096502950964265e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.8538680421294795e+24. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 277486.2922440217. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3217618.6371948486. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.5796638077319363e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 14165157950.288723. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 20304375617.04186. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.3619343586166237e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1647679487681.3506. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6.42996223933855e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 9964105.729270255. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.271776532584472e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 21294779.03550635. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 17303332645294.264. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 26461015712267.863. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1457794498.842856. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 986248.3053279775. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 273674791.5988892. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 305095545.16085553. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 259586056499.44263. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 838178349085285.2. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 327118127362.88873. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3.0006401835656675e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 7.282431759743722e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6.56117682817261e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.989327213998726e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4.201620902703903e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.954886607256499e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 12940861.4156149. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 58538780.98227195. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1130911557079867.2. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.0579827472220321e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 10409725.903325554. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3.6829773273354445e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6.638348024185736e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6331142.132758783. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2388071.1836686465. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 7.671644564128659e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.5376269410211103e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.1796248035198583e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 9342159270.440134. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 498094096520110.9. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4.948431295815192e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 169193657400685.75. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 8.445355250504217e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3.715545660080963e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 7584996720882.063. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.1930206342435232e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.9315836625310158e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 429167.99037939264. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 208111040162494.8. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 310506179447689.4. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 232618.75685901515. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.6761993673359418e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 17218643.009073716. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 27172357.761870507. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 216303.58224508428. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2201608.0287433825. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2767642456390200.5. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4174727.7008745214. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4.5642955580059505e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6.553177436465925e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 9.167194137434059e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2547618.938711653. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 27997351.83772302. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 146818580.7066016. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.1993895580300596e+16. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 8260587539.916012. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2541845717330.3394. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 5.881195680754209e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 8871207434018067.0. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 449810950560.74066. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 97056917.89168943. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4149878932.132809. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.261919283260552e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1497037226.8733373. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.2724721235618203e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 5.490845347880264e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3.368333329672302e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3984018.5382932094. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3.8504772799742756e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3438389997899594.0. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.7424888549702412e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1548810.2672149793. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.7023584889246013e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 38733004.540524624. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 291445867975.6539. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.0995628883519295e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 244196310998771.47. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4107351399.1508827. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 469600728.73888344. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 7.392518098738683e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6455874369.425109. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1155859805.9118166. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 61472305.28102577. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 448993830.2102894. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 400304958311604.4. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.2059508375433347e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3741210690.9524956. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 8628939.092524469. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1729658658.1998787. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3094656995163.888. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1404896783769905.2. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3683476.586258207. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.7064478763935898e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6.707378319762218e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1019835710211443.4. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2448997.385051236. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 240854932642.83133. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4.5512386285799473e+21. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.018786787004258e+22. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 615885.2836048122. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 596386150062110.2. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.7043546308082182e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.2689215777699888e+21. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1350930087927565.0. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 495807.2191163571. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 187551299.68295413. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 5465946.693574128. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.5290075992619994e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.7422263952111432e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.204651463268736e+21. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 657466.7727403688. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3.250478007684229e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 275182185388232.12. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 58024041.6849574. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 115205075.73471414. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 30163666.754207697. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3288993195654.574. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6.287697677441418e+25. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 13525389.109531121. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6.593355924465997e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 164624.34176807705. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1226076158.5571313. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 633237.4899404766. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.5538026589444092e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4.020910420191658e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 10874778446.891918. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 390017203.4861446. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 246387705.01624358. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 494409774325.4807. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 7.954383372700054e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 11402899.61701463. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3.219283596448695e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 102031.08474978636. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.940505143250855e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 33847264425881.516. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 9509886444796.992. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 22591194.15443885. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.7131484499400003e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1846005974534.919. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.3517571354558598e+21. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 213592273.10890883. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 128971664697109.92. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3702250.0050138715. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 5804199422.1136265. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6447417579336012.0. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4248415323701594.5. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 9261342508.004827. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 24610229.622610707. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 12513984420.059126. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.3512727237807524e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.0461234851301625e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.359836685147542e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6.425593312755116e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1109487833.9431136. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 7.775916849975211e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.4068730959527596e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2481582379103848.0. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 744390010.2978319. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4.421413536019713e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 10366021.583669141. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 5.705708802738046e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.905743024278492e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1161105787.5877964. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 66861534582.69428. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 330506081993.34424. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 5.866847312460257e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3611238995274.5513. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3.7415373379027073e+22. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 445965.8634581627. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 95866013.1152303. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 471587.08084535337. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.6420925507732196e+22. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.2886181394131723e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 224260.0444046424. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 184530868.56244004. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3087610558149.8857. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.5846305760917246e+16. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 179922340384.40936. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1052339.4302452295. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 78043360.78256111. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.532801939389721e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 612899.0568690532. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 581358232.1818818. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1618958008.8631525. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 186461876.38790235. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.6832444129405755e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 165906740.72953. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "N_cal, N_test = 200, 200\n",
    "(cal_C, cal_C_hat),   cal_scores  = generate_scores(net, num_samples=N_cal,  get_true_dynamics=False)\n",
    "(test_C, test_C_hat), test_scores = generate_scores(net, num_samples=N_test, get_true_dynamics=True)\n",
    "N_cal, N_test = len(cal_C), len(test_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '$\\\\mathrm{Model\\\\ Calibration}$')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_theme()\n",
    "\n",
    "plt.rcParams['mathtext.fontset'] = 'stix'\n",
    "plt.rcParams['font.family'] = 'STIXGeneral'\n",
    "\n",
    "SMALL_SIZE = 12\n",
    "MEDIUM_SIZE = 14\n",
    "BIGGER_SIZE = 18\n",
    "\n",
    "plt.rc('font', size=MEDIUM_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=MEDIUM_SIZE)  # fontsize of the figure title\n",
    "\n",
    "alphas = np.arange(0, 1, 0.05)\n",
    "coverages = []\n",
    "for alpha in alphas:\n",
    "    q_hat = np.quantile(cal_scores, q = 1-alpha)\n",
    "    coverages.append(np.sum(test_scores < q_hat) / N_test)\n",
    "\n",
    "sns.lineplot(x=(1-alphas), y=(1-alphas), linestyle='--')\n",
    "sns.lineplot(x=(1-alphas), y=coverages)\n",
    "plt.xlabel(r\"$\\mathrm{Expected\\ Coverage} (1-\\alpha)$\")\n",
    "plt.ylabel(r\"$\\mathrm{Empirical\\ Coverage}$\")\n",
    "plt.title(r\"$\\mathrm{Model\\ Calibration}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "q_hat = np.quantile(cal_scores, q = 1-alpha)\n",
    "\n",
    "with open(\"experiments/load_pos.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"test_C\": test_C, \n",
    "        \"test_C_hat\": test_C_hat,\n",
    "        \"q_hat\": q_hat,\n",
    "    }, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "operator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
