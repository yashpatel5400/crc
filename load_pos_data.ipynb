{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import cvxpy as cp\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "from pydmd import DMDc\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution parameters need to be fixed for the simulation\n",
    "mu_m_B, sigma_m_B = np.random.random(), np.abs(np.random.random())\n",
    "mu_m_L, sigma_m_L = np.random.random(), np.abs(np.random.random())\n",
    "mu_d_L, sigma_d_L = np.random.random(), np.abs(np.random.random())\n",
    "mu_k_B, sigma_k_B = np.random.random(), np.abs(np.random.random())\n",
    "mu_d_B, sigma_d_B = np.random.random(), np.abs(np.random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dynamics_matrices(num_samples):\n",
    "    m_B = np.expand_dims(np.abs(np.random.normal(mu_m_B, 10 * sigma_m_B, num_samples)),axis=0)\n",
    "    m_L = np.expand_dims(np.abs(np.random.normal(mu_m_L, 10 * sigma_m_L, num_samples)),axis=0)\n",
    "    d_L = np.expand_dims(np.abs(np.random.normal(mu_d_L, 10 * sigma_d_L, num_samples)),axis=0)\n",
    "    k_B = np.expand_dims(np.abs(np.random.normal(mu_k_B, 10 * sigma_k_B, num_samples)),axis=0)\n",
    "    d_B = np.expand_dims(np.abs(np.random.normal(mu_d_B, 10 * sigma_d_B, num_samples)),axis=0)\n",
    "    \n",
    "    thetas = np.vstack([m_B, m_L, d_L, k_B, d_B]).T\n",
    "    As = np.zeros((num_samples, 4, 4))\n",
    "    As[:,0,1]  = 1\n",
    "\n",
    "    As[:,1,1] = -d_L / m_L - d_L / m_B \n",
    "    As[:,1,2] = k_B / m_B\n",
    "    As[:,1,3] = d_B / m_B \n",
    "\n",
    "    As[:,2,3] = 1\n",
    "\n",
    "    As[:,3,1] = d_L / m_B\n",
    "    As[:,3,2] = -k_B / m_B\n",
    "    As[:,3,3] = -d_B / m_B\n",
    "\n",
    "    Bs = np.zeros((num_samples, 4, 1))\n",
    "    Bs[:,1,0] = 1 / m_L + 1 / m_B\n",
    "    Bs[:,3,0] = -1 / m_B\n",
    "\n",
    "    return thetas, (As, Bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m: trajectory length\n",
    "def generate_system_trajectories(As, Bs, m = 25):\n",
    "    n = As.shape[-1]\n",
    "    l = Bs.shape[-1]\n",
    "\n",
    "    x0 = np.random.random((n, 1))\n",
    "    u = np.random.rand(l, m - 1) - .5\n",
    "\n",
    "    x0 = np.tile(x0, reps=(As.shape[0],1,1)).astype(np.float32)\n",
    "    u  = np.tile(u,  reps=(Bs.shape[0],1,1)).astype(np.float32)\n",
    "\n",
    "    snapshots = [x0]\n",
    "\n",
    "    for i in range(m - 1):\n",
    "        snapshots.append(As @ snapshots[i] + Bs @ u[:, :, i:i+1])\n",
    "    snapshots = np.array(snapshots).T\n",
    "    return {'snapshots': snapshots, 'u': u, 'B': Bs, 'A': As}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_dynamics_matrices(system):\n",
    "    mb_size = system[\"A\"].shape[0]\n",
    "    A_hats, B_hats = [], []\n",
    "    for i in range(mb_size):\n",
    "        dmdc = DMDc(svd_rank=-1, opt=True)\n",
    "        dmdc.fit(system['snapshots'][:,:,i,:], system['u'][i])\n",
    "        A_hat, B_hat, _ = dmdc.reconstructed_data() # NOTE: the PyDMD reconstructed_data() function was modified to return the dynamics -- this will *not* work by default\n",
    "        A_hats.append(np.real(A_hat))\n",
    "        B_hats.append(np.real(B_hat))\n",
    "    A_hats = np.array(A_hats).reshape(mb_size, -1)\n",
    "    B_hats = np.array(B_hats).reshape(mb_size, -1)\n",
    "    return A_hats, B_hats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_pts):\n",
    "    thetas, (As, Bs) = generate_dynamics_matrices(n_pts)\n",
    "    system = generate_system_trajectories(As, Bs, m = 25)\n",
    "    A_hats, B_hats = estimate_dynamics_matrices(system)\n",
    "    A_hats, B_hats = A_hats.reshape(As.shape), B_hats.reshape(Bs.shape)\n",
    "\n",
    "    thresh    = 0.1\n",
    "    valid_ind = np.where(np.logical_and(\n",
    "        np.linalg.norm(A_hats - As, ord=\"fro\", axis=(1,2)) < thresh,\n",
    "        np.linalg.norm(B_hats - Bs, ord=\"fro\", axis=(1,2)) < thresh,\n",
    "    ))\n",
    "    thetas, As, Bs, A_hats, B_hats = thetas[valid_ind], As[valid_ind], Bs[valid_ind], A_hats[valid_ind], B_hats[valid_ind]\n",
    "\n",
    "    thetas         = torch.from_numpy(thetas).to(torch.float32).to(device)\n",
    "    As, Bs         = torch.from_numpy(As).to(torch.float32).to(device), torch.from_numpy(Bs).to(torch.float32).to(device)\n",
    "    A_hats, B_hats = torch.from_numpy(A_hats).to(torch.float32).to(device), torch.from_numpy(B_hats).to(torch.float32).to(device)\n",
    "\n",
    "    return thetas, (As, Bs), (A_hats, B_hats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextualLQR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(5, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        \n",
    "        self.fc_A = nn.Linear(64, 16)\n",
    "        self.fc_B = nn.Linear(64, 4)\n",
    "        self.fc_C = nn.Linear(64, 24)\n",
    "\n",
    "    def forward(self, theta):\n",
    "        x = F.relu(self.fc1(theta))\n",
    "        \n",
    "        fc2_x = self.fc2(x)\n",
    "        x     = F.relu(x + fc2_x)\n",
    "\n",
    "        fc3_x = self.fc3(x)\n",
    "        x     = F.relu(x + fc3_x)\n",
    "\n",
    "        # for predictions of A matrix\n",
    "        A = self.fc_A(x).reshape((-1,4,4))\n",
    "\n",
    "        # for predictions of B matrix\n",
    "        B = self.fc_B(x).reshape((-1,4,1))\n",
    "\n",
    "        # for predictions of C := [A, B] matrix\n",
    "        # C = self.fc_C(x).reshape((-1,4,6))\n",
    "        # return C\n",
    "        return A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1114490909.9967296. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3.3315739989611284e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.2725389442500542e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4416263.126911494. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 335609.5012375312. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6.265223823800515e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 688007.1863268632. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 115085.4695478111. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 373303025545.0593. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 10247389028.010834. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 252652505961.16904. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 950357120.2563063. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3.330127455312165e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3336478000.295937. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4.9159922377420134e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.2215493819450144e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6284535.899996558. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 233294940417100.06. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6.872894177519059e+16. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 741144067285.5394. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 11560194830947.137. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 152867912.77208033. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1706644768.4195597. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6942099942200.087. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 28994472695.4901. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 33224891278.67708. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 229917.05920161374. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 5.412770311136807e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 657135784013.24. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 227779.2556094891. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 20754344696.242485. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 112192.38755982138. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 41092628.173414424. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 161643.97335354943. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.3753888987868564e+16. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 8875702.551559268. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 578675.2868119535. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 638395710.7931345. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 5.871360521729861e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1252828.9642689924. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 5984217.5462650135. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6031955273661.042. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 68436584374.63576. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1014068.8672540867. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 12561376.805338502. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 7930296484.035905. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 11349079941.436636. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 7.62865805696647e+21. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 9251788003081.9. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 5019664.361827549. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6.534949659089678e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.7168187015750375e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6130688.836778897. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 9.576563933275953e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 132271.21626790043. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.142425618251709e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 119876323057.12543. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 186957.74623698025. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4.325535244488496e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 23244309221.70719. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.4031765733657377e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 631446.4303739057. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 134162409930.75328. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 5.83932841960458e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.505210751418245e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 13340458793377.87. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6567691.488837845. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.3759553209204192e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 15017697244901.514. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1291782316.412726. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 161861.433381923. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 202302.14722522668. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.2765332423751104e+23. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 81711309.46254581. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6.167018885200398e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1207504.3994112578. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 41048805271937.89. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 212314790809.58902. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 456779.1541183938. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 249372740.83888575. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 207569656.25359333. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.269851915085486e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 231062.08851842294. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3616020.5524669834. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 354917949.6284918. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2192712181.8202353. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1943138522.8600996. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4549743.025190599. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2090972959.4646738. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.1755459912970692e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 271874019187.7623. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6.492376482746754e+16. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2740299598.724606. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 951903816.0796915. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4632633.703161582. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 83368560.03950356. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 81828662.14890665. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2880166217.6461697. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 244093728518.84158. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4.1802356771233357e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 39645265539.086876. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3584036154878.556. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2928223.921284771. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 195927517018.1816. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 33095323.746242736. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6449269.81385536. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4.1688528367579974e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 204774.59041530162. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 67910774220161.914. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 5731787068214.975. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3.677829219068343e+16. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4482529567.189366. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2130694020.7933486. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.9026167824179583e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 118333.99453383176. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 977958.1084196096. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 554095974968297.06. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 789786556.3008745. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 435310207919.13184. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 334577.0553254775. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 471126.5831222166. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 17787952682352.18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 46677311.94164656. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 280458166974.69794. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3.457294774732844e+16. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 374631.15699390305. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 58677947.42810602. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3926395.7509902366. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6.223219750710182e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 97258714.54662745. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.5275572787729566e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4729255.992892169. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1178651.903696181. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 270799662.5416541. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 5.0834110221491896e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 7.726888990254367e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 610302055.4100529. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 736161.3097747021. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.6810718943813379e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2298815.5320391515. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1415926151.8152099. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 7128756851408.651. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.0579546491069751e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 146127.1450315347. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 8433432802.566658. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.225055036027245e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6384313.509615898. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 7341153996427.026. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 400205632.52083296. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4712920.880358869. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 891254.2950215256. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 360662088363.35596. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6.900087080922616e+23. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.2157996989823951e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 77345382.16552845. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4743380.275074217. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 204957.142679757. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 254347.4691316955. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6.761549926715418e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.5048727120485366e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 9.565648925097096e+16. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.8033764683687956e+16. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 11653180.44988901. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 71042088.79730631. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 20190436096.932148. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 29280153759.081764. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 173288.8110580789. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1422605.231677606. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 179600575105226.75. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4.750407870600328e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 39402376080114.79. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1494002.1058779368. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 138313.49879790287. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 5528076.9829322575. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 10014742834.529251. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 773191596724.4573. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 98546352613021.36. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3.522456975866568e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1310624428.143616. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 52943900.558191836. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 7.268084043537802e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.0070464808021778e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 836073038857.8291. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6.854995990459443e+21. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 340845878990.161. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 479760.86740414554. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 25683504.90479688. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2472256198230.784. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3.327542870552241e+16. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 16829397.30594589. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 56942359290351.83. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 9275012.253330233. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 69892753.40773374. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 59586728.40130067. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 751356015714.5922. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 284369044673.753. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.3977051630205234e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 7.026225103438043e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6775401.054397171. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2924966562465570.5. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 11363709.060245967. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 23683231944.20613. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 144096068579.45273. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4.824496773631308e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2163305.034148813. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6755157517373.347. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 394185.7242011994. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 105558590910795.05. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "net       = ContextualLQR().to(device)\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "N_train = 500\n",
    "thetas_train, _, (As_train, Bs_train) = generate_data(N_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 8.215907096862793\n",
      "[2,     1] loss: 6.724334239959717\n",
      "[3,     1] loss: 5.582704544067383\n",
      "[4,     1] loss: 4.724503040313721\n",
      "[5,     1] loss: 4.081449031829834\n",
      "[6,     1] loss: 3.5900328159332275\n",
      "[7,     1] loss: 3.202420234680176\n",
      "[8,     1] loss: 2.8884520530700684\n",
      "[9,     1] loss: 2.6294803619384766\n",
      "[10,     1] loss: 2.414473056793213\n",
      "[11,     1] loss: 2.2389087677001953\n",
      "[12,     1] loss: 2.098719596862793\n",
      "[13,     1] loss: 1.9906256198883057\n",
      "[14,     1] loss: 1.9108922481536865\n",
      "[15,     1] loss: 1.8541642427444458\n",
      "[16,     1] loss: 1.8141682147979736\n",
      "[17,     1] loss: 1.784682035446167\n",
      "[18,     1] loss: 1.7598158121109009\n",
      "[19,     1] loss: 1.7355875968933105\n",
      "[20,     1] loss: 1.7101056575775146\n",
      "[21,     1] loss: 1.6836655139923096\n",
      "[22,     1] loss: 1.657149076461792\n",
      "[23,     1] loss: 1.6310979127883911\n",
      "[24,     1] loss: 1.6058354377746582\n",
      "[25,     1] loss: 1.581413745880127\n",
      "[26,     1] loss: 1.5573904514312744\n",
      "[27,     1] loss: 1.5333333015441895\n",
      "[28,     1] loss: 1.5088675022125244\n",
      "[29,     1] loss: 1.4842580556869507\n",
      "[30,     1] loss: 1.4599535465240479\n",
      "[31,     1] loss: 1.4361761808395386\n",
      "[32,     1] loss: 1.4135239124298096\n",
      "[33,     1] loss: 1.3921090364456177\n",
      "[34,     1] loss: 1.3718986511230469\n",
      "[35,     1] loss: 1.3527954816818237\n",
      "[36,     1] loss: 1.33463716506958\n",
      "[37,     1] loss: 1.3174033164978027\n",
      "[38,     1] loss: 1.3010146617889404\n",
      "[39,     1] loss: 1.2852694988250732\n",
      "[40,     1] loss: 1.2700462341308594\n",
      "[41,     1] loss: 1.2552833557128906\n",
      "[42,     1] loss: 1.2408792972564697\n",
      "[43,     1] loss: 1.226854681968689\n",
      "[44,     1] loss: 1.2132165431976318\n",
      "[45,     1] loss: 1.1998705863952637\n",
      "[46,     1] loss: 1.1866618394851685\n",
      "[47,     1] loss: 1.173602819442749\n",
      "[48,     1] loss: 1.1607698202133179\n",
      "[49,     1] loss: 1.1480964422225952\n",
      "[50,     1] loss: 1.1357824802398682\n",
      "[51,     1] loss: 1.1239014863967896\n",
      "[52,     1] loss: 1.1124587059020996\n",
      "[53,     1] loss: 1.1012946367263794\n",
      "[54,     1] loss: 1.0902626514434814\n",
      "[55,     1] loss: 1.0793875455856323\n",
      "[56,     1] loss: 1.0687103271484375\n",
      "[57,     1] loss: 1.05814790725708\n",
      "[58,     1] loss: 1.047671914100647\n",
      "[59,     1] loss: 1.0372430086135864\n",
      "[60,     1] loss: 1.0269205570220947\n",
      "[61,     1] loss: 1.0168263912200928\n",
      "[62,     1] loss: 1.0069979429244995\n",
      "[63,     1] loss: 0.9974790811538696\n",
      "[64,     1] loss: 0.9881905317306519\n",
      "[65,     1] loss: 0.9790207147598267\n",
      "[66,     1] loss: 0.9699171781539917\n",
      "[67,     1] loss: 0.9608960151672363\n",
      "[68,     1] loss: 0.9519565105438232\n",
      "[69,     1] loss: 0.9430735111236572\n",
      "[70,     1] loss: 0.9343233704566956\n",
      "[71,     1] loss: 0.9256624579429626\n",
      "[72,     1] loss: 0.9171047806739807\n",
      "[73,     1] loss: 0.9085345268249512\n",
      "[74,     1] loss: 0.9000338315963745\n",
      "[75,     1] loss: 0.8915373086929321\n",
      "[76,     1] loss: 0.8830718994140625\n",
      "[77,     1] loss: 0.8746819496154785\n",
      "[78,     1] loss: 0.8663425445556641\n",
      "[79,     1] loss: 0.857953667640686\n",
      "[80,     1] loss: 0.8496190309524536\n",
      "[81,     1] loss: 0.8413759469985962\n",
      "[82,     1] loss: 0.8330181241035461\n",
      "[83,     1] loss: 0.8247168660163879\n",
      "[84,     1] loss: 0.8166297674179077\n",
      "[85,     1] loss: 0.8085716366767883\n",
      "[86,     1] loss: 0.8005470633506775\n",
      "[87,     1] loss: 0.7925382852554321\n",
      "[88,     1] loss: 0.7847625017166138\n",
      "[89,     1] loss: 0.7770431041717529\n",
      "[90,     1] loss: 0.769404411315918\n",
      "[91,     1] loss: 0.7619010210037231\n",
      "[92,     1] loss: 0.7545177936553955\n",
      "[93,     1] loss: 0.7470912933349609\n",
      "[94,     1] loss: 0.7396882772445679\n",
      "[95,     1] loss: 0.7322644591331482\n",
      "[96,     1] loss: 0.7249041795730591\n",
      "[97,     1] loss: 0.717574954032898\n",
      "[98,     1] loss: 0.7101893424987793\n",
      "[99,     1] loss: 0.7026570439338684\n",
      "[100,     1] loss: 0.6952382326126099\n",
      "[101,     1] loss: 0.6878539323806763\n",
      "[102,     1] loss: 0.6805257797241211\n",
      "[103,     1] loss: 0.6732351779937744\n",
      "[104,     1] loss: 0.6656504273414612\n",
      "[105,     1] loss: 0.6582578420639038\n",
      "[106,     1] loss: 0.6510528326034546\n",
      "[107,     1] loss: 0.6437903642654419\n",
      "[108,     1] loss: 0.6364644765853882\n",
      "[109,     1] loss: 0.629070520401001\n",
      "[110,     1] loss: 0.6216557621955872\n",
      "[111,     1] loss: 0.6141983270645142\n",
      "[112,     1] loss: 0.6066702604293823\n",
      "[113,     1] loss: 0.5991671085357666\n",
      "[114,     1] loss: 0.5915945172309875\n",
      "[115,     1] loss: 0.584100067615509\n",
      "[116,     1] loss: 0.5767145752906799\n",
      "[117,     1] loss: 0.569317102432251\n",
      "[118,     1] loss: 0.5620924234390259\n",
      "[119,     1] loss: 0.5550772547721863\n",
      "[120,     1] loss: 0.5481777191162109\n",
      "[121,     1] loss: 0.5412250757217407\n",
      "[122,     1] loss: 0.5342152118682861\n",
      "[123,     1] loss: 0.5272622108459473\n",
      "[124,     1] loss: 0.5203608274459839\n",
      "[125,     1] loss: 0.5134977102279663\n",
      "[126,     1] loss: 0.5066540241241455\n",
      "[127,     1] loss: 0.49982714653015137\n",
      "[128,     1] loss: 0.49306151270866394\n",
      "[129,     1] loss: 0.48625099658966064\n",
      "[130,     1] loss: 0.4794425368309021\n",
      "[131,     1] loss: 0.47266411781311035\n",
      "[132,     1] loss: 0.46584323048591614\n",
      "[133,     1] loss: 0.4590391516685486\n",
      "[134,     1] loss: 0.4523456394672394\n",
      "[135,     1] loss: 0.44566068053245544\n",
      "[136,     1] loss: 0.43905383348464966\n",
      "[137,     1] loss: 0.4324438273906708\n",
      "[138,     1] loss: 0.42586541175842285\n",
      "[139,     1] loss: 0.4193257689476013\n",
      "[140,     1] loss: 0.4126390516757965\n",
      "[141,     1] loss: 0.4059767425060272\n",
      "[142,     1] loss: 0.3994143605232239\n",
      "[143,     1] loss: 0.39294853806495667\n",
      "[144,     1] loss: 0.38657712936401367\n",
      "[145,     1] loss: 0.38046467304229736\n",
      "[146,     1] loss: 0.3743829131126404\n",
      "[147,     1] loss: 0.3683195114135742\n",
      "[148,     1] loss: 0.36227092146873474\n",
      "[149,     1] loss: 0.3563162088394165\n",
      "[150,     1] loss: 0.3504998981952667\n",
      "[151,     1] loss: 0.3448313772678375\n",
      "[152,     1] loss: 0.3392561972141266\n",
      "[153,     1] loss: 0.33385801315307617\n",
      "[154,     1] loss: 0.32863524556159973\n",
      "[155,     1] loss: 0.323517382144928\n",
      "[156,     1] loss: 0.31856396794319153\n",
      "[157,     1] loss: 0.3137182891368866\n",
      "[158,     1] loss: 0.30900463461875916\n",
      "[159,     1] loss: 0.304451584815979\n",
      "[160,     1] loss: 0.2999308407306671\n",
      "[161,     1] loss: 0.2955338954925537\n",
      "[162,     1] loss: 0.29131102561950684\n",
      "[163,     1] loss: 0.2870917320251465\n",
      "[164,     1] loss: 0.2829558551311493\n",
      "[165,     1] loss: 0.27894580364227295\n",
      "[166,     1] loss: 0.2750297486782074\n",
      "[167,     1] loss: 0.2712630033493042\n",
      "[168,     1] loss: 0.2676166892051697\n",
      "[169,     1] loss: 0.26400381326675415\n",
      "[170,     1] loss: 0.2605038285255432\n",
      "[171,     1] loss: 0.2570618689060211\n",
      "[172,     1] loss: 0.25367969274520874\n",
      "[173,     1] loss: 0.2503417730331421\n",
      "[174,     1] loss: 0.24706751108169556\n",
      "[175,     1] loss: 0.24386852979660034\n",
      "[176,     1] loss: 0.24073641002178192\n",
      "[177,     1] loss: 0.23767437040805817\n",
      "[178,     1] loss: 0.23466411232948303\n",
      "[179,     1] loss: 0.23173122107982635\n",
      "[180,     1] loss: 0.2288784384727478\n",
      "[181,     1] loss: 0.22612673044204712\n",
      "[182,     1] loss: 0.2233927994966507\n",
      "[183,     1] loss: 0.2206965982913971\n",
      "[184,     1] loss: 0.2180653214454651\n",
      "[185,     1] loss: 0.21549484133720398\n",
      "[186,     1] loss: 0.21296539902687073\n",
      "[187,     1] loss: 0.210519939661026\n",
      "[188,     1] loss: 0.20805737376213074\n",
      "[189,     1] loss: 0.20569245517253876\n",
      "[190,     1] loss: 0.20336276292800903\n",
      "[191,     1] loss: 0.20106711983680725\n",
      "[192,     1] loss: 0.19884683191776276\n",
      "[193,     1] loss: 0.19664517045021057\n",
      "[194,     1] loss: 0.19446784257888794\n",
      "[195,     1] loss: 0.19234953820705414\n",
      "[196,     1] loss: 0.19022458791732788\n",
      "[197,     1] loss: 0.18810191750526428\n",
      "[198,     1] loss: 0.18602702021598816\n",
      "[199,     1] loss: 0.1840091198682785\n",
      "[200,     1] loss: 0.18200910091400146\n",
      "[201,     1] loss: 0.1800929456949234\n",
      "[202,     1] loss: 0.1782122254371643\n",
      "[203,     1] loss: 0.17634941637516022\n",
      "[204,     1] loss: 0.17451907694339752\n",
      "[205,     1] loss: 0.1727009117603302\n",
      "[206,     1] loss: 0.17091961205005646\n",
      "[207,     1] loss: 0.16918931901454926\n",
      "[208,     1] loss: 0.16744226217269897\n",
      "[209,     1] loss: 0.1657639741897583\n",
      "[210,     1] loss: 0.16406965255737305\n",
      "[211,     1] loss: 0.1624196320772171\n",
      "[212,     1] loss: 0.16079086065292358\n",
      "[213,     1] loss: 0.15913952887058258\n",
      "[214,     1] loss: 0.1575533002614975\n",
      "[215,     1] loss: 0.15597856044769287\n",
      "[216,     1] loss: 0.15441006422042847\n",
      "[217,     1] loss: 0.15283918380737305\n",
      "[218,     1] loss: 0.15132266283035278\n",
      "[219,     1] loss: 0.14985564351081848\n",
      "[220,     1] loss: 0.14834949374198914\n",
      "[221,     1] loss: 0.14686590433120728\n",
      "[222,     1] loss: 0.14543521404266357\n",
      "[223,     1] loss: 0.14399370551109314\n",
      "[224,     1] loss: 0.14257581532001495\n",
      "[225,     1] loss: 0.1411818563938141\n",
      "[226,     1] loss: 0.13976502418518066\n",
      "[227,     1] loss: 0.13836736977100372\n",
      "[228,     1] loss: 0.1369989961385727\n",
      "[229,     1] loss: 0.13564161956310272\n",
      "[230,     1] loss: 0.1342744529247284\n",
      "[231,     1] loss: 0.13296900689601898\n",
      "[232,     1] loss: 0.13168926537036896\n",
      "[233,     1] loss: 0.13038599491119385\n",
      "[234,     1] loss: 0.12913738191127777\n",
      "[235,     1] loss: 0.12789727747440338\n",
      "[236,     1] loss: 0.12666647136211395\n",
      "[237,     1] loss: 0.1254062056541443\n",
      "[238,     1] loss: 0.12417301535606384\n",
      "[239,     1] loss: 0.1230158656835556\n",
      "[240,     1] loss: 0.12186311930418015\n",
      "[241,     1] loss: 0.12070862948894501\n",
      "[242,     1] loss: 0.1195974200963974\n",
      "[243,     1] loss: 0.11851274967193604\n",
      "[244,     1] loss: 0.1174096018075943\n",
      "[245,     1] loss: 0.11635348200798035\n",
      "[246,     1] loss: 0.11529400944709778\n",
      "[247,     1] loss: 0.11425741016864777\n",
      "[248,     1] loss: 0.11322531849145889\n",
      "[249,     1] loss: 0.11218670010566711\n",
      "[250,     1] loss: 0.11118137836456299\n",
      "[251,     1] loss: 0.11023259162902832\n",
      "[252,     1] loss: 0.10923141241073608\n",
      "[253,     1] loss: 0.10826371610164642\n",
      "[254,     1] loss: 0.10735191404819489\n",
      "[255,     1] loss: 0.10641772300004959\n",
      "[256,     1] loss: 0.10549747198820114\n",
      "[257,     1] loss: 0.10457855463027954\n",
      "[258,     1] loss: 0.10366581380367279\n",
      "[259,     1] loss: 0.10277941823005676\n",
      "[260,     1] loss: 0.10190129280090332\n",
      "[261,     1] loss: 0.10101539641618729\n",
      "[262,     1] loss: 0.10016360878944397\n",
      "[263,     1] loss: 0.0993039458990097\n",
      "[264,     1] loss: 0.09846073389053345\n",
      "[265,     1] loss: 0.09763732552528381\n",
      "[266,     1] loss: 0.09675273299217224\n",
      "[267,     1] loss: 0.09590277820825577\n",
      "[268,     1] loss: 0.09508465230464935\n",
      "[269,     1] loss: 0.09427665174007416\n",
      "[270,     1] loss: 0.09346042573451996\n",
      "[271,     1] loss: 0.09265077114105225\n",
      "[272,     1] loss: 0.09187304973602295\n",
      "[273,     1] loss: 0.09110936522483826\n",
      "[274,     1] loss: 0.09034375101327896\n",
      "[275,     1] loss: 0.0895652025938034\n",
      "[276,     1] loss: 0.08885382115840912\n",
      "[277,     1] loss: 0.08815845102071762\n",
      "[278,     1] loss: 0.08741526305675507\n",
      "[279,     1] loss: 0.086676225066185\n",
      "[280,     1] loss: 0.08596542477607727\n",
      "[281,     1] loss: 0.08527316898107529\n",
      "[282,     1] loss: 0.08459317684173584\n",
      "[283,     1] loss: 0.08390660583972931\n",
      "[284,     1] loss: 0.08321981132030487\n",
      "[285,     1] loss: 0.08255863189697266\n",
      "[286,     1] loss: 0.08189097791910172\n",
      "[287,     1] loss: 0.08124183118343353\n",
      "[288,     1] loss: 0.08060016483068466\n",
      "[289,     1] loss: 0.07997177541255951\n",
      "[290,     1] loss: 0.07936760783195496\n",
      "[291,     1] loss: 0.07876843959093094\n",
      "[292,     1] loss: 0.07816968113183975\n",
      "[293,     1] loss: 0.07758136838674545\n",
      "[294,     1] loss: 0.07700233906507492\n",
      "[295,     1] loss: 0.07643626630306244\n",
      "[296,     1] loss: 0.07589384913444519\n",
      "[297,     1] loss: 0.0753466933965683\n",
      "[298,     1] loss: 0.07479498535394669\n",
      "[299,     1] loss: 0.07426314800977707\n",
      "[300,     1] loss: 0.07372593879699707\n",
      "[301,     1] loss: 0.07319166511297226\n",
      "[302,     1] loss: 0.07266364991664886\n",
      "[303,     1] loss: 0.07213716953992844\n",
      "[304,     1] loss: 0.07159918546676636\n",
      "[305,     1] loss: 0.071059450507164\n",
      "[306,     1] loss: 0.0705270990729332\n",
      "[307,     1] loss: 0.07000856101512909\n",
      "[308,     1] loss: 0.06947986781597137\n",
      "[309,     1] loss: 0.06896655261516571\n",
      "[310,     1] loss: 0.06846397370100021\n",
      "[311,     1] loss: 0.06796357035636902\n",
      "[312,     1] loss: 0.06746800243854523\n",
      "[313,     1] loss: 0.06697949022054672\n",
      "[314,     1] loss: 0.06649678945541382\n",
      "[315,     1] loss: 0.06602858752012253\n",
      "[316,     1] loss: 0.06555943936109543\n",
      "[317,     1] loss: 0.06510963290929794\n",
      "[318,     1] loss: 0.06465977430343628\n",
      "[319,     1] loss: 0.06421804428100586\n",
      "[320,     1] loss: 0.06379181891679764\n",
      "[321,     1] loss: 0.06335419416427612\n",
      "[322,     1] loss: 0.06293804943561554\n",
      "[323,     1] loss: 0.06251533329486847\n",
      "[324,     1] loss: 0.06209293752908707\n",
      "[325,     1] loss: 0.06169106811285019\n",
      "[326,     1] loss: 0.06128675490617752\n",
      "[327,     1] loss: 0.06088019162416458\n",
      "[328,     1] loss: 0.060487959533929825\n",
      "[329,     1] loss: 0.060091011226177216\n",
      "[330,     1] loss: 0.05970102548599243\n",
      "[331,     1] loss: 0.059326592832803726\n",
      "[332,     1] loss: 0.05894835293292999\n",
      "[333,     1] loss: 0.05858936160802841\n",
      "[334,     1] loss: 0.05823669582605362\n",
      "[335,     1] loss: 0.057861924171447754\n",
      "[336,     1] loss: 0.05748363211750984\n",
      "[337,     1] loss: 0.0570991113781929\n",
      "[338,     1] loss: 0.05672222003340721\n",
      "[339,     1] loss: 0.05635195970535278\n",
      "[340,     1] loss: 0.055999185889959335\n",
      "[341,     1] loss: 0.055647775530815125\n",
      "[342,     1] loss: 0.055311109870672226\n",
      "[343,     1] loss: 0.05496346205472946\n",
      "[344,     1] loss: 0.05462293699383736\n",
      "[345,     1] loss: 0.05428706854581833\n",
      "[346,     1] loss: 0.053956061601638794\n",
      "[347,     1] loss: 0.053627029061317444\n",
      "[348,     1] loss: 0.0532965287566185\n",
      "[349,     1] loss: 0.052976466715335846\n",
      "[350,     1] loss: 0.052659161388874054\n",
      "[351,     1] loss: 0.05234212428331375\n",
      "[352,     1] loss: 0.05203188955783844\n",
      "[353,     1] loss: 0.05172022804617882\n",
      "[354,     1] loss: 0.051411714404821396\n",
      "[355,     1] loss: 0.051106490194797516\n",
      "[356,     1] loss: 0.05082006752490997\n",
      "[357,     1] loss: 0.050528984516859055\n",
      "[358,     1] loss: 0.050231240689754486\n",
      "[359,     1] loss: 0.049950502812862396\n",
      "[360,     1] loss: 0.04966505616903305\n",
      "[361,     1] loss: 0.04936743155121803\n",
      "[362,     1] loss: 0.04908037930727005\n",
      "[363,     1] loss: 0.04878757894039154\n",
      "[364,     1] loss: 0.048496343195438385\n",
      "[365,     1] loss: 0.04820116236805916\n",
      "[366,     1] loss: 0.04790491238236427\n",
      "[367,     1] loss: 0.04762399569153786\n",
      "[368,     1] loss: 0.047357227653265\n",
      "[369,     1] loss: 0.04707864671945572\n",
      "[370,     1] loss: 0.046802010387182236\n",
      "[371,     1] loss: 0.0465318001806736\n",
      "[372,     1] loss: 0.046263083815574646\n",
      "[373,     1] loss: 0.0459938608109951\n",
      "[374,     1] loss: 0.04573337733745575\n",
      "[375,     1] loss: 0.04549255222082138\n",
      "[376,     1] loss: 0.04526291787624359\n",
      "[377,     1] loss: 0.045037657022476196\n",
      "[378,     1] loss: 0.04483164846897125\n",
      "[379,     1] loss: 0.04460446909070015\n",
      "[380,     1] loss: 0.04435780644416809\n",
      "[381,     1] loss: 0.04403633996844292\n",
      "[382,     1] loss: 0.0437166802585125\n",
      "[383,     1] loss: 0.043438881635665894\n",
      "[384,     1] loss: 0.04321745038032532\n",
      "[385,     1] loss: 0.043039314448833466\n",
      "[386,     1] loss: 0.04282054305076599\n",
      "[387,     1] loss: 0.042559847235679626\n",
      "[388,     1] loss: 0.042273759841918945\n",
      "[389,     1] loss: 0.04201774671673775\n",
      "[390,     1] loss: 0.041800372302532196\n",
      "[391,     1] loss: 0.04161323606967926\n",
      "[392,     1] loss: 0.04141053557395935\n",
      "[393,     1] loss: 0.041178204119205475\n",
      "[394,     1] loss: 0.040924809873104095\n",
      "[395,     1] loss: 0.040693797171115875\n",
      "[396,     1] loss: 0.04047151282429695\n",
      "[397,     1] loss: 0.04027213528752327\n",
      "[398,     1] loss: 0.040088675916194916\n",
      "[399,     1] loss: 0.03989198058843613\n",
      "[400,     1] loss: 0.039682209491729736\n",
      "[401,     1] loss: 0.03947177156805992\n",
      "[402,     1] loss: 0.03926528990268707\n",
      "[403,     1] loss: 0.039076972752809525\n",
      "[404,     1] loss: 0.0388898067176342\n",
      "[405,     1] loss: 0.03869903087615967\n",
      "[406,     1] loss: 0.03850251063704491\n",
      "[407,     1] loss: 0.03830549120903015\n",
      "[408,     1] loss: 0.038112539798021317\n",
      "[409,     1] loss: 0.037921831011772156\n",
      "[410,     1] loss: 0.03774895519018173\n",
      "[411,     1] loss: 0.03757627308368683\n",
      "[412,     1] loss: 0.03740036115050316\n",
      "[413,     1] loss: 0.03722423315048218\n",
      "[414,     1] loss: 0.0370493158698082\n",
      "[415,     1] loss: 0.03687320649623871\n",
      "[416,     1] loss: 0.036704838275909424\n",
      "[417,     1] loss: 0.036537881940603256\n",
      "[418,     1] loss: 0.036376599222421646\n",
      "[419,     1] loss: 0.03621711581945419\n",
      "[420,     1] loss: 0.036050714552402496\n",
      "[421,     1] loss: 0.035887107253074646\n",
      "[422,     1] loss: 0.03572215512394905\n",
      "[423,     1] loss: 0.035557009279727936\n",
      "[424,     1] loss: 0.035396892577409744\n",
      "[425,     1] loss: 0.03523783013224602\n",
      "[426,     1] loss: 0.0350835919380188\n",
      "[427,     1] loss: 0.034929193556308746\n",
      "[428,     1] loss: 0.03478534519672394\n",
      "[429,     1] loss: 0.03465050086379051\n",
      "[430,     1] loss: 0.03451364487409592\n",
      "[431,     1] loss: 0.03438342735171318\n",
      "[432,     1] loss: 0.03424576297402382\n",
      "[433,     1] loss: 0.034096553921699524\n",
      "[434,     1] loss: 0.03393063321709633\n",
      "[435,     1] loss: 0.0337631031870842\n",
      "[436,     1] loss: 0.03360433876514435\n",
      "[437,     1] loss: 0.03345967456698418\n",
      "[438,     1] loss: 0.033330030739307404\n",
      "[439,     1] loss: 0.03320305049419403\n",
      "[440,     1] loss: 0.033072322607040405\n",
      "[441,     1] loss: 0.03293786942958832\n",
      "[442,     1] loss: 0.03280305117368698\n",
      "[443,     1] loss: 0.03265205770730972\n",
      "[444,     1] loss: 0.032498255372047424\n",
      "[445,     1] loss: 0.03234867751598358\n",
      "[446,     1] loss: 0.032211512327194214\n",
      "[447,     1] loss: 0.03208533674478531\n",
      "[448,     1] loss: 0.031964778900146484\n",
      "[449,     1] loss: 0.03184695541858673\n",
      "[450,     1] loss: 0.03173116222023964\n",
      "[451,     1] loss: 0.03160775825381279\n",
      "[452,     1] loss: 0.031484369188547134\n",
      "[453,     1] loss: 0.03136202692985535\n",
      "[454,     1] loss: 0.03122832253575325\n",
      "[455,     1] loss: 0.031077764928340912\n",
      "[456,     1] loss: 0.030931614339351654\n",
      "[457,     1] loss: 0.03079800307750702\n",
      "[458,     1] loss: 0.030680416151881218\n",
      "[459,     1] loss: 0.030566247180104256\n",
      "[460,     1] loss: 0.03045833110809326\n",
      "[461,     1] loss: 0.030356261879205704\n",
      "[462,     1] loss: 0.030252007767558098\n",
      "[463,     1] loss: 0.030123259872198105\n",
      "[464,     1] loss: 0.029988672584295273\n",
      "[465,     1] loss: 0.02985526993870735\n",
      "[466,     1] loss: 0.029727254062891006\n",
      "[467,     1] loss: 0.02960677444934845\n",
      "[468,     1] loss: 0.0294830072671175\n",
      "[469,     1] loss: 0.02936374954879284\n",
      "[470,     1] loss: 0.029231499880552292\n",
      "[471,     1] loss: 0.02910209633409977\n",
      "[472,     1] loss: 0.02897745370864868\n",
      "[473,     1] loss: 0.028864577412605286\n",
      "[474,     1] loss: 0.028737854212522507\n",
      "[475,     1] loss: 0.028589535504579544\n",
      "[476,     1] loss: 0.02843930572271347\n",
      "[477,     1] loss: 0.028295747935771942\n",
      "[478,     1] loss: 0.02816661074757576\n",
      "[479,     1] loss: 0.028051301836967468\n",
      "[480,     1] loss: 0.027942325919866562\n",
      "[481,     1] loss: 0.027838923037052155\n",
      "[482,     1] loss: 0.027729492634534836\n",
      "[483,     1] loss: 0.027605291455984116\n",
      "[484,     1] loss: 0.027469053864479065\n",
      "[485,     1] loss: 0.027317924425005913\n",
      "[486,     1] loss: 0.027176188305020332\n",
      "[487,     1] loss: 0.027053292840719223\n",
      "[488,     1] loss: 0.02694922313094139\n",
      "[489,     1] loss: 0.02685074508190155\n",
      "[490,     1] loss: 0.02673954702913761\n",
      "[491,     1] loss: 0.02663116529583931\n",
      "[492,     1] loss: 0.02651173435151577\n",
      "[493,     1] loss: 0.026394188404083252\n",
      "[494,     1] loss: 0.026274610310792923\n",
      "[495,     1] loss: 0.026162488386034966\n",
      "[496,     1] loss: 0.026055585592985153\n",
      "[497,     1] loss: 0.025951888412237167\n",
      "[498,     1] loss: 0.025849344208836555\n",
      "[499,     1] loss: 0.025739623233675957\n",
      "[500,     1] loss: 0.02562534250319004\n",
      "[501,     1] loss: 0.025516904890537262\n",
      "[502,     1] loss: 0.02540859393775463\n",
      "[503,     1] loss: 0.025297310203313828\n",
      "[504,     1] loss: 0.02519148588180542\n",
      "[505,     1] loss: 0.025087349116802216\n",
      "[506,     1] loss: 0.02498428151011467\n",
      "[507,     1] loss: 0.024874277412891388\n",
      "[508,     1] loss: 0.024768691509962082\n",
      "[509,     1] loss: 0.024664396420121193\n",
      "[510,     1] loss: 0.02455788664519787\n",
      "[511,     1] loss: 0.024448679760098457\n",
      "[512,     1] loss: 0.02433730661869049\n",
      "[513,     1] loss: 0.024231113493442535\n",
      "[514,     1] loss: 0.024128388613462448\n",
      "[515,     1] loss: 0.02403007261455059\n",
      "[516,     1] loss: 0.023940257728099823\n",
      "[517,     1] loss: 0.023848485201597214\n",
      "[518,     1] loss: 0.02375270612537861\n",
      "[519,     1] loss: 0.02365693636238575\n",
      "[520,     1] loss: 0.02355491742491722\n",
      "[521,     1] loss: 0.023451682180166245\n",
      "[522,     1] loss: 0.023344168439507484\n",
      "[523,     1] loss: 0.023243093863129616\n",
      "[524,     1] loss: 0.02314753457903862\n",
      "[525,     1] loss: 0.023054730147123337\n",
      "[526,     1] loss: 0.022968940436840057\n",
      "[527,     1] loss: 0.02288632094860077\n",
      "[528,     1] loss: 0.02280687540769577\n",
      "[529,     1] loss: 0.022722749039530754\n",
      "[530,     1] loss: 0.02263425849378109\n",
      "[531,     1] loss: 0.022557290270924568\n",
      "[532,     1] loss: 0.022481553256511688\n",
      "[533,     1] loss: 0.022411556914448738\n",
      "[534,     1] loss: 0.022335762158036232\n",
      "[535,     1] loss: 0.022249868139624596\n",
      "[536,     1] loss: 0.02214590460062027\n",
      "[537,     1] loss: 0.02203873172402382\n",
      "[538,     1] loss: 0.02193845994770527\n",
      "[539,     1] loss: 0.021846387535333633\n",
      "[540,     1] loss: 0.021769028156995773\n",
      "[541,     1] loss: 0.021701673045754433\n",
      "[542,     1] loss: 0.021648433059453964\n",
      "[543,     1] loss: 0.021592173725366592\n",
      "[544,     1] loss: 0.02154586650431156\n",
      "[545,     1] loss: 0.021485429257154465\n",
      "[546,     1] loss: 0.021413085982203484\n",
      "[547,     1] loss: 0.02130953222513199\n",
      "[548,     1] loss: 0.02119334042072296\n",
      "[549,     1] loss: 0.021079707890748978\n",
      "[550,     1] loss: 0.020988959819078445\n",
      "[551,     1] loss: 0.020941458642482758\n",
      "[552,     1] loss: 0.02088170312345028\n",
      "[553,     1] loss: 0.02083677239716053\n",
      "[554,     1] loss: 0.020796015858650208\n",
      "[555,     1] loss: 0.02073591761291027\n",
      "[556,     1] loss: 0.020656228065490723\n",
      "[557,     1] loss: 0.020555345341563225\n",
      "[558,     1] loss: 0.020448870956897736\n",
      "[559,     1] loss: 0.020352210849523544\n",
      "[560,     1] loss: 0.020267397165298462\n",
      "[561,     1] loss: 0.020211437717080116\n",
      "[562,     1] loss: 0.020166225731372833\n",
      "[563,     1] loss: 0.0201182272285223\n",
      "[564,     1] loss: 0.020064130425453186\n",
      "[565,     1] loss: 0.019998088479042053\n",
      "[566,     1] loss: 0.019920093938708305\n",
      "[567,     1] loss: 0.019826997071504593\n",
      "[568,     1] loss: 0.019739581272006035\n",
      "[569,     1] loss: 0.01965617947280407\n",
      "[570,     1] loss: 0.019571341574192047\n",
      "[571,     1] loss: 0.0194957684725523\n",
      "[572,     1] loss: 0.019433366134762764\n",
      "[573,     1] loss: 0.019370872527360916\n",
      "[574,     1] loss: 0.019305739551782608\n",
      "[575,     1] loss: 0.019255321472883224\n",
      "[576,     1] loss: 0.019198250025510788\n",
      "[577,     1] loss: 0.019124796614050865\n",
      "[578,     1] loss: 0.019043678417801857\n",
      "[579,     1] loss: 0.018957503139972687\n",
      "[580,     1] loss: 0.0188753604888916\n",
      "[581,     1] loss: 0.018792932853102684\n",
      "[582,     1] loss: 0.0187222957611084\n",
      "[583,     1] loss: 0.018651124089956284\n",
      "[584,     1] loss: 0.018596038222312927\n",
      "[585,     1] loss: 0.018535194918513298\n",
      "[586,     1] loss: 0.018477538600564003\n",
      "[587,     1] loss: 0.018412664532661438\n",
      "[588,     1] loss: 0.018341675400733948\n",
      "[589,     1] loss: 0.018264811486005783\n",
      "[590,     1] loss: 0.01818249002099037\n",
      "[591,     1] loss: 0.018107114359736443\n",
      "[592,     1] loss: 0.018025128170847893\n",
      "[593,     1] loss: 0.01795986481010914\n",
      "[594,     1] loss: 0.01789015345275402\n",
      "[595,     1] loss: 0.01782257668673992\n",
      "[596,     1] loss: 0.0177538450807333\n",
      "[597,     1] loss: 0.017687102779746056\n",
      "[598,     1] loss: 0.01762455888092518\n",
      "[599,     1] loss: 0.01756381429731846\n",
      "[600,     1] loss: 0.01750602386891842\n",
      "[601,     1] loss: 0.017443645745515823\n",
      "[602,     1] loss: 0.017383722588419914\n",
      "[603,     1] loss: 0.01732274889945984\n",
      "[604,     1] loss: 0.017268138006329536\n",
      "[605,     1] loss: 0.017205514013767242\n",
      "[606,     1] loss: 0.017143700271844864\n",
      "[607,     1] loss: 0.017083346843719482\n",
      "[608,     1] loss: 0.01702318713068962\n",
      "[609,     1] loss: 0.01695180870592594\n",
      "[610,     1] loss: 0.01689412258565426\n",
      "[611,     1] loss: 0.016827279701828957\n",
      "[612,     1] loss: 0.016759026795625687\n",
      "[613,     1] loss: 0.016692236065864563\n",
      "[614,     1] loss: 0.016635553911328316\n",
      "[615,     1] loss: 0.016568467020988464\n",
      "[616,     1] loss: 0.0164930559694767\n",
      "[617,     1] loss: 0.01641874946653843\n",
      "[618,     1] loss: 0.016355440020561218\n",
      "[619,     1] loss: 0.016293318942189217\n",
      "[620,     1] loss: 0.01624145358800888\n",
      "[621,     1] loss: 0.01619584858417511\n",
      "[622,     1] loss: 0.016147851943969727\n",
      "[623,     1] loss: 0.016115423291921616\n",
      "[624,     1] loss: 0.016088217496871948\n",
      "[625,     1] loss: 0.016031546518206596\n",
      "[626,     1] loss: 0.0159761905670166\n",
      "[627,     1] loss: 0.015904664993286133\n",
      "[628,     1] loss: 0.015853073447942734\n",
      "[629,     1] loss: 0.015776731073856354\n",
      "[630,     1] loss: 0.0156855545938015\n",
      "[631,     1] loss: 0.01558922603726387\n",
      "[632,     1] loss: 0.015517251566052437\n",
      "[633,     1] loss: 0.015442168340086937\n",
      "[634,     1] loss: 0.015367474406957626\n",
      "[635,     1] loss: 0.015304055996239185\n",
      "[636,     1] loss: 0.015258989296853542\n",
      "[637,     1] loss: 0.015207517892122269\n",
      "[638,     1] loss: 0.015152055770158768\n",
      "[639,     1] loss: 0.015109563246369362\n",
      "[640,     1] loss: 0.015076255425810814\n",
      "[641,     1] loss: 0.015052704140543938\n",
      "[642,     1] loss: 0.015023106709122658\n",
      "[643,     1] loss: 0.015038914978504181\n",
      "[644,     1] loss: 0.01502695307135582\n",
      "[645,     1] loss: 0.014986430294811726\n",
      "[646,     1] loss: 0.014896683394908905\n",
      "[647,     1] loss: 0.014794403687119484\n",
      "[648,     1] loss: 0.014666618779301643\n",
      "[649,     1] loss: 0.014555164612829685\n",
      "[650,     1] loss: 0.01447975356131792\n",
      "[651,     1] loss: 0.014434149488806725\n",
      "[652,     1] loss: 0.01441020704805851\n",
      "[653,     1] loss: 0.014391317963600159\n",
      "[654,     1] loss: 0.014373557642102242\n",
      "[655,     1] loss: 0.014325328171253204\n",
      "[656,     1] loss: 0.014267298392951488\n",
      "[657,     1] loss: 0.014188267290592194\n",
      "[658,     1] loss: 0.014109630137681961\n",
      "[659,     1] loss: 0.014028478413820267\n",
      "[660,     1] loss: 0.013966266065835953\n",
      "[661,     1] loss: 0.013912945985794067\n",
      "[662,     1] loss: 0.013878975063562393\n",
      "[663,     1] loss: 0.013869746588170528\n",
      "[664,     1] loss: 0.013868970796465874\n",
      "[665,     1] loss: 0.013871708884835243\n",
      "[666,     1] loss: 0.013839233666658401\n",
      "[667,     1] loss: 0.0137818343937397\n",
      "[668,     1] loss: 0.013703734613955021\n",
      "[669,     1] loss: 0.013611561618745327\n",
      "[670,     1] loss: 0.013528808951377869\n",
      "[671,     1] loss: 0.013465570285916328\n",
      "[672,     1] loss: 0.013435523957014084\n",
      "[673,     1] loss: 0.013409844599664211\n",
      "[674,     1] loss: 0.013386551290750504\n",
      "[675,     1] loss: 0.013371851295232773\n",
      "[676,     1] loss: 0.01337343268096447\n",
      "[677,     1] loss: 0.013343247584998608\n",
      "[678,     1] loss: 0.013302555307745934\n",
      "[679,     1] loss: 0.013241174630820751\n",
      "[680,     1] loss: 0.013171764090657234\n",
      "[681,     1] loss: 0.013094916008412838\n",
      "[682,     1] loss: 0.013017496094107628\n",
      "[683,     1] loss: 0.012970011681318283\n",
      "[684,     1] loss: 0.012956960126757622\n",
      "[685,     1] loss: 0.012963883578777313\n",
      "[686,     1] loss: 0.01298022735863924\n",
      "[687,     1] loss: 0.012998213991522789\n",
      "[688,     1] loss: 0.012976438738405704\n",
      "[689,     1] loss: 0.012940458953380585\n",
      "[690,     1] loss: 0.012847788631916046\n",
      "[691,     1] loss: 0.012752851471304893\n",
      "[692,     1] loss: 0.012658978812396526\n",
      "[693,     1] loss: 0.012590737082064152\n",
      "[694,     1] loss: 0.012559995986521244\n",
      "[695,     1] loss: 0.012553941458463669\n",
      "[696,     1] loss: 0.012560533359646797\n",
      "[697,     1] loss: 0.012544035911560059\n",
      "[698,     1] loss: 0.01253307145088911\n",
      "[699,     1] loss: 0.012494001537561417\n",
      "[700,     1] loss: 0.01243660133332014\n",
      "[701,     1] loss: 0.012358201667666435\n",
      "[702,     1] loss: 0.012288251891732216\n",
      "[703,     1] loss: 0.012234918773174286\n",
      "[704,     1] loss: 0.012204392813146114\n",
      "[705,     1] loss: 0.012205854058265686\n",
      "[706,     1] loss: 0.01221827045083046\n",
      "[707,     1] loss: 0.012236813083291054\n",
      "[708,     1] loss: 0.012224197387695312\n",
      "[709,     1] loss: 0.012195484712719917\n",
      "[710,     1] loss: 0.012121890671551228\n",
      "[711,     1] loss: 0.012042476795613766\n",
      "[712,     1] loss: 0.011957041919231415\n",
      "[713,     1] loss: 0.011900248937308788\n",
      "[714,     1] loss: 0.011879464611411095\n",
      "[715,     1] loss: 0.011883473955094814\n",
      "[716,     1] loss: 0.011902786791324615\n",
      "[717,     1] loss: 0.011912448331713676\n",
      "[718,     1] loss: 0.01190983410924673\n",
      "[719,     1] loss: 0.011859155260026455\n",
      "[720,     1] loss: 0.011794442310929298\n",
      "[721,     1] loss: 0.011708893813192844\n",
      "[722,     1] loss: 0.011635477654635906\n",
      "[723,     1] loss: 0.011580433696508408\n",
      "[724,     1] loss: 0.011554556898772717\n",
      "[725,     1] loss: 0.01154731959104538\n",
      "[726,     1] loss: 0.011542846448719501\n",
      "[727,     1] loss: 0.01154362689703703\n",
      "[728,     1] loss: 0.011523714289069176\n",
      "[729,     1] loss: 0.01148324366658926\n",
      "[730,     1] loss: 0.01142793521285057\n",
      "[731,     1] loss: 0.011371278204023838\n",
      "[732,     1] loss: 0.01132393628358841\n",
      "[733,     1] loss: 0.011282017454504967\n",
      "[734,     1] loss: 0.011248038150370121\n",
      "[735,     1] loss: 0.011229431256651878\n",
      "[736,     1] loss: 0.011211537756025791\n",
      "[737,     1] loss: 0.011193408630788326\n",
      "[738,     1] loss: 0.01118482369929552\n",
      "[739,     1] loss: 0.011172418482601643\n",
      "[740,     1] loss: 0.011154429987072945\n",
      "[741,     1] loss: 0.011119140312075615\n",
      "[742,     1] loss: 0.011076387949287891\n",
      "[743,     1] loss: 0.011029954999685287\n",
      "[744,     1] loss: 0.010989734902977943\n",
      "[745,     1] loss: 0.010947979055345058\n",
      "[746,     1] loss: 0.010908269323408604\n",
      "[747,     1] loss: 0.010877787135541439\n",
      "[748,     1] loss: 0.01085579115897417\n",
      "[749,     1] loss: 0.010831335559487343\n",
      "[750,     1] loss: 0.010798227973282337\n",
      "[751,     1] loss: 0.010766619816422462\n",
      "[752,     1] loss: 0.010739867575466633\n",
      "[753,     1] loss: 0.010715301148593426\n",
      "[754,     1] loss: 0.010691046714782715\n",
      "[755,     1] loss: 0.010669548995792866\n",
      "[756,     1] loss: 0.010656336322426796\n",
      "[757,     1] loss: 0.010655994527041912\n",
      "[758,     1] loss: 0.010667946189641953\n",
      "[759,     1] loss: 0.010699227452278137\n",
      "[760,     1] loss: 0.010728253051638603\n",
      "[761,     1] loss: 0.010776509530842304\n",
      "[762,     1] loss: 0.010778149589896202\n",
      "[763,     1] loss: 0.010749046690762043\n",
      "[764,     1] loss: 0.01064379047602415\n",
      "[765,     1] loss: 0.0105360122397542\n",
      "[766,     1] loss: 0.01042704377323389\n",
      "[767,     1] loss: 0.01035126019269228\n",
      "[768,     1] loss: 0.010330602526664734\n",
      "[769,     1] loss: 0.010342767462134361\n",
      "[770,     1] loss: 0.010373838245868683\n",
      "[771,     1] loss: 0.010396822355687618\n",
      "[772,     1] loss: 0.010398992337286472\n",
      "[773,     1] loss: 0.010363740846514702\n",
      "[774,     1] loss: 0.010325580835342407\n",
      "[775,     1] loss: 0.010257295332849026\n",
      "[776,     1] loss: 0.010180696845054626\n",
      "[777,     1] loss: 0.010117536410689354\n",
      "[778,     1] loss: 0.010075214318931103\n",
      "[779,     1] loss: 0.010060509666800499\n",
      "[780,     1] loss: 0.010060211643576622\n",
      "[781,     1] loss: 0.010069005191326141\n",
      "[782,     1] loss: 0.010072377510368824\n",
      "[783,     1] loss: 0.010065610520541668\n",
      "[784,     1] loss: 0.010034545324742794\n",
      "[785,     1] loss: 0.009996658191084862\n",
      "[786,     1] loss: 0.009946977719664574\n",
      "[787,     1] loss: 0.009897616691887379\n",
      "[788,     1] loss: 0.009846363216638565\n",
      "[789,     1] loss: 0.009804956614971161\n",
      "[790,     1] loss: 0.00977741926908493\n",
      "[791,     1] loss: 0.009758946485817432\n",
      "[792,     1] loss: 0.009747899137437344\n",
      "[793,     1] loss: 0.009740278124809265\n",
      "[794,     1] loss: 0.009740587323904037\n",
      "[795,     1] loss: 0.009737914428114891\n",
      "[796,     1] loss: 0.00974280945956707\n",
      "[797,     1] loss: 0.009737000800669193\n",
      "[798,     1] loss: 0.00972190871834755\n",
      "[799,     1] loss: 0.00968867912888527\n",
      "[800,     1] loss: 0.009655882604420185\n",
      "[801,     1] loss: 0.009604963473975658\n",
      "[802,     1] loss: 0.009542262181639671\n",
      "[803,     1] loss: 0.009488129988312721\n",
      "[804,     1] loss: 0.009450913406908512\n",
      "[805,     1] loss: 0.009432109072804451\n",
      "[806,     1] loss: 0.009433561936020851\n",
      "[807,     1] loss: 0.009466570802032948\n",
      "[808,     1] loss: 0.00951683521270752\n",
      "[809,     1] loss: 0.009615740738809109\n",
      "[810,     1] loss: 0.009648412466049194\n",
      "[811,     1] loss: 0.009649987332522869\n",
      "[812,     1] loss: 0.00954131968319416\n",
      "[813,     1] loss: 0.00942390039563179\n",
      "[814,     1] loss: 0.009296021424233913\n",
      "[815,     1] loss: 0.00921604223549366\n",
      "[816,     1] loss: 0.009191346354782581\n",
      "[817,     1] loss: 0.00920831598341465\n",
      "[818,     1] loss: 0.009258987382054329\n",
      "[819,     1] loss: 0.009303596802055836\n",
      "[820,     1] loss: 0.009360043331980705\n",
      "[821,     1] loss: 0.009354205802083015\n",
      "[822,     1] loss: 0.009348517283797264\n",
      "[823,     1] loss: 0.00924770999699831\n",
      "[824,     1] loss: 0.009120726957917213\n",
      "[825,     1] loss: 0.009025203995406628\n",
      "[826,     1] loss: 0.008974932134151459\n",
      "[827,     1] loss: 0.008958997204899788\n",
      "[828,     1] loss: 0.008965865708887577\n",
      "[829,     1] loss: 0.00899403914809227\n",
      "[830,     1] loss: 0.009018545038998127\n",
      "[831,     1] loss: 0.009036201052367687\n",
      "[832,     1] loss: 0.009012704715132713\n",
      "[833,     1] loss: 0.008974865078926086\n",
      "[834,     1] loss: 0.00890359003096819\n",
      "[835,     1] loss: 0.008853836916387081\n",
      "[836,     1] loss: 0.008796429261565208\n",
      "[837,     1] loss: 0.00875149667263031\n",
      "[838,     1] loss: 0.008721939288079739\n",
      "[839,     1] loss: 0.008704611100256443\n",
      "[840,     1] loss: 0.008697917684912682\n",
      "[841,     1] loss: 0.00869704782962799\n",
      "[842,     1] loss: 0.00870006624609232\n",
      "[843,     1] loss: 0.008696152828633785\n",
      "[844,     1] loss: 0.008699815720319748\n",
      "[845,     1] loss: 0.008687007240951061\n",
      "[846,     1] loss: 0.008661964908242226\n",
      "[847,     1] loss: 0.008614231832325459\n",
      "[848,     1] loss: 0.008571252226829529\n",
      "[849,     1] loss: 0.008526946417987347\n",
      "[850,     1] loss: 0.008489569649100304\n",
      "[851,     1] loss: 0.00846612174063921\n",
      "[852,     1] loss: 0.008455055765807629\n",
      "[853,     1] loss: 0.008454849943518639\n",
      "[854,     1] loss: 0.00845714844763279\n",
      "[855,     1] loss: 0.008475571870803833\n",
      "[856,     1] loss: 0.00848845113068819\n",
      "[857,     1] loss: 0.0085306316614151\n",
      "[858,     1] loss: 0.008533774875104427\n",
      "[859,     1] loss: 0.008520775474607944\n",
      "[860,     1] loss: 0.008455945178866386\n",
      "[861,     1] loss: 0.008382471278309822\n",
      "[862,     1] loss: 0.00830800924450159\n",
      "[863,     1] loss: 0.008257727138698101\n",
      "[864,     1] loss: 0.008238458074629307\n",
      "[865,     1] loss: 0.00824733730405569\n",
      "[866,     1] loss: 0.008271806873381138\n",
      "[867,     1] loss: 0.008287506178021431\n",
      "[868,     1] loss: 0.00829956866800785\n",
      "[869,     1] loss: 0.008281589485704899\n",
      "[870,     1] loss: 0.008265172131359577\n",
      "[871,     1] loss: 0.008220851421356201\n",
      "[872,     1] loss: 0.008184230886399746\n",
      "[873,     1] loss: 0.008131458424031734\n",
      "[874,     1] loss: 0.008082594722509384\n",
      "[875,     1] loss: 0.008045930415391922\n",
      "[876,     1] loss: 0.008029548451304436\n",
      "[877,     1] loss: 0.00802928488701582\n",
      "[878,     1] loss: 0.00803440809249878\n",
      "[879,     1] loss: 0.008042844012379646\n",
      "[880,     1] loss: 0.008041542023420334\n",
      "[881,     1] loss: 0.008055467158555984\n",
      "[882,     1] loss: 0.008049880154430866\n",
      "[883,     1] loss: 0.008049043826758862\n",
      "[884,     1] loss: 0.008018897846341133\n",
      "[885,     1] loss: 0.007975734770298004\n",
      "[886,     1] loss: 0.007919728755950928\n",
      "[887,     1] loss: 0.007870638743042946\n",
      "[888,     1] loss: 0.00783474836498499\n",
      "[889,     1] loss: 0.00781488511711359\n",
      "[890,     1] loss: 0.00780823826789856\n",
      "[891,     1] loss: 0.007810160517692566\n",
      "[892,     1] loss: 0.007820285856723785\n",
      "[893,     1] loss: 0.007829030975699425\n",
      "[894,     1] loss: 0.007836967706680298\n",
      "[895,     1] loss: 0.007829821668565273\n",
      "[896,     1] loss: 0.00782763585448265\n",
      "[897,     1] loss: 0.007802347652614117\n",
      "[898,     1] loss: 0.007766650058329105\n",
      "[899,     1] loss: 0.007720085792243481\n",
      "[900,     1] loss: 0.0076729655265808105\n",
      "[901,     1] loss: 0.007635789457708597\n",
      "[902,     1] loss: 0.007610643282532692\n",
      "[903,     1] loss: 0.007599387317895889\n",
      "[904,     1] loss: 0.007593558635562658\n",
      "[905,     1] loss: 0.007600158452987671\n",
      "[906,     1] loss: 0.007610605098307133\n",
      "[907,     1] loss: 0.0076238904148340225\n",
      "[908,     1] loss: 0.00763038732111454\n",
      "[909,     1] loss: 0.007648773491382599\n",
      "[910,     1] loss: 0.007645871490240097\n",
      "[911,     1] loss: 0.007644688710570335\n",
      "[912,     1] loss: 0.007618451490998268\n",
      "[913,     1] loss: 0.007589274551719427\n",
      "[914,     1] loss: 0.00754269864410162\n",
      "[915,     1] loss: 0.00748876016587019\n",
      "[916,     1] loss: 0.007439319044351578\n",
      "[917,     1] loss: 0.007402355782687664\n",
      "[918,     1] loss: 0.007376974914222956\n",
      "[919,     1] loss: 0.007358843926340342\n",
      "[920,     1] loss: 0.0073510343208909035\n",
      "[921,     1] loss: 0.007343355566263199\n",
      "[922,     1] loss: 0.007338933181017637\n",
      "[923,     1] loss: 0.007333352230489254\n",
      "[924,     1] loss: 0.007329081185162067\n",
      "[925,     1] loss: 0.00732021126896143\n",
      "[926,     1] loss: 0.00731848506256938\n",
      "[927,     1] loss: 0.007315109483897686\n",
      "[928,     1] loss: 0.007311881519854069\n",
      "[929,     1] loss: 0.007307328283786774\n",
      "[930,     1] loss: 0.007307013962417841\n",
      "[931,     1] loss: 0.007300873287022114\n",
      "[932,     1] loss: 0.007290662731975317\n",
      "[933,     1] loss: 0.007276526652276516\n",
      "[934,     1] loss: 0.007261739112436771\n",
      "[935,     1] loss: 0.007240914739668369\n",
      "[936,     1] loss: 0.00721392035484314\n",
      "[937,     1] loss: 0.0071819550357759\n",
      "[938,     1] loss: 0.007161097601056099\n",
      "[939,     1] loss: 0.007136934902518988\n",
      "[940,     1] loss: 0.0071082706563174725\n",
      "[941,     1] loss: 0.007082686293870211\n",
      "[942,     1] loss: 0.007059215568006039\n",
      "[943,     1] loss: 0.007040577009320259\n",
      "[944,     1] loss: 0.007022617384791374\n",
      "[945,     1] loss: 0.00700792483985424\n",
      "[946,     1] loss: 0.006994431372731924\n",
      "[947,     1] loss: 0.006981588434427977\n",
      "[948,     1] loss: 0.006969247478991747\n",
      "[949,     1] loss: 0.0069589680060744286\n",
      "[950,     1] loss: 0.006953167729079723\n",
      "[951,     1] loss: 0.0069412183947861195\n",
      "[952,     1] loss: 0.006939471233636141\n",
      "[953,     1] loss: 0.006945870816707611\n",
      "[954,     1] loss: 0.006965404376387596\n",
      "[955,     1] loss: 0.00699358806014061\n",
      "[956,     1] loss: 0.007038639858365059\n",
      "[957,     1] loss: 0.007082413882017136\n",
      "[958,     1] loss: 0.007160291541367769\n",
      "[959,     1] loss: 0.007218183483928442\n",
      "[960,     1] loss: 0.007301055360585451\n",
      "[961,     1] loss: 0.007308624219149351\n",
      "[962,     1] loss: 0.007283967919647694\n",
      "[963,     1] loss: 0.007158078718930483\n",
      "[964,     1] loss: 0.007014012895524502\n",
      "[965,     1] loss: 0.006869054399430752\n",
      "[966,     1] loss: 0.00676776934415102\n",
      "[967,     1] loss: 0.006732410751283169\n",
      "[968,     1] loss: 0.006747513078153133\n",
      "[969,     1] loss: 0.006793176755309105\n",
      "[970,     1] loss: 0.006844040472060442\n",
      "[971,     1] loss: 0.006887203082442284\n",
      "[972,     1] loss: 0.006898305378854275\n",
      "[973,     1] loss: 0.0069023543037474155\n",
      "[974,     1] loss: 0.006858757697045803\n",
      "[975,     1] loss: 0.006791667081415653\n",
      "[976,     1] loss: 0.0067102015018463135\n",
      "[977,     1] loss: 0.00664207898080349\n",
      "[978,     1] loss: 0.006604479625821114\n",
      "[979,     1] loss: 0.006598065607249737\n",
      "[980,     1] loss: 0.006610953249037266\n",
      "[981,     1] loss: 0.006627976894378662\n",
      "[982,     1] loss: 0.006639842409640551\n",
      "[983,     1] loss: 0.006642095744609833\n",
      "[984,     1] loss: 0.006645281799137592\n",
      "[985,     1] loss: 0.006634112913161516\n",
      "[986,     1] loss: 0.006612785160541534\n",
      "[987,     1] loss: 0.0065773301757872105\n",
      "[988,     1] loss: 0.006544533651322126\n",
      "[989,     1] loss: 0.00651173572987318\n",
      "[990,     1] loss: 0.0064825755544006824\n",
      "[991,     1] loss: 0.006461365148425102\n",
      "[992,     1] loss: 0.0064466241747140884\n",
      "[993,     1] loss: 0.0064356084913015366\n",
      "[994,     1] loss: 0.006430164445191622\n",
      "[995,     1] loss: 0.00642982916906476\n",
      "[996,     1] loss: 0.006433322560042143\n",
      "[997,     1] loss: 0.006449248641729355\n",
      "[998,     1] loss: 0.006469945888966322\n",
      "[999,     1] loss: 0.006507937330752611\n",
      "[1000,     1] loss: 0.006536912173032761\n",
      "[1001,     1] loss: 0.0065797679126262665\n",
      "[1002,     1] loss: 0.00658783596009016\n",
      "[1003,     1] loss: 0.00659151840955019\n",
      "[1004,     1] loss: 0.006552014499902725\n",
      "[1005,     1] loss: 0.0065061915665864944\n",
      "[1006,     1] loss: 0.006438229698687792\n",
      "[1007,     1] loss: 0.006369320675730705\n",
      "[1008,     1] loss: 0.006309708580374718\n",
      "[1009,     1] loss: 0.006270473822951317\n",
      "[1010,     1] loss: 0.006253953091800213\n",
      "[1011,     1] loss: 0.006259343586862087\n",
      "[1012,     1] loss: 0.006277700420469046\n",
      "[1013,     1] loss: 0.006301093380898237\n",
      "[1014,     1] loss: 0.006335167214274406\n",
      "[1015,     1] loss: 0.00635868264362216\n",
      "[1016,     1] loss: 0.00639526080340147\n",
      "[1017,     1] loss: 0.006412227172404528\n",
      "[1018,     1] loss: 0.006417922209948301\n",
      "[1019,     1] loss: 0.006387792062014341\n",
      "[1020,     1] loss: 0.0063551440834999084\n",
      "[1021,     1] loss: 0.0062882062047719955\n",
      "[1022,     1] loss: 0.006214849650859833\n",
      "[1023,     1] loss: 0.006157655734568834\n",
      "[1024,     1] loss: 0.0061239334754645824\n",
      "[1025,     1] loss: 0.006112734787166119\n",
      "[1026,     1] loss: 0.00611516460776329\n",
      "[1027,     1] loss: 0.0061241076327860355\n",
      "[1028,     1] loss: 0.006134472321718931\n",
      "[1029,     1] loss: 0.006152984220534563\n",
      "[1030,     1] loss: 0.006170187145471573\n",
      "[1031,     1] loss: 0.006197905633598566\n",
      "[1032,     1] loss: 0.006209251470863819\n",
      "[1033,     1] loss: 0.006224204786121845\n",
      "[1034,     1] loss: 0.006208444945514202\n",
      "[1035,     1] loss: 0.006181193515658379\n",
      "[1036,     1] loss: 0.006129458546638489\n",
      "[1037,     1] loss: 0.0060824062675237656\n",
      "[1038,     1] loss: 0.006031468044966459\n",
      "[1039,     1] loss: 0.0059906914830207825\n",
      "[1040,     1] loss: 0.005963495932519436\n",
      "[1041,     1] loss: 0.005947940982878208\n",
      "[1042,     1] loss: 0.0059445882216095924\n",
      "[1043,     1] loss: 0.005949917249381542\n",
      "[1044,     1] loss: 0.005963488481938839\n",
      "[1045,     1] loss: 0.005980928428471088\n",
      "[1046,     1] loss: 0.00600815936923027\n",
      "[1047,     1] loss: 0.006035094149410725\n",
      "[1048,     1] loss: 0.006076542194932699\n",
      "[1049,     1] loss: 0.006105729378759861\n",
      "[1050,     1] loss: 0.006157427094876766\n",
      "[1051,     1] loss: 0.006163421086966991\n",
      "[1052,     1] loss: 0.006157160736620426\n",
      "[1053,     1] loss: 0.0060976119711995125\n",
      "[1054,     1] loss: 0.006019320338964462\n",
      "[1055,     1] loss: 0.005930790677666664\n",
      "[1056,     1] loss: 0.0058612702414393425\n",
      "[1057,     1] loss: 0.005817286670207977\n",
      "[1058,     1] loss: 0.00580496434122324\n",
      "[1059,     1] loss: 0.00581740029156208\n",
      "[1060,     1] loss: 0.005842696409672499\n",
      "[1061,     1] loss: 0.005874686408787966\n",
      "[1062,     1] loss: 0.005900504998862743\n",
      "[1063,     1] loss: 0.0059276241809129715\n",
      "[1064,     1] loss: 0.005935785360634327\n",
      "[1065,     1] loss: 0.005934074986726046\n",
      "[1066,     1] loss: 0.005904604680836201\n",
      "[1067,     1] loss: 0.005871470086276531\n",
      "[1068,     1] loss: 0.005822120234370232\n",
      "[1069,     1] loss: 0.00577178131788969\n",
      "[1070,     1] loss: 0.00572547409683466\n",
      "[1071,     1] loss: 0.005689577665179968\n",
      "[1072,     1] loss: 0.005669791717082262\n",
      "[1073,     1] loss: 0.0056642936542630196\n",
      "[1074,     1] loss: 0.005668981000781059\n",
      "[1075,     1] loss: 0.005678205750882626\n",
      "[1076,     1] loss: 0.005693277809768915\n",
      "[1077,     1] loss: 0.005712538957595825\n",
      "[1078,     1] loss: 0.005742901936173439\n",
      "[1079,     1] loss: 0.005766945891082287\n",
      "[1080,     1] loss: 0.005794399883598089\n",
      "[1081,     1] loss: 0.005799996200948954\n",
      "[1082,     1] loss: 0.005797655321657658\n",
      "[1083,     1] loss: 0.0057654185220599174\n",
      "[1084,     1] loss: 0.005722053349018097\n",
      "[1085,     1] loss: 0.005664408206939697\n",
      "[1086,     1] loss: 0.005608833860605955\n",
      "[1087,     1] loss: 0.005567116197198629\n",
      "[1088,     1] loss: 0.005544607061892748\n",
      "[1089,     1] loss: 0.005539368372410536\n",
      "[1090,     1] loss: 0.005546269007027149\n",
      "[1091,     1] loss: 0.005558942910283804\n",
      "[1092,     1] loss: 0.005573354195803404\n",
      "[1093,     1] loss: 0.005597393959760666\n",
      "[1094,     1] loss: 0.005619099363684654\n",
      "[1095,     1] loss: 0.005651955027133226\n",
      "[1096,     1] loss: 0.005671964958310127\n",
      "[1097,     1] loss: 0.005704589653760195\n",
      "[1098,     1] loss: 0.005709685385227203\n",
      "[1099,     1] loss: 0.005707781761884689\n",
      "[1100,     1] loss: 0.0056747072376310825\n",
      "[1101,     1] loss: 0.005613449029624462\n",
      "[1102,     1] loss: 0.005539101082831621\n",
      "[1103,     1] loss: 0.005473652854561806\n",
      "[1104,     1] loss: 0.005426598247140646\n",
      "[1105,     1] loss: 0.0053995149210095406\n",
      "[1106,     1] loss: 0.00539250485599041\n",
      "[1107,     1] loss: 0.005400632042437792\n",
      "[1108,     1] loss: 0.005420527420938015\n",
      "[1109,     1] loss: 0.005447004456073046\n",
      "[1110,     1] loss: 0.005478416569530964\n",
      "[1111,     1] loss: 0.005505681969225407\n",
      "[1112,     1] loss: 0.005537285003811121\n",
      "[1113,     1] loss: 0.005557267926633358\n",
      "[1114,     1] loss: 0.005582740064710379\n",
      "[1115,     1] loss: 0.0055786482989788055\n",
      "[1116,     1] loss: 0.005563011392951012\n",
      "[1117,     1] loss: 0.005512533709406853\n",
      "[1118,     1] loss: 0.005444732960313559\n",
      "[1119,     1] loss: 0.005370431113988161\n",
      "[1120,     1] loss: 0.00531349703669548\n",
      "[1121,     1] loss: 0.005279905162751675\n",
      "[1122,     1] loss: 0.0052686114795506\n",
      "[1123,     1] loss: 0.005274924915283918\n",
      "[1124,     1] loss: 0.005295248236507177\n",
      "[1125,     1] loss: 0.005325340665876865\n",
      "[1126,     1] loss: 0.005359483417123556\n",
      "[1127,     1] loss: 0.005405292846262455\n",
      "[1128,     1] loss: 0.0054367054253816605\n",
      "[1129,     1] loss: 0.0054756589233875275\n",
      "[1130,     1] loss: 0.005483172368258238\n",
      "[1131,     1] loss: 0.00547998771071434\n",
      "[1132,     1] loss: 0.005437059327960014\n",
      "[1133,     1] loss: 0.005375172011554241\n",
      "[1134,     1] loss: 0.0053059011697769165\n",
      "[1135,     1] loss: 0.005242712330073118\n",
      "[1136,     1] loss: 0.0051979306153953075\n",
      "[1137,     1] loss: 0.005174477118998766\n",
      "[1138,     1] loss: 0.005171205382794142\n",
      "[1139,     1] loss: 0.005181105341762304\n",
      "[1140,     1] loss: 0.0052019767463207245\n",
      "[1141,     1] loss: 0.005225431174039841\n",
      "[1142,     1] loss: 0.005254938267171383\n",
      "[1143,     1] loss: 0.005277686752378941\n",
      "[1144,     1] loss: 0.005309079773724079\n",
      "[1145,     1] loss: 0.0053193094208836555\n",
      "[1146,     1] loss: 0.00532597117125988\n",
      "[1147,     1] loss: 0.0053084599785506725\n",
      "[1148,     1] loss: 0.005275816656649113\n",
      "[1149,     1] loss: 0.005230358801782131\n",
      "[1150,     1] loss: 0.005181989632546902\n",
      "[1151,     1] loss: 0.005132385995239019\n",
      "[1152,     1] loss: 0.005087344907224178\n",
      "[1153,     1] loss: 0.0050557698123157024\n",
      "[1154,     1] loss: 0.005039923824369907\n",
      "[1155,     1] loss: 0.005037372000515461\n",
      "[1156,     1] loss: 0.005045498721301556\n",
      "[1157,     1] loss: 0.0050607346929609776\n",
      "[1158,     1] loss: 0.005080041475594044\n",
      "[1159,     1] loss: 0.005106212571263313\n",
      "[1160,     1] loss: 0.005130329169332981\n",
      "[1161,     1] loss: 0.005163693334907293\n",
      "[1162,     1] loss: 0.005184330511838198\n",
      "[1163,     1] loss: 0.005203813314437866\n",
      "[1164,     1] loss: 0.0052013699896633625\n",
      "[1165,     1] loss: 0.005195836536586285\n",
      "[1166,     1] loss: 0.005164932459592819\n",
      "[1167,     1] loss: 0.005128479562699795\n",
      "[1168,     1] loss: 0.005076216068118811\n",
      "[1169,     1] loss: 0.0050226361490786076\n",
      "[1170,     1] loss: 0.004976757802069187\n",
      "[1171,     1] loss: 0.004942669067531824\n",
      "[1172,     1] loss: 0.0049239411018788815\n",
      "[1173,     1] loss: 0.004919311497360468\n",
      "[1174,     1] loss: 0.004925394430756569\n",
      "[1175,     1] loss: 0.004937912803143263\n",
      "[1176,     1] loss: 0.004962649196386337\n",
      "[1177,     1] loss: 0.0049907136708498\n",
      "[1178,     1] loss: 0.005033913999795914\n",
      "[1179,     1] loss: 0.005070121493190527\n",
      "[1180,     1] loss: 0.0051210541278123856\n",
      "[1181,     1] loss: 0.005144533701241016\n",
      "[1182,     1] loss: 0.005164821166545153\n",
      "[1183,     1] loss: 0.0051466249860823154\n",
      "[1184,     1] loss: 0.0051118358969688416\n",
      "[1185,     1] loss: 0.0050523122772574425\n",
      "[1186,     1] loss: 0.004982281941920519\n",
      "[1187,     1] loss: 0.004914924502372742\n",
      "[1188,     1] loss: 0.004866329021751881\n",
      "[1189,     1] loss: 0.004834366962313652\n",
      "[1190,     1] loss: 0.004820098169147968\n",
      "[1191,     1] loss: 0.004821592941880226\n",
      "[1192,     1] loss: 0.00483362702652812\n",
      "[1193,     1] loss: 0.004856709856539965\n",
      "[1194,     1] loss: 0.004877201281487942\n",
      "[1195,     1] loss: 0.004908228293061256\n",
      "[1196,     1] loss: 0.004926839843392372\n",
      "[1197,     1] loss: 0.004948184825479984\n",
      "[1198,     1] loss: 0.004947193898260593\n",
      "[1199,     1] loss: 0.004939314443618059\n",
      "[1200,     1] loss: 0.004910591058433056\n",
      "[1201,     1] loss: 0.004874143283814192\n",
      "[1202,     1] loss: 0.004834374412894249\n",
      "[1203,     1] loss: 0.004797200206667185\n",
      "[1204,     1] loss: 0.004763662349432707\n",
      "[1205,     1] loss: 0.004739262163639069\n",
      "[1206,     1] loss: 0.00472452724352479\n",
      "[1207,     1] loss: 0.0047183167189359665\n",
      "[1208,     1] loss: 0.004720301833003759\n",
      "[1209,     1] loss: 0.004724985919892788\n",
      "[1210,     1] loss: 0.00473276199772954\n",
      "[1211,     1] loss: 0.004741261247545481\n",
      "[1212,     1] loss: 0.004759368486702442\n",
      "[1213,     1] loss: 0.004774320404976606\n",
      "[1214,     1] loss: 0.004798142705112696\n",
      "[1215,     1] loss: 0.004813383333384991\n",
      "[1216,     1] loss: 0.004836981650441885\n",
      "[1217,     1] loss: 0.004846307914704084\n",
      "[1218,     1] loss: 0.004862557630985975\n",
      "[1219,     1] loss: 0.004861679393798113\n",
      "[1220,     1] loss: 0.004860541317611933\n",
      "[1221,     1] loss: 0.004842759575694799\n",
      "[1222,     1] loss: 0.004815858788788319\n",
      "[1223,     1] loss: 0.004778985865414143\n",
      "[1224,     1] loss: 0.004742729477584362\n",
      "[1225,     1] loss: 0.004707750864326954\n",
      "[1226,     1] loss: 0.004677395336329937\n",
      "[1227,     1] loss: 0.004650464281439781\n",
      "[1228,     1] loss: 0.004628232214599848\n",
      "[1229,     1] loss: 0.004613376688212156\n",
      "[1230,     1] loss: 0.004604707937687635\n",
      "[1231,     1] loss: 0.004607768729329109\n",
      "[1232,     1] loss: 0.0046189213171601295\n",
      "[1233,     1] loss: 0.0046426113694906235\n",
      "[1234,     1] loss: 0.004668013658374548\n",
      "[1235,     1] loss: 0.00470533175393939\n",
      "[1236,     1] loss: 0.004734458401799202\n",
      "[1237,     1] loss: 0.004785455763339996\n",
      "[1238,     1] loss: 0.004817483015358448\n",
      "[1239,     1] loss: 0.004848322831094265\n",
      "[1240,     1] loss: 0.004850251600146294\n",
      "[1241,     1] loss: 0.0048498911783099174\n",
      "[1242,     1] loss: 0.004815674852579832\n",
      "[1243,     1] loss: 0.004765826277434826\n",
      "[1244,     1] loss: 0.004695068579167128\n",
      "[1245,     1] loss: 0.004625238478183746\n",
      "[1246,     1] loss: 0.004560957197099924\n",
      "[1247,     1] loss: 0.004511683713644743\n",
      "[1248,     1] loss: 0.004483608528971672\n",
      "[1249,     1] loss: 0.004476172383874655\n",
      "[1250,     1] loss: 0.004485722165554762\n",
      "[1251,     1] loss: 0.004505558870732784\n",
      "[1252,     1] loss: 0.004536963999271393\n",
      "[1253,     1] loss: 0.004567307885736227\n",
      "[1254,     1] loss: 0.004604996182024479\n",
      "[1255,     1] loss: 0.004630166571587324\n",
      "[1256,     1] loss: 0.004660175181925297\n",
      "[1257,     1] loss: 0.004666486289352179\n",
      "[1258,     1] loss: 0.0046780845150351524\n",
      "[1259,     1] loss: 0.0046559954062104225\n",
      "[1260,     1] loss: 0.0046287281438708305\n",
      "[1261,     1] loss: 0.004575537052005529\n",
      "[1262,     1] loss: 0.004519491456449032\n",
      "[1263,     1] loss: 0.004462318494915962\n",
      "[1264,     1] loss: 0.004417163785547018\n",
      "[1265,     1] loss: 0.004388101864606142\n",
      "[1266,     1] loss: 0.004375940188765526\n",
      "[1267,     1] loss: 0.0043776435777544975\n",
      "[1268,     1] loss: 0.004386552609503269\n",
      "[1269,     1] loss: 0.004401222337037325\n",
      "[1270,     1] loss: 0.004416158422827721\n",
      "[1271,     1] loss: 0.004437149036675692\n",
      "[1272,     1] loss: 0.0044541447423398495\n",
      "[1273,     1] loss: 0.004480605013668537\n",
      "[1274,     1] loss: 0.004495049361139536\n",
      "[1275,     1] loss: 0.004518780391663313\n",
      "[1276,     1] loss: 0.004527655895799398\n",
      "[1277,     1] loss: 0.004546253476291895\n",
      "[1278,     1] loss: 0.004545933101326227\n",
      "[1279,     1] loss: 0.004547957796603441\n",
      "[1280,     1] loss: 0.004529655911028385\n",
      "[1281,     1] loss: 0.004509541671723127\n",
      "[1282,     1] loss: 0.004472062923014164\n",
      "[1283,     1] loss: 0.004433996509760618\n",
      "[1284,     1] loss: 0.0043917689472436905\n",
      "[1285,     1] loss: 0.004355044569820166\n",
      "[1286,     1] loss: 0.004319590516388416\n",
      "[1287,     1] loss: 0.004293530248105526\n",
      "[1288,     1] loss: 0.004278026521205902\n",
      "[1289,     1] loss: 0.004270062781870365\n",
      "[1290,     1] loss: 0.004269381985068321\n",
      "[1291,     1] loss: 0.004274699836969376\n",
      "[1292,     1] loss: 0.004288014955818653\n",
      "[1293,     1] loss: 0.004306001588702202\n",
      "[1294,     1] loss: 0.0043365550227463245\n",
      "[1295,     1] loss: 0.004368927329778671\n",
      "[1296,     1] loss: 0.004420447628945112\n",
      "[1297,     1] loss: 0.004469023551791906\n",
      "[1298,     1] loss: 0.004538158420473337\n",
      "[1299,     1] loss: 0.00459128525108099\n",
      "[1300,     1] loss: 0.004654893185943365\n",
      "[1301,     1] loss: 0.004675527103245258\n",
      "[1302,     1] loss: 0.004707308020442724\n",
      "[1303,     1] loss: 0.004679388832300901\n",
      "[1304,     1] loss: 0.004638355690985918\n",
      "[1305,     1] loss: 0.004566415678709745\n",
      "[1306,     1] loss: 0.004505875986069441\n",
      "[1307,     1] loss: 0.004458708688616753\n",
      "[1308,     1] loss: 0.004442150238901377\n",
      "[1309,     1] loss: 0.004437807947397232\n",
      "[1310,     1] loss: 0.004431309178471565\n",
      "[1311,     1] loss: 0.004397454671561718\n",
      "[1312,     1] loss: 0.004334139171987772\n",
      "[1313,     1] loss: 0.004272333811968565\n",
      "[1314,     1] loss: 0.004222781863063574\n",
      "[1315,     1] loss: 0.004210720770061016\n",
      "[1316,     1] loss: 0.004232810810208321\n",
      "[1317,     1] loss: 0.004274627193808556\n",
      "[1318,     1] loss: 0.004305812530219555\n",
      "[1319,     1] loss: 0.004308293107897043\n",
      "[1320,     1] loss: 0.0042752595618367195\n",
      "[1321,     1] loss: 0.004218191374093294\n",
      "[1322,     1] loss: 0.004156460054218769\n",
      "[1323,     1] loss: 0.004114295355975628\n",
      "[1324,     1] loss: 0.004097450524568558\n",
      "[1325,     1] loss: 0.0041022757068276405\n",
      "[1326,     1] loss: 0.004117861855775118\n",
      "[1327,     1] loss: 0.0041353823617100716\n",
      "[1328,     1] loss: 0.0041413758881390095\n",
      "[1329,     1] loss: 0.004132622852921486\n",
      "[1330,     1] loss: 0.004114122129976749\n",
      "[1331,     1] loss: 0.004095645155757666\n",
      "[1332,     1] loss: 0.004085456486791372\n",
      "[1333,     1] loss: 0.0040886616334319115\n",
      "[1334,     1] loss: 0.004107251297682524\n",
      "[1335,     1] loss: 0.004130896180868149\n",
      "[1336,     1] loss: 0.0041687581688165665\n",
      "[1337,     1] loss: 0.004201818723231554\n",
      "[1338,     1] loss: 0.004244619514793158\n",
      "[1339,     1] loss: 0.004267184063792229\n",
      "[1340,     1] loss: 0.004292650148272514\n",
      "[1341,     1] loss: 0.004300153348594904\n",
      "[1342,     1] loss: 0.004310921765863895\n",
      "[1343,     1] loss: 0.004309369251132011\n",
      "[1344,     1] loss: 0.004319964442402124\n",
      "[1345,     1] loss: 0.004313905257731676\n",
      "[1346,     1] loss: 0.004302223213016987\n",
      "[1347,     1] loss: 0.0042626685462892056\n",
      "[1348,     1] loss: 0.004204966593533754\n",
      "[1349,     1] loss: 0.00413530832156539\n",
      "[1350,     1] loss: 0.0040705506689846516\n",
      "[1351,     1] loss: 0.004019935615360737\n",
      "[1352,     1] loss: 0.00399007136002183\n",
      "[1353,     1] loss: 0.0039794486947357655\n",
      "[1354,     1] loss: 0.00398137466982007\n",
      "[1355,     1] loss: 0.003984861541539431\n",
      "[1356,     1] loss: 0.003984673414379358\n",
      "[1357,     1] loss: 0.003980271052569151\n",
      "[1358,     1] loss: 0.003974989056587219\n",
      "[1359,     1] loss: 0.00397529685869813\n",
      "[1360,     1] loss: 0.003981581423431635\n",
      "[1361,     1] loss: 0.003999626729637384\n",
      "[1362,     1] loss: 0.004021797329187393\n",
      "[1363,     1] loss: 0.004056646954268217\n",
      "[1364,     1] loss: 0.004088886547833681\n",
      "[1365,     1] loss: 0.004129870794713497\n",
      "[1366,     1] loss: 0.004156801849603653\n",
      "[1367,     1] loss: 0.004193098284304142\n",
      "[1368,     1] loss: 0.004214119166135788\n",
      "[1369,     1] loss: 0.004252264741808176\n",
      "[1370,     1] loss: 0.004271046724170446\n",
      "[1371,     1] loss: 0.0042879618704319\n",
      "[1372,     1] loss: 0.004276731051504612\n",
      "[1373,     1] loss: 0.004252034239470959\n",
      "[1374,     1] loss: 0.004196000751107931\n",
      "[1375,     1] loss: 0.004122982732951641\n",
      "[1376,     1] loss: 0.00403396924957633\n",
      "[1377,     1] loss: 0.003954378888010979\n",
      "[1378,     1] loss: 0.0038949474692344666\n",
      "[1379,     1] loss: 0.003862312063574791\n",
      "[1380,     1] loss: 0.0038527552969753742\n",
      "[1381,     1] loss: 0.0038594198413193226\n",
      "[1382,     1] loss: 0.003876286558806896\n",
      "[1383,     1] loss: 0.003892539767548442\n",
      "[1384,     1] loss: 0.003907263744622469\n",
      "[1385,     1] loss: 0.003920166753232479\n",
      "[1386,     1] loss: 0.003936027642339468\n",
      "[1387,     1] loss: 0.003952259663492441\n",
      "[1388,     1] loss: 0.003973649814724922\n",
      "[1389,     1] loss: 0.003991422243416309\n",
      "[1390,     1] loss: 0.00402692798525095\n",
      "[1391,     1] loss: 0.004047204274684191\n",
      "[1392,     1] loss: 0.004073776304721832\n",
      "[1393,     1] loss: 0.004070918075740337\n",
      "[1394,     1] loss: 0.004067272413522005\n",
      "[1395,     1] loss: 0.0040357173420488834\n",
      "[1396,     1] loss: 0.0040025291964411736\n",
      "[1397,     1] loss: 0.003959162626415491\n",
      "[1398,     1] loss: 0.003919478040188551\n",
      "[1399,     1] loss: 0.003883524565026164\n",
      "[1400,     1] loss: 0.00385298952460289\n",
      "[1401,     1] loss: 0.0038278126157820225\n",
      "[1402,     1] loss: 0.003805409651249647\n",
      "[1403,     1] loss: 0.0037874002009630203\n",
      "[1404,     1] loss: 0.00377291115000844\n",
      "[1405,     1] loss: 0.003765272442251444\n",
      "[1406,     1] loss: 0.0037643825635313988\n",
      "[1407,     1] loss: 0.0037720855325460434\n",
      "[1408,     1] loss: 0.003784744068980217\n",
      "[1409,     1] loss: 0.0038042538799345493\n",
      "[1410,     1] loss: 0.0038253695238381624\n",
      "[1411,     1] loss: 0.003852922236546874\n",
      "[1412,     1] loss: 0.003881893353536725\n",
      "[1413,     1] loss: 0.003921902738511562\n",
      "[1414,     1] loss: 0.0039619156159460545\n",
      "[1415,     1] loss: 0.004025014117360115\n",
      "[1416,     1] loss: 0.004082667641341686\n",
      "[1417,     1] loss: 0.004164533223956823\n",
      "[1418,     1] loss: 0.004218047950416803\n",
      "[1419,     1] loss: 0.004272280726581812\n",
      "[1420,     1] loss: 0.004267707467079163\n",
      "[1421,     1] loss: 0.00424141064286232\n",
      "[1422,     1] loss: 0.0041520725935697556\n",
      "[1423,     1] loss: 0.004030487034469843\n",
      "[1424,     1] loss: 0.00389364012517035\n",
      "[1425,     1] loss: 0.0037821601144969463\n",
      "[1426,     1] loss: 0.003709925804287195\n",
      "[1427,     1] loss: 0.0036802319809794426\n",
      "[1428,     1] loss: 0.003689228091388941\n",
      "[1429,     1] loss: 0.003722571302205324\n",
      "[1430,     1] loss: 0.0037694801576435566\n",
      "[1431,     1] loss: 0.003812500275671482\n",
      "[1432,     1] loss: 0.0038495073094964027\n",
      "[1433,     1] loss: 0.003866205457597971\n",
      "[1434,     1] loss: 0.0038731021340936422\n",
      "[1435,     1] loss: 0.0038605385925620794\n",
      "[1436,     1] loss: 0.0038391766138374805\n",
      "[1437,     1] loss: 0.0038074844051152468\n",
      "[1438,     1] loss: 0.0037690442986786366\n",
      "[1439,     1] loss: 0.003728693351149559\n",
      "[1440,     1] loss: 0.003689715638756752\n",
      "[1441,     1] loss: 0.0036564215552061796\n",
      "[1442,     1] loss: 0.0036319331265985966\n",
      "[1443,     1] loss: 0.0036177858710289\n",
      "[1444,     1] loss: 0.0036147763021290302\n",
      "[1445,     1] loss: 0.003619758877903223\n",
      "[1446,     1] loss: 0.0036296886391937733\n",
      "[1447,     1] loss: 0.0036445027217268944\n",
      "[1448,     1] loss: 0.0036604609340429306\n",
      "[1449,     1] loss: 0.00367941171862185\n",
      "[1450,     1] loss: 0.0036969268694519997\n",
      "[1451,     1] loss: 0.0037131132557988167\n",
      "[1452,     1] loss: 0.0037192769814282656\n",
      "[1453,     1] loss: 0.0037184692919254303\n",
      "[1454,     1] loss: 0.003712317906320095\n",
      "[1455,     1] loss: 0.0037068079691380262\n",
      "[1456,     1] loss: 0.0036949883215129375\n",
      "[1457,     1] loss: 0.0036799758672714233\n",
      "[1458,     1] loss: 0.003659606445580721\n",
      "[1459,     1] loss: 0.003641038201749325\n",
      "[1460,     1] loss: 0.0036229626275599003\n",
      "[1461,     1] loss: 0.0036060549318790436\n",
      "[1462,     1] loss: 0.0035883993841707706\n",
      "[1463,     1] loss: 0.003572216723114252\n",
      "[1464,     1] loss: 0.00355835841037333\n",
      "[1465,     1] loss: 0.0035469713620841503\n",
      "[1466,     1] loss: 0.0035366262309253216\n",
      "[1467,     1] loss: 0.0035298806615173817\n",
      "[1468,     1] loss: 0.0035245970357209444\n",
      "[1469,     1] loss: 0.0035207332111895084\n",
      "[1470,     1] loss: 0.003517087083309889\n",
      "[1471,     1] loss: 0.003515030490234494\n",
      "[1472,     1] loss: 0.003513297298923135\n",
      "[1473,     1] loss: 0.0035115228965878487\n",
      "[1474,     1] loss: 0.0035101878456771374\n",
      "[1475,     1] loss: 0.0035092646721750498\n",
      "[1476,     1] loss: 0.0035075866617262363\n",
      "[1477,     1] loss: 0.0035069824662059546\n",
      "[1478,     1] loss: 0.003506379434838891\n",
      "[1479,     1] loss: 0.003506417851895094\n",
      "[1480,     1] loss: 0.003507931251078844\n",
      "[1481,     1] loss: 0.0035101929679512978\n",
      "[1482,     1] loss: 0.003513670526444912\n",
      "[1483,     1] loss: 0.003519479651004076\n",
      "[1484,     1] loss: 0.0035279688891023397\n",
      "[1485,     1] loss: 0.003540254198014736\n",
      "[1486,     1] loss: 0.003560673911124468\n",
      "[1487,     1] loss: 0.0035934748593717813\n",
      "[1488,     1] loss: 0.0036539731081575155\n",
      "[1489,     1] loss: 0.003741353750228882\n",
      "[1490,     1] loss: 0.0038961840327829123\n",
      "[1491,     1] loss: 0.004096745979040861\n",
      "[1492,     1] loss: 0.004429533611983061\n",
      "[1493,     1] loss: 0.00476102577522397\n",
      "[1494,     1] loss: 0.005199732258915901\n",
      "[1495,     1] loss: 0.0054073152132332325\n",
      "[1496,     1] loss: 0.005558277014642954\n",
      "[1497,     1] loss: 0.005123134236782789\n",
      "[1498,     1] loss: 0.004513218533247709\n",
      "[1499,     1] loss: 0.0038600743282586336\n",
      "[1500,     1] loss: 0.003525183070451021\n",
      "[1501,     1] loss: 0.003571444423869252\n",
      "[1502,     1] loss: 0.0038373551797121763\n",
      "[1503,     1] loss: 0.00410290015861392\n",
      "[1504,     1] loss: 0.004139193799346685\n",
      "[1505,     1] loss: 0.003992700949311256\n",
      "[1506,     1] loss: 0.00373813952319324\n",
      "[1507,     1] loss: 0.003572255838662386\n",
      "[1508,     1] loss: 0.003552955575287342\n",
      "[1509,     1] loss: 0.003628330072388053\n",
      "[1510,     1] loss: 0.0036981217563152313\n",
      "[1511,     1] loss: 0.0036761087831109762\n",
      "[1512,     1] loss: 0.003596985712647438\n",
      "[1513,     1] loss: 0.0034985393285751343\n",
      "[1514,     1] loss: 0.0034563555382192135\n",
      "[1515,     1] loss: 0.0034795317333191633\n",
      "[1516,     1] loss: 0.003525683656334877\n",
      "[1517,     1] loss: 0.003545553656294942\n",
      "[1518,     1] loss: 0.003509348491206765\n",
      "[1519,     1] loss: 0.003444755682721734\n",
      "[1520,     1] loss: 0.003386156866326928\n",
      "[1521,     1] loss: 0.0033662416972219944\n",
      "[1522,     1] loss: 0.0033871943596750498\n",
      "[1523,     1] loss: 0.0034230200108140707\n",
      "[1524,     1] loss: 0.0034426944330334663\n",
      "[1525,     1] loss: 0.0034287767484784126\n",
      "[1526,     1] loss: 0.003390273544937372\n",
      "[1527,     1] loss: 0.003347584046423435\n",
      "[1528,     1] loss: 0.00332173565402627\n",
      "[1529,     1] loss: 0.003320795251056552\n",
      "[1530,     1] loss: 0.0033378798980265856\n",
      "[1531,     1] loss: 0.003356354543939233\n",
      "[1532,     1] loss: 0.0033627809025347233\n",
      "[1533,     1] loss: 0.0033541324082762003\n",
      "[1534,     1] loss: 0.003333430737257004\n",
      "[1535,     1] loss: 0.0033120056614279747\n",
      "[1536,     1] loss: 0.0032963878475129604\n",
      "[1537,     1] loss: 0.003291590139269829\n",
      "[1538,     1] loss: 0.003296204376965761\n",
      "[1539,     1] loss: 0.0033033969812095165\n",
      "[1540,     1] loss: 0.0033077870029956102\n",
      "[1541,     1] loss: 0.0033057734835892916\n",
      "[1542,     1] loss: 0.0032978453673422337\n",
      "[1543,     1] loss: 0.0032870995346456766\n",
      "[1544,     1] loss: 0.0032759576570242643\n",
      "[1545,     1] loss: 0.0032684176694601774\n",
      "[1546,     1] loss: 0.003263638587668538\n",
      "[1547,     1] loss: 0.0032622599974274635\n",
      "[1548,     1] loss: 0.0032636108808219433\n",
      "[1549,     1] loss: 0.0032650907523930073\n",
      "[1550,     1] loss: 0.0032665005419403315\n",
      "[1551,     1] loss: 0.0032665152102708817\n",
      "[1552,     1] loss: 0.0032644777093082666\n",
      "[1553,     1] loss: 0.003261434379965067\n",
      "[1554,     1] loss: 0.0032572681084275246\n",
      "[1555,     1] loss: 0.0032523730769753456\n",
      "[1556,     1] loss: 0.0032478757202625275\n",
      "[1557,     1] loss: 0.0032456235494464636\n",
      "[1558,     1] loss: 0.0032436863984912634\n",
      "[1559,     1] loss: 0.0032444328535348177\n",
      "[1560,     1] loss: 0.0032446354161947966\n",
      "[1561,     1] loss: 0.003246132517233491\n",
      "[1562,     1] loss: 0.003246946493163705\n",
      "[1563,     1] loss: 0.0032472279854118824\n",
      "[1564,     1] loss: 0.0032473106402903795\n",
      "[1565,     1] loss: 0.0032479362562298775\n",
      "[1566,     1] loss: 0.003249863628298044\n",
      "[1567,     1] loss: 0.0032547786831855774\n",
      "[1568,     1] loss: 0.003260484430938959\n",
      "[1569,     1] loss: 0.0032725450582802296\n",
      "[1570,     1] loss: 0.0032853023149073124\n",
      "[1571,     1] loss: 0.0032988826278597116\n",
      "[1572,     1] loss: 0.0033127055503427982\n",
      "[1573,     1] loss: 0.003328695660457015\n",
      "[1574,     1] loss: 0.0033396845683455467\n",
      "[1575,     1] loss: 0.0033502383157610893\n",
      "[1576,     1] loss: 0.003360939212143421\n",
      "[1577,     1] loss: 0.003377047600224614\n",
      "[1578,     1] loss: 0.0033880556002259254\n",
      "[1579,     1] loss: 0.003402040107175708\n",
      "[1580,     1] loss: 0.003407566575333476\n",
      "[1581,     1] loss: 0.0034187387209385633\n",
      "[1582,     1] loss: 0.003419384825974703\n",
      "[1583,     1] loss: 0.0034119898919016123\n",
      "[1584,     1] loss: 0.003398450557142496\n",
      "[1585,     1] loss: 0.0033799591474235058\n",
      "[1586,     1] loss: 0.0033493153750896454\n",
      "[1587,     1] loss: 0.0033166133798658848\n",
      "[1588,     1] loss: 0.0032812166027724743\n",
      "[1589,     1] loss: 0.0032506063580513\n",
      "[1590,     1] loss: 0.0032269619405269623\n",
      "[1591,     1] loss: 0.003210570430383086\n",
      "[1592,     1] loss: 0.0031945151276886463\n",
      "[1593,     1] loss: 0.0031824056059122086\n",
      "[1594,     1] loss: 0.0031693759374320507\n",
      "[1595,     1] loss: 0.003156703896820545\n",
      "[1596,     1] loss: 0.003141241380944848\n",
      "[1597,     1] loss: 0.0031304731965065002\n",
      "[1598,     1] loss: 0.003121420741081238\n",
      "[1599,     1] loss: 0.0031136085744947195\n",
      "[1600,     1] loss: 0.0031075726728886366\n",
      "[1601,     1] loss: 0.0031064925715327263\n",
      "[1602,     1] loss: 0.0031075703445822\n",
      "[1603,     1] loss: 0.0031102742068469524\n",
      "[1604,     1] loss: 0.0031188162975013256\n",
      "[1605,     1] loss: 0.0031317397952079773\n",
      "[1606,     1] loss: 0.0031510605476796627\n",
      "[1607,     1] loss: 0.0031770027708262205\n",
      "[1608,     1] loss: 0.003209856804460287\n",
      "[1609,     1] loss: 0.0032514538615942\n",
      "[1610,     1] loss: 0.003322349628433585\n",
      "[1611,     1] loss: 0.0034095733426511288\n",
      "[1612,     1] loss: 0.003544790670275688\n",
      "[1613,     1] loss: 0.0036872231867164373\n",
      "[1614,     1] loss: 0.003905215999111533\n",
      "[1615,     1] loss: 0.0040878900326788425\n",
      "[1616,     1] loss: 0.004282936453819275\n",
      "[1617,     1] loss: 0.004358717240393162\n",
      "[1618,     1] loss: 0.0044102915562689304\n",
      "[1619,     1] loss: 0.004269639030098915\n",
      "[1620,     1] loss: 0.004026542417705059\n",
      "[1621,     1] loss: 0.0036778554785996675\n",
      "[1622,     1] loss: 0.0033480299171060324\n",
      "[1623,     1] loss: 0.003127684351056814\n",
      "[1624,     1] loss: 0.0030736152548342943\n",
      "[1625,     1] loss: 0.0031646976713091135\n",
      "[1626,     1] loss: 0.003324564779177308\n",
      "[1627,     1] loss: 0.0034819357097148895\n",
      "[1628,     1] loss: 0.003556683426722884\n",
      "[1629,     1] loss: 0.0035355736035853624\n",
      "[1630,     1] loss: 0.003403794253244996\n",
      "[1631,     1] loss: 0.0032414053566753864\n",
      "[1632,     1] loss: 0.0031002843752503395\n",
      "[1633,     1] loss: 0.0030324840918183327\n",
      "[1634,     1] loss: 0.0030396387446671724\n",
      "[1635,     1] loss: 0.003093740902841091\n",
      "[1636,     1] loss: 0.003156717400997877\n",
      "[1637,     1] loss: 0.0031958138570189476\n",
      "[1638,     1] loss: 0.0032060155645012856\n",
      "[1639,     1] loss: 0.0031855469569563866\n",
      "[1640,     1] loss: 0.003154223784804344\n",
      "[1641,     1] loss: 0.0031193308532238007\n",
      "[1642,     1] loss: 0.003096275730058551\n",
      "[1643,     1] loss: 0.0030732990708202124\n",
      "[1644,     1] loss: 0.003053767839446664\n",
      "[1645,     1] loss: 0.0030342931859195232\n",
      "[1646,     1] loss: 0.0030167249497026205\n",
      "[1647,     1] loss: 0.003006014507263899\n",
      "[1648,     1] loss: 0.0030025101732462645\n",
      "[1649,     1] loss: 0.0030062044970691204\n",
      "[1650,     1] loss: 0.003017802955582738\n",
      "[1651,     1] loss: 0.0030291718430817127\n",
      "[1652,     1] loss: 0.0030340622179210186\n",
      "[1653,     1] loss: 0.00303189386613667\n",
      "[1654,     1] loss: 0.003022785298526287\n",
      "[1655,     1] loss: 0.0030081316363066435\n",
      "[1656,     1] loss: 0.002988776657730341\n",
      "[1657,     1] loss: 0.0029732941184192896\n",
      "[1658,     1] loss: 0.0029609210323542356\n",
      "[1659,     1] loss: 0.002952808514237404\n",
      "[1660,     1] loss: 0.002949504181742668\n",
      "[1661,     1] loss: 0.002948272740468383\n",
      "[1662,     1] loss: 0.002948107896372676\n",
      "[1663,     1] loss: 0.0029486187268048525\n",
      "[1664,     1] loss: 0.0029481553938239813\n",
      "[1665,     1] loss: 0.0029477206990122795\n",
      "[1666,     1] loss: 0.0029470608569681644\n",
      "[1667,     1] loss: 0.00294674513861537\n",
      "[1668,     1] loss: 0.002949252026155591\n",
      "[1669,     1] loss: 0.0029526662547141314\n",
      "[1670,     1] loss: 0.002960242796689272\n",
      "[1671,     1] loss: 0.0029691585805267096\n",
      "[1672,     1] loss: 0.002981574507430196\n",
      "[1673,     1] loss: 0.0029953967314213514\n",
      "[1674,     1] loss: 0.0030119875445961952\n",
      "[1675,     1] loss: 0.0030291646253317595\n",
      "[1676,     1] loss: 0.0030484162271022797\n",
      "[1677,     1] loss: 0.0030646820086985826\n",
      "[1678,     1] loss: 0.0030885664746165276\n",
      "[1679,     1] loss: 0.003104011993855238\n",
      "[1680,     1] loss: 0.003133453894406557\n",
      "[1681,     1] loss: 0.0031521033961325884\n",
      "[1682,     1] loss: 0.003185305744409561\n",
      "[1683,     1] loss: 0.0031992923468351364\n",
      "[1684,     1] loss: 0.0032112961634993553\n",
      "[1685,     1] loss: 0.003196691395714879\n",
      "[1686,     1] loss: 0.0031737727113068104\n",
      "[1687,     1] loss: 0.003126216819509864\n",
      "[1688,     1] loss: 0.0030726781114935875\n",
      "[1689,     1] loss: 0.0030115090776234865\n",
      "[1690,     1] loss: 0.0029592812061309814\n",
      "[1691,     1] loss: 0.002918533980846405\n",
      "[1692,     1] loss: 0.002892840886488557\n",
      "[1693,     1] loss: 0.002880392363294959\n",
      "[1694,     1] loss: 0.002877735299989581\n",
      "[1695,     1] loss: 0.002880046609789133\n",
      "[1696,     1] loss: 0.0028863539919257164\n",
      "[1697,     1] loss: 0.00289333239197731\n",
      "[1698,     1] loss: 0.0029000379145145416\n",
      "[1699,     1] loss: 0.002908102935180068\n",
      "[1700,     1] loss: 0.0029139965772628784\n",
      "[1701,     1] loss: 0.0029242553282529116\n",
      "[1702,     1] loss: 0.0029331259429454803\n",
      "[1703,     1] loss: 0.0029480208177119493\n",
      "[1704,     1] loss: 0.0029642970766872168\n",
      "[1705,     1] loss: 0.002992614172399044\n",
      "[1706,     1] loss: 0.0030224649235606194\n",
      "[1707,     1] loss: 0.0030678389593958855\n",
      "[1708,     1] loss: 0.003110297489911318\n",
      "[1709,     1] loss: 0.003162409644573927\n",
      "[1710,     1] loss: 0.0032027207780629396\n",
      "[1711,     1] loss: 0.0032449597492814064\n",
      "[1712,     1] loss: 0.0032671347726136446\n",
      "[1713,     1] loss: 0.003290897700935602\n",
      "[1714,     1] loss: 0.0032839602790772915\n",
      "[1715,     1] loss: 0.0032739019952714443\n",
      "[1716,     1] loss: 0.00323080993257463\n",
      "[1717,     1] loss: 0.00317961978726089\n",
      "[1718,     1] loss: 0.0031031472608447075\n",
      "[1719,     1] loss: 0.003027144819498062\n",
      "[1720,     1] loss: 0.002950224094092846\n",
      "[1721,     1] loss: 0.002888375660404563\n",
      "[1722,     1] loss: 0.0028420311864465475\n",
      "[1723,     1] loss: 0.0028151297010481358\n",
      "[1724,     1] loss: 0.002804120071232319\n",
      "[1725,     1] loss: 0.002807368291541934\n",
      "[1726,     1] loss: 0.0028200745582580566\n",
      "[1727,     1] loss: 0.0028391429223120213\n",
      "[1728,     1] loss: 0.0028618823271244764\n",
      "[1729,     1] loss: 0.00288382382132113\n",
      "[1730,     1] loss: 0.0029066186398267746\n",
      "[1731,     1] loss: 0.002926237415522337\n",
      "[1732,     1] loss: 0.0029515253845602274\n",
      "[1733,     1] loss: 0.002975289709866047\n",
      "[1734,     1] loss: 0.003007145831361413\n",
      "[1735,     1] loss: 0.0030322049278765917\n",
      "[1736,     1] loss: 0.0030695979949086905\n",
      "[1737,     1] loss: 0.0030900759156793356\n",
      "[1738,     1] loss: 0.0031175001058727503\n",
      "[1739,     1] loss: 0.00311622628942132\n",
      "[1740,     1] loss: 0.0031132923904806376\n",
      "[1741,     1] loss: 0.003073920961469412\n",
      "[1742,     1] loss: 0.0030227561946958303\n",
      "[1743,     1] loss: 0.0029508620500564575\n",
      "[1744,     1] loss: 0.0028815018013119698\n",
      "[1745,     1] loss: 0.0028168666176497936\n",
      "[1746,     1] loss: 0.0027706236578524113\n",
      "[1747,     1] loss: 0.0027447903994470835\n",
      "[1748,     1] loss: 0.0027389121241867542\n",
      "[1749,     1] loss: 0.0027471999637782574\n",
      "[1750,     1] loss: 0.002764533506706357\n",
      "[1751,     1] loss: 0.002786405850201845\n",
      "[1752,     1] loss: 0.0028086169622838497\n",
      "[1753,     1] loss: 0.0028313726652413607\n",
      "[1754,     1] loss: 0.0028499907348304987\n",
      "[1755,     1] loss: 0.002871807897463441\n",
      "[1756,     1] loss: 0.002882215427234769\n",
      "[1757,     1] loss: 0.0028935568407177925\n",
      "[1758,     1] loss: 0.002891922602429986\n",
      "[1759,     1] loss: 0.0028906925581395626\n",
      "[1760,     1] loss: 0.00287782889790833\n",
      "[1761,     1] loss: 0.002866098191589117\n",
      "[1762,     1] loss: 0.002850319491699338\n",
      "[1763,     1] loss: 0.0028378746937960386\n",
      "[1764,     1] loss: 0.0028297812677919865\n",
      "[1765,     1] loss: 0.002835433464497328\n",
      "[1766,     1] loss: 0.0028470999095588923\n",
      "[1767,     1] loss: 0.0028737029060721397\n",
      "[1768,     1] loss: 0.0029064309783279896\n",
      "[1769,     1] loss: 0.002951255766674876\n",
      "[1770,     1] loss: 0.002994393929839134\n",
      "[1771,     1] loss: 0.0030349178705364466\n",
      "[1772,     1] loss: 0.0030533394310623407\n",
      "[1773,     1] loss: 0.003051878185942769\n",
      "[1774,     1] loss: 0.00301594496704638\n",
      "[1775,     1] loss: 0.002961384132504463\n",
      "[1776,     1] loss: 0.002895832760259509\n",
      "[1777,     1] loss: 0.00284241302870214\n",
      "[1778,     1] loss: 0.002809845143929124\n",
      "[1779,     1] loss: 0.0028148258570581675\n",
      "[1780,     1] loss: 0.0028438312001526356\n",
      "[1781,     1] loss: 0.0029019706416875124\n",
      "[1782,     1] loss: 0.002958765020594001\n",
      "[1783,     1] loss: 0.0030229617841541767\n",
      "[1784,     1] loss: 0.0030500241555273533\n",
      "[1785,     1] loss: 0.0030656626913696527\n",
      "[1786,     1] loss: 0.003032064763829112\n",
      "[1787,     1] loss: 0.0029884844552725554\n",
      "[1788,     1] loss: 0.002920611295849085\n",
      "[1789,     1] loss: 0.0028731687925755978\n",
      "[1790,     1] loss: 0.002837730571627617\n",
      "[1791,     1] loss: 0.002829199656844139\n",
      "[1792,     1] loss: 0.002836166648194194\n",
      "[1793,     1] loss: 0.0028471825644373894\n",
      "[1794,     1] loss: 0.0028450111858546734\n",
      "[1795,     1] loss: 0.0028215544298291206\n",
      "[1796,     1] loss: 0.002776455134153366\n",
      "[1797,     1] loss: 0.0027222842909395695\n",
      "[1798,     1] loss: 0.0026712799444794655\n",
      "[1799,     1] loss: 0.0026375441811978817\n",
      "[1800,     1] loss: 0.0026254006661474705\n",
      "[1801,     1] loss: 0.0026312207337468863\n",
      "[1802,     1] loss: 0.00264716031961143\n",
      "[1803,     1] loss: 0.002665831008926034\n",
      "[1804,     1] loss: 0.002678499324247241\n",
      "[1805,     1] loss: 0.002683171071112156\n",
      "[1806,     1] loss: 0.0026798394974321127\n",
      "[1807,     1] loss: 0.002669221255928278\n",
      "[1808,     1] loss: 0.002658016048371792\n",
      "[1809,     1] loss: 0.0026499300729483366\n",
      "[1810,     1] loss: 0.0026512134354561567\n",
      "[1811,     1] loss: 0.0026650438085198402\n",
      "[1812,     1] loss: 0.0026962284464389086\n",
      "[1813,     1] loss: 0.0027416408993303776\n",
      "[1814,     1] loss: 0.002814129227772355\n",
      "[1815,     1] loss: 0.0028961440548300743\n",
      "[1816,     1] loss: 0.003013372188434005\n",
      "[1817,     1] loss: 0.0031290638726204634\n",
      "[1818,     1] loss: 0.003302948083728552\n",
      "[1819,     1] loss: 0.0034567227121442556\n",
      "[1820,     1] loss: 0.003688473254442215\n",
      "[1821,     1] loss: 0.0038289292715489864\n",
      "[1822,     1] loss: 0.004018291365355253\n",
      "[1823,     1] loss: 0.004003467969596386\n",
      "[1824,     1] loss: 0.003903951495885849\n",
      "[1825,     1] loss: 0.00360863353125751\n",
      "[1826,     1] loss: 0.0032646264880895615\n",
      "[1827,     1] loss: 0.002929162932559848\n",
      "[1828,     1] loss: 0.0026988391764461994\n",
      "[1829,     1] loss: 0.0026188655756413937\n",
      "[1830,     1] loss: 0.0026830073911696672\n",
      "[1831,     1] loss: 0.0028414782136678696\n",
      "[1832,     1] loss: 0.003006178652867675\n",
      "[1833,     1] loss: 0.003118216060101986\n",
      "[1834,     1] loss: 0.0031147541012614965\n",
      "[1835,     1] loss: 0.0030213636346161366\n",
      "[1836,     1] loss: 0.0028541008941829205\n",
      "[1837,     1] loss: 0.0026938070077449083\n",
      "[1838,     1] loss: 0.002585679991170764\n",
      "[1839,     1] loss: 0.0025557742919772863\n",
      "[1840,     1] loss: 0.0025929161347448826\n",
      "[1841,     1] loss: 0.002662286628037691\n",
      "[1842,     1] loss: 0.002726357663050294\n",
      "[1843,     1] loss: 0.0027603432536125183\n",
      "[1844,     1] loss: 0.002763938857242465\n",
      "[1845,     1] loss: 0.0027349083684384823\n",
      "[1846,     1] loss: 0.0026970901526510715\n",
      "[1847,     1] loss: 0.002650884911417961\n",
      "[1848,     1] loss: 0.002612623618915677\n",
      "[1849,     1] loss: 0.0025810152292251587\n",
      "[1850,     1] loss: 0.0025596285704523325\n",
      "[1851,     1] loss: 0.002549446187913418\n",
      "[1852,     1] loss: 0.0025496280286461115\n",
      "[1853,     1] loss: 0.002558046020567417\n",
      "[1854,     1] loss: 0.0025718468241393566\n",
      "[1855,     1] loss: 0.002588828094303608\n",
      "[1856,     1] loss: 0.0026026570703834295\n",
      "[1857,     1] loss: 0.0026159577537328005\n",
      "[1858,     1] loss: 0.0026177235413342714\n",
      "[1859,     1] loss: 0.0026133842766284943\n",
      "[1860,     1] loss: 0.002597920363768935\n",
      "[1861,     1] loss: 0.002576917875558138\n",
      "[1862,     1] loss: 0.002552058780565858\n",
      "[1863,     1] loss: 0.002530233468860388\n",
      "[1864,     1] loss: 0.0025139932986348867\n",
      "[1865,     1] loss: 0.0025050442200154066\n",
      "[1866,     1] loss: 0.0025015193969011307\n",
      "[1867,     1] loss: 0.0025024181231856346\n",
      "[1868,     1] loss: 0.0025057117454707623\n",
      "[1869,     1] loss: 0.002509172074496746\n",
      "[1870,     1] loss: 0.002512961393222213\n",
      "[1871,     1] loss: 0.002515351166948676\n",
      "[1872,     1] loss: 0.0025188829749822617\n",
      "[1873,     1] loss: 0.002523580798879266\n",
      "[1874,     1] loss: 0.0025296600069850683\n",
      "[1875,     1] loss: 0.0025375676341354847\n",
      "[1876,     1] loss: 0.0025497323367744684\n",
      "[1877,     1] loss: 0.0025618348736315966\n",
      "[1878,     1] loss: 0.002576510887593031\n",
      "[1879,     1] loss: 0.002588422503322363\n",
      "[1880,     1] loss: 0.0026080261450260878\n",
      "[1881,     1] loss: 0.0026197112165391445\n",
      "[1882,     1] loss: 0.0026353346183896065\n",
      "[1883,     1] loss: 0.002642157720401883\n",
      "[1884,     1] loss: 0.00265114801004529\n",
      "[1885,     1] loss: 0.002647486049681902\n",
      "[1886,     1] loss: 0.002649230882525444\n",
      "[1887,     1] loss: 0.002636767691001296\n",
      "[1888,     1] loss: 0.0026267466600984335\n",
      "[1889,     1] loss: 0.0026062449906021357\n",
      "[1890,     1] loss: 0.002586020389571786\n",
      "[1891,     1] loss: 0.002560455584898591\n",
      "[1892,     1] loss: 0.002539711771532893\n",
      "[1893,     1] loss: 0.0025186515413224697\n",
      "[1894,     1] loss: 0.002500794129446149\n",
      "[1895,     1] loss: 0.002483031479641795\n",
      "[1896,     1] loss: 0.0024695093743503094\n",
      "[1897,     1] loss: 0.002457584487274289\n",
      "[1898,     1] loss: 0.0024496109690517187\n",
      "[1899,     1] loss: 0.0024436318781226873\n",
      "[1900,     1] loss: 0.0024388295132666826\n",
      "[1901,     1] loss: 0.0024357354268431664\n",
      "[1902,     1] loss: 0.002434814115986228\n",
      "[1903,     1] loss: 0.0024334306363016367\n",
      "[1904,     1] loss: 0.0024328716099262238\n",
      "[1905,     1] loss: 0.0024340501986443996\n",
      "[1906,     1] loss: 0.002435262780636549\n",
      "[1907,     1] loss: 0.0024383990094065666\n",
      "[1908,     1] loss: 0.0024459261912852526\n",
      "[1909,     1] loss: 0.002457109745591879\n",
      "[1910,     1] loss: 0.002472663763910532\n",
      "[1911,     1] loss: 0.002499606227502227\n",
      "[1912,     1] loss: 0.0025332143995910883\n",
      "[1913,     1] loss: 0.0025907298550009727\n",
      "[1914,     1] loss: 0.002663965104147792\n",
      "[1915,     1] loss: 0.002784694079309702\n",
      "[1916,     1] loss: 0.002920997329056263\n",
      "[1917,     1] loss: 0.003127040108665824\n",
      "[1918,     1] loss: 0.0033334665931761265\n",
      "[1919,     1] loss: 0.0036604921333491802\n",
      "[1920,     1] loss: 0.003917145077139139\n",
      "[1921,     1] loss: 0.004285912029445171\n",
      "[1922,     1] loss: 0.004407406784594059\n",
      "[1923,     1] loss: 0.004414339549839497\n",
      "[1924,     1] loss: 0.004080554004758596\n",
      "[1925,     1] loss: 0.003617219626903534\n",
      "[1926,     1] loss: 0.0030881930142641068\n",
      "[1927,     1] loss: 0.0026953918859362602\n",
      "[1928,     1] loss: 0.002532634884119034\n",
      "[1929,     1] loss: 0.002611809875816107\n",
      "[1930,     1] loss: 0.0028439401648938656\n",
      "[1931,     1] loss: 0.0030598498415201902\n",
      "[1932,     1] loss: 0.003165959380567074\n",
      "[1933,     1] loss: 0.0030678841285407543\n",
      "[1934,     1] loss: 0.0028443923220038414\n",
      "[1935,     1] loss: 0.0025846920907497406\n",
      "[1936,     1] loss: 0.0024174030404537916\n",
      "[1937,     1] loss: 0.002398172626271844\n",
      "[1938,     1] loss: 0.002500297501683235\n",
      "[1939,     1] loss: 0.002645013155415654\n",
      "[1940,     1] loss: 0.0027334378100931644\n",
      "[1941,     1] loss: 0.002733582863584161\n",
      "[1942,     1] loss: 0.002639589598402381\n",
      "[1943,     1] loss: 0.002515843603760004\n",
      "[1944,     1] loss: 0.0024125638883560896\n",
      "[1945,     1] loss: 0.0023694902192801237\n",
      "[1946,     1] loss: 0.0023843341041356325\n",
      "[1947,     1] loss: 0.0024319146759808064\n",
      "[1948,     1] loss: 0.0024767450522631407\n",
      "[1949,     1] loss: 0.002495804335922003\n",
      "[1950,     1] loss: 0.002486045705154538\n",
      "[1951,     1] loss: 0.0024544275365769863\n",
      "[1952,     1] loss: 0.0024241644423455\n",
      "[1953,     1] loss: 0.002403951482847333\n",
      "[1954,     1] loss: 0.0023966042790561914\n",
      "[1955,     1] loss: 0.0023897665087133646\n",
      "[1956,     1] loss: 0.002382330596446991\n",
      "[1957,     1] loss: 0.00236875144764781\n",
      "[1958,     1] loss: 0.002355005592107773\n",
      "[1959,     1] loss: 0.002346059074625373\n",
      "[1960,     1] loss: 0.0023462013341486454\n",
      "[1961,     1] loss: 0.002355024218559265\n",
      "[1962,     1] loss: 0.002368215937167406\n",
      "[1963,     1] loss: 0.002380696125328541\n",
      "[1964,     1] loss: 0.0023874654434621334\n",
      "[1965,     1] loss: 0.002386712236329913\n",
      "[1966,     1] loss: 0.0023771733976900578\n",
      "[1967,     1] loss: 0.0023649660870432854\n",
      "[1968,     1] loss: 0.002350840251892805\n",
      "[1969,     1] loss: 0.0023411025758832693\n",
      "[1970,     1] loss: 0.002334055257961154\n",
      "[1971,     1] loss: 0.002330866875126958\n",
      "[1972,     1] loss: 0.002328047761693597\n",
      "[1973,     1] loss: 0.0023231906816363335\n",
      "[1974,     1] loss: 0.0023176767863333225\n",
      "[1975,     1] loss: 0.002312703290954232\n",
      "[1976,     1] loss: 0.0023062643595039845\n",
      "[1977,     1] loss: 0.0023012750316411257\n",
      "[1978,     1] loss: 0.002299134386703372\n",
      "[1979,     1] loss: 0.0022989334538578987\n",
      "[1980,     1] loss: 0.00230075279250741\n",
      "[1981,     1] loss: 0.0023060524836182594\n",
      "[1982,     1] loss: 0.0023116557858884335\n",
      "[1983,     1] loss: 0.0023186698090285063\n",
      "[1984,     1] loss: 0.0023287241347134113\n",
      "[1985,     1] loss: 0.002339867176488042\n",
      "[1986,     1] loss: 0.0023550621699541807\n",
      "[1987,     1] loss: 0.002371795941144228\n",
      "[1988,     1] loss: 0.0023966622538864613\n",
      "[1989,     1] loss: 0.0024193236604332924\n",
      "[1990,     1] loss: 0.0024508286733180285\n",
      "[1991,     1] loss: 0.002474156441166997\n",
      "[1992,     1] loss: 0.002511137630790472\n",
      "[1993,     1] loss: 0.002529884921386838\n",
      "[1994,     1] loss: 0.0025576346088200808\n",
      "[1995,     1] loss: 0.002555857179686427\n",
      "[1996,     1] loss: 0.002546759555116296\n",
      "[1997,     1] loss: 0.0025112545117735863\n",
      "[1998,     1] loss: 0.002474255161359906\n",
      "[1999,     1] loss: 0.0024268070701509714\n",
      "[2000,     1] loss: 0.0023853431921452284\n",
      "[2001,     1] loss: 0.002347792498767376\n",
      "[2002,     1] loss: 0.0023186879698187113\n",
      "[2003,     1] loss: 0.0022959124762564898\n",
      "[2004,     1] loss: 0.002280203625559807\n",
      "[2005,     1] loss: 0.0022701043635606766\n",
      "[2006,     1] loss: 0.0022648139856755733\n",
      "[2007,     1] loss: 0.0022652901243418455\n",
      "[2008,     1] loss: 0.0022686575539410114\n",
      "[2009,     1] loss: 0.0022768457420170307\n",
      "[2010,     1] loss: 0.0022885433863848448\n",
      "[2011,     1] loss: 0.0023076552897691727\n",
      "[2012,     1] loss: 0.0023300624452531338\n",
      "[2013,     1] loss: 0.002362283878028393\n",
      "[2014,     1] loss: 0.002395602175965905\n",
      "[2015,     1] loss: 0.002439526841044426\n",
      "[2016,     1] loss: 0.0024819313548505306\n",
      "[2017,     1] loss: 0.0025430512614548206\n",
      "[2018,     1] loss: 0.0025962451472878456\n",
      "[2019,     1] loss: 0.0026787323877215385\n",
      "[2020,     1] loss: 0.002733682980760932\n",
      "[2021,     1] loss: 0.0028117576148360968\n",
      "[2022,     1] loss: 0.002833808772265911\n",
      "[2023,     1] loss: 0.0028594709001481533\n",
      "[2024,     1] loss: 0.0028086514212191105\n",
      "[2025,     1] loss: 0.0027424292638897896\n",
      "[2026,     1] loss: 0.0026193028315901756\n",
      "[2027,     1] loss: 0.0024965310003608465\n",
      "[2028,     1] loss: 0.0023754192516207695\n",
      "[2029,     1] loss: 0.0022874977439641953\n",
      "[2030,     1] loss: 0.0022381474263966084\n",
      "[2031,     1] loss: 0.0022265161387622356\n",
      "[2032,     1] loss: 0.002244231989607215\n",
      "[2033,     1] loss: 0.0022816264536231756\n",
      "[2034,     1] loss: 0.0023313581477850676\n",
      "[2035,     1] loss: 0.0023801885545253754\n",
      "[2036,     1] loss: 0.0024318411014974117\n",
      "[2037,     1] loss: 0.0024679985363036394\n",
      "[2038,     1] loss: 0.0025043748319149017\n",
      "[2039,     1] loss: 0.0025128626730293036\n",
      "[2040,     1] loss: 0.0025173851754516363\n",
      "[2041,     1] loss: 0.0024913595989346504\n",
      "[2042,     1] loss: 0.0024590115062892437\n",
      "[2043,     1] loss: 0.0024118029978126287\n",
      "[2044,     1] loss: 0.0023665651679039\n",
      "[2045,     1] loss: 0.0023224549368023872\n",
      "[2046,     1] loss: 0.0022894570138305426\n",
      "[2047,     1] loss: 0.0022659788373857737\n",
      "[2048,     1] loss: 0.0022499021142721176\n",
      "[2049,     1] loss: 0.0022387984208762646\n",
      "[2050,     1] loss: 0.0022336114197969437\n",
      "[2051,     1] loss: 0.0022320894058793783\n",
      "[2052,     1] loss: 0.002234098967164755\n",
      "[2053,     1] loss: 0.002242952585220337\n",
      "[2054,     1] loss: 0.0022536180913448334\n",
      "[2055,     1] loss: 0.0022728878539055586\n",
      "[2056,     1] loss: 0.002293828409165144\n",
      "[2057,     1] loss: 0.0023243390023708344\n",
      "[2058,     1] loss: 0.0023533920757472515\n",
      "[2059,     1] loss: 0.0023906403221189976\n",
      "[2060,     1] loss: 0.0024198212195187807\n",
      "[2061,     1] loss: 0.002459816401824355\n",
      "[2062,     1] loss: 0.0024860326666384935\n",
      "[2063,     1] loss: 0.0025239421520382166\n",
      "[2064,     1] loss: 0.002545358147472143\n",
      "[2065,     1] loss: 0.0025725143495947123\n",
      "[2066,     1] loss: 0.002570298733189702\n",
      "[2067,     1] loss: 0.002566057024523616\n",
      "[2068,     1] loss: 0.002525614108890295\n",
      "[2069,     1] loss: 0.002474636770784855\n",
      "[2070,     1] loss: 0.002404258120805025\n",
      "[2071,     1] loss: 0.0023384978994727135\n",
      "[2072,     1] loss: 0.002274152124300599\n",
      "[2073,     1] loss: 0.0022260472178459167\n",
      "[2074,     1] loss: 0.0021897845435887575\n",
      "[2075,     1] loss: 0.0021694095339626074\n",
      "[2076,     1] loss: 0.002162081655114889\n",
      "[2077,     1] loss: 0.0021646127570420504\n",
      "[2078,     1] loss: 0.0021731960587203503\n",
      "[2079,     1] loss: 0.002185241552069783\n",
      "[2080,     1] loss: 0.0021965806372463703\n",
      "[2081,     1] loss: 0.0022076908499002457\n",
      "[2082,     1] loss: 0.0022156236227601767\n",
      "[2083,     1] loss: 0.0022202241234481335\n",
      "[2084,     1] loss: 0.002223189687356353\n",
      "[2085,     1] loss: 0.0022241035476326942\n",
      "[2086,     1] loss: 0.002229665871709585\n",
      "[2087,     1] loss: 0.0022395802661776543\n",
      "[2088,     1] loss: 0.002260675886645913\n",
      "[2089,     1] loss: 0.0022891429252922535\n",
      "[2090,     1] loss: 0.002344382693991065\n",
      "[2091,     1] loss: 0.002406897721812129\n",
      "[2092,     1] loss: 0.0025135839823633432\n",
      "[2093,     1] loss: 0.00261687277816236\n",
      "[2094,     1] loss: 0.0027867876924574375\n",
      "[2095,     1] loss: 0.0029106810688972473\n",
      "[2096,     1] loss: 0.0030883802101016045\n",
      "[2097,     1] loss: 0.0031376881524920464\n",
      "[2098,     1] loss: 0.003154174890369177\n",
      "[2099,     1] loss: 0.0030024696607142687\n",
      "[2100,     1] loss: 0.0028139364439994097\n",
      "[2101,     1] loss: 0.0025645969435572624\n",
      "[2102,     1] loss: 0.0023711747489869595\n",
      "[2103,     1] loss: 0.002265274990350008\n",
      "[2104,     1] loss: 0.0022632882464677095\n",
      "[2105,     1] loss: 0.0023323404602706432\n",
      "[2106,     1] loss: 0.0024083240423351526\n",
      "[2107,     1] loss: 0.0024566089268773794\n",
      "[2108,     1] loss: 0.0024336979258805513\n",
      "[2109,     1] loss: 0.0023719575256109238\n",
      "[2110,     1] loss: 0.0022792324889451265\n",
      "[2111,     1] loss: 0.0022064149379730225\n",
      "[2112,     1] loss: 0.002171306172385812\n",
      "[2113,     1] loss: 0.002181141171604395\n",
      "[2114,     1] loss: 0.0022194611374288797\n",
      "[2115,     1] loss: 0.0022597990464419127\n",
      "[2116,     1] loss: 0.0022785677574574947\n",
      "[2117,     1] loss: 0.0022643490228801966\n",
      "[2118,     1] loss: 0.0022201042156666517\n",
      "[2119,     1] loss: 0.0021629061084240675\n",
      "[2120,     1] loss: 0.002112683141604066\n",
      "[2121,     1] loss: 0.002082463586702943\n",
      "[2122,     1] loss: 0.0020755953155457973\n",
      "[2123,     1] loss: 0.0020882016979157925\n",
      "[2124,     1] loss: 0.0021090973168611526\n",
      "[2125,     1] loss: 0.0021306355483829975\n",
      "[2126,     1] loss: 0.0021434640511870384\n",
      "[2127,     1] loss: 0.002145339036360383\n",
      "[2128,     1] loss: 0.0021376011427491903\n",
      "[2129,     1] loss: 0.00212215562351048\n",
      "[2130,     1] loss: 0.0021036870311945677\n",
      "[2131,     1] loss: 0.002086560009047389\n",
      "[2132,     1] loss: 0.002073314506560564\n",
      "[2133,     1] loss: 0.002067744731903076\n",
      "[2134,     1] loss: 0.0020709922537207603\n",
      "[2135,     1] loss: 0.002078510355204344\n",
      "[2136,     1] loss: 0.00209236447699368\n",
      "[2137,     1] loss: 0.002107167849317193\n",
      "[2138,     1] loss: 0.0021252664737403393\n",
      "[2139,     1] loss: 0.0021413296926766634\n",
      "[2140,     1] loss: 0.0021636520978063345\n",
      "[2141,     1] loss: 0.002181527903303504\n",
      "[2142,     1] loss: 0.0022100163623690605\n",
      "[2143,     1] loss: 0.0022367704659700394\n",
      "[2144,     1] loss: 0.002281385473906994\n",
      "[2145,     1] loss: 0.002329848241060972\n",
      "[2146,     1] loss: 0.0024049808271229267\n",
      "[2147,     1] loss: 0.00248492369428277\n",
      "[2148,     1] loss: 0.002600649604573846\n",
      "[2149,     1] loss: 0.0027102858293801546\n",
      "[2150,     1] loss: 0.002851034514605999\n",
      "[2151,     1] loss: 0.0029528127051889896\n",
      "[2152,     1] loss: 0.0030511103104799986\n",
      "[2153,     1] loss: 0.003043250646442175\n",
      "[2154,     1] loss: 0.0029906281270086765\n",
      "[2155,     1] loss: 0.002825904404744506\n",
      "[2156,     1] loss: 0.0026318749878555536\n",
      "[2157,     1] loss: 0.0024219558108597994\n",
      "[2158,     1] loss: 0.002260669134557247\n",
      "[2159,     1] loss: 0.0021513018291443586\n",
      "[2160,     1] loss: 0.002103412989526987\n",
      "[2161,     1] loss: 0.0021002916619181633\n",
      "[2162,     1] loss: 0.002129811327904463\n",
      "[2163,     1] loss: 0.002175598405301571\n",
      "[2164,     1] loss: 0.0022223088890314102\n",
      "[2165,     1] loss: 0.0022670829202979803\n",
      "[2166,     1] loss: 0.0023034922778606415\n",
      "[2167,     1] loss: 0.002345408545807004\n",
      "[2168,     1] loss: 0.0023602021392434835\n",
      "[2169,     1] loss: 0.0023612906225025654\n",
      "[2170,     1] loss: 0.0023208479396998882\n",
      "[2171,     1] loss: 0.002264402573928237\n",
      "[2172,     1] loss: 0.0021825721487402916\n",
      "[2173,     1] loss: 0.0021042386069893837\n",
      "[2174,     1] loss: 0.002041630446910858\n",
      "[2175,     1] loss: 0.002009243005886674\n",
      "[2176,     1] loss: 0.002006219234317541\n",
      "[2177,     1] loss: 0.002025070134550333\n",
      "[2178,     1] loss: 0.0020547597669065\n",
      "[2179,     1] loss: 0.0020829085260629654\n",
      "[2180,     1] loss: 0.002110001165419817\n",
      "[2181,     1] loss: 0.0021250711288303137\n",
      "[2182,     1] loss: 0.0021413126960396767\n",
      "[2183,     1] loss: 0.0021464216988533735\n",
      "[2184,     1] loss: 0.0021559714805334806\n",
      "[2185,     1] loss: 0.002154258079826832\n",
      "[2186,     1] loss: 0.002156428061425686\n",
      "[2187,     1] loss: 0.0021505660843104124\n",
      "[2188,     1] loss: 0.002142591867595911\n",
      "[2189,     1] loss: 0.00212763249874115\n",
      "[2190,     1] loss: 0.0021096202544867992\n",
      "[2191,     1] loss: 0.0020849688444286585\n",
      "[2192,     1] loss: 0.0020595695823431015\n",
      "[2193,     1] loss: 0.002034731674939394\n",
      "[2194,     1] loss: 0.0020133405923843384\n",
      "[2195,     1] loss: 0.001997213112190366\n",
      "[2196,     1] loss: 0.001986071467399597\n",
      "[2197,     1] loss: 0.0019792139064520597\n",
      "[2198,     1] loss: 0.0019771703518927097\n",
      "[2199,     1] loss: 0.0019770790822803974\n",
      "[2200,     1] loss: 0.00197833264246583\n",
      "[2201,     1] loss: 0.0019799943547695875\n",
      "[2202,     1] loss: 0.001981492852792144\n",
      "[2203,     1] loss: 0.0019818514119833708\n",
      "[2204,     1] loss: 0.0019809314981102943\n",
      "[2205,     1] loss: 0.0019798632711172104\n",
      "[2206,     1] loss: 0.00197730609215796\n",
      "[2207,     1] loss: 0.001973958220332861\n",
      "[2208,     1] loss: 0.0019709530752152205\n",
      "[2209,     1] loss: 0.0019680054392665625\n",
      "[2210,     1] loss: 0.0019676298834383488\n",
      "[2211,     1] loss: 0.0019699595868587494\n",
      "[2212,     1] loss: 0.0019780071452260017\n",
      "[2213,     1] loss: 0.0019905571825802326\n",
      "[2214,     1] loss: 0.002013501012697816\n",
      "[2215,     1] loss: 0.002044925931841135\n",
      "[2216,     1] loss: 0.0020972909405827522\n",
      "[2217,     1] loss: 0.002166938968002796\n",
      "[2218,     1] loss: 0.0022808038629591465\n",
      "[2219,     1] loss: 0.002423227531835437\n",
      "[2220,     1] loss: 0.0026436029002070427\n",
      "[2221,     1] loss: 0.002886395202949643\n",
      "[2222,     1] loss: 0.0032893065363168716\n",
      "[2223,     1] loss: 0.003662033472210169\n",
      "[2224,     1] loss: 0.004164308309555054\n",
      "[2225,     1] loss: 0.004400298930704594\n",
      "[2226,     1] loss: 0.004553432110697031\n",
      "[2227,     1] loss: 0.004157016985118389\n",
      "[2228,     1] loss: 0.003548981389030814\n",
      "[2229,     1] loss: 0.0027617961168289185\n",
      "[2230,     1] loss: 0.002197118941694498\n",
      "[2231,     1] loss: 0.002022482454776764\n",
      "[2232,     1] loss: 0.002203961368650198\n",
      "[2233,     1] loss: 0.0025393066462129354\n",
      "[2234,     1] loss: 0.002769390819594264\n",
      "[2235,     1] loss: 0.002824916038662195\n",
      "[2236,     1] loss: 0.0026314514689147472\n",
      "[2237,     1] loss: 0.002352252835407853\n",
      "[2238,     1] loss: 0.002109018387272954\n",
      "[2239,     1] loss: 0.002016122918576002\n",
      "[2240,     1] loss: 0.0020705985371023417\n",
      "[2241,     1] loss: 0.0021890769712626934\n",
      "[2242,     1] loss: 0.0022903571370989084\n",
      "[2243,     1] loss: 0.00229753740131855\n",
      "[2244,     1] loss: 0.002232139930129051\n",
      "[2245,     1] loss: 0.002121545607224107\n",
      "[2246,     1] loss: 0.002029610797762871\n",
      "[2247,     1] loss: 0.0019906829111278057\n",
      "[2248,     1] loss: 0.0020014711190015078\n",
      "[2249,     1] loss: 0.002035444136708975\n",
      "[2250,     1] loss: 0.002058581681922078\n",
      "[2251,     1] loss: 0.0020561409182846546\n",
      "[2252,     1] loss: 0.00202878937125206\n",
      "[2253,     1] loss: 0.0019949274137616158\n",
      "[2254,     1] loss: 0.0019681390840560198\n",
      "[2255,     1] loss: 0.001958568813279271\n",
      "[2256,     1] loss: 0.001963250106200576\n",
      "[2257,     1] loss: 0.001970326993614435\n",
      "[2258,     1] loss: 0.0019726345781236887\n",
      "[2259,     1] loss: 0.0019657916855067015\n",
      "[2260,     1] loss: 0.0019558430649340153\n",
      "[2261,     1] loss: 0.0019424394704401493\n",
      "[2262,     1] loss: 0.0019326162291690707\n",
      "[2263,     1] loss: 0.0019243696006014943\n",
      "[2264,     1] loss: 0.0019201348768547177\n",
      "[2265,     1] loss: 0.0019176647765561938\n",
      "[2266,     1] loss: 0.0019168579019606113\n",
      "[2267,     1] loss: 0.0019151507876813412\n",
      "[2268,     1] loss: 0.0019129280699416995\n",
      "[2269,     1] loss: 0.0019103116355836391\n",
      "[2270,     1] loss: 0.0019064836669713259\n",
      "[2271,     1] loss: 0.0019035256700590253\n",
      "[2272,     1] loss: 0.0019011518452316523\n",
      "[2273,     1] loss: 0.0018984668422490358\n",
      "[2274,     1] loss: 0.0018957280553877354\n",
      "[2275,     1] loss: 0.0018925850745290518\n",
      "[2276,     1] loss: 0.0018897474510595202\n",
      "[2277,     1] loss: 0.001886836253106594\n",
      "[2278,     1] loss: 0.0018833853537216783\n",
      "[2279,     1] loss: 0.0018798434175550938\n",
      "[2280,     1] loss: 0.0018775304779410362\n",
      "[2281,     1] loss: 0.001876103226095438\n",
      "[2282,     1] loss: 0.0018766415305435658\n",
      "[2283,     1] loss: 0.001876687165349722\n",
      "[2284,     1] loss: 0.0018781349062919617\n",
      "[2285,     1] loss: 0.0018793168710544705\n",
      "[2286,     1] loss: 0.0018808025633916259\n",
      "[2287,     1] loss: 0.00188150885514915\n",
      "[2288,     1] loss: 0.001882520504295826\n",
      "[2289,     1] loss: 0.0018840054981410503\n",
      "[2290,     1] loss: 0.0018846297170966864\n",
      "[2291,     1] loss: 0.0018839361146092415\n",
      "[2292,     1] loss: 0.0018834786023944616\n",
      "[2293,     1] loss: 0.0018803002312779427\n",
      "[2294,     1] loss: 0.0018776257056742907\n",
      "[2295,     1] loss: 0.001873358036391437\n",
      "[2296,     1] loss: 0.0018685762770473957\n",
      "[2297,     1] loss: 0.0018647919641807675\n",
      "[2298,     1] loss: 0.0018637740286067128\n",
      "[2299,     1] loss: 0.001861555501818657\n",
      "[2300,     1] loss: 0.0018621019553393126\n",
      "[2301,     1] loss: 0.0018632437568157911\n",
      "[2302,     1] loss: 0.0018659449415281415\n",
      "[2303,     1] loss: 0.0018694703467190266\n",
      "[2304,     1] loss: 0.0018772106850519776\n",
      "[2305,     1] loss: 0.0018839453114196658\n",
      "[2306,     1] loss: 0.001894791261292994\n",
      "[2307,     1] loss: 0.0019039210164919496\n",
      "[2308,     1] loss: 0.0019171297317370772\n",
      "[2309,     1] loss: 0.0019264871953055263\n",
      "[2310,     1] loss: 0.0019395459676161408\n",
      "[2311,     1] loss: 0.0019449472893029451\n",
      "[2312,     1] loss: 0.0019527431577444077\n",
      "[2313,     1] loss: 0.0019534463062882423\n",
      "[2314,     1] loss: 0.0019573932513594627\n",
      "[2315,     1] loss: 0.0019554398022592068\n",
      "[2316,     1] loss: 0.0019599611405283213\n",
      "[2317,     1] loss: 0.001961309462785721\n",
      "[2318,     1] loss: 0.001969067845493555\n",
      "[2319,     1] loss: 0.0019744723103940487\n",
      "[2320,     1] loss: 0.0019873662386089563\n",
      "[2321,     1] loss: 0.0019999537616968155\n",
      "[2322,     1] loss: 0.002022010274231434\n",
      "[2323,     1] loss: 0.0020447990391403437\n",
      "[2324,     1] loss: 0.0020792230498045683\n",
      "[2325,     1] loss: 0.0021107723005115986\n",
      "[2326,     1] loss: 0.0021440796554088593\n",
      "[2327,     1] loss: 0.0021690502762794495\n",
      "[2328,     1] loss: 0.002186654368415475\n",
      "[2329,     1] loss: 0.00218623923137784\n",
      "[2330,     1] loss: 0.0021830336190760136\n",
      "[2331,     1] loss: 0.002158006187528372\n",
      "[2332,     1] loss: 0.0021344854030758142\n",
      "[2333,     1] loss: 0.00210006907582283\n",
      "[2334,     1] loss: 0.002080741338431835\n",
      "[2335,     1] loss: 0.0020671719685196877\n",
      "[2336,     1] loss: 0.002084242645651102\n",
      "[2337,     1] loss: 0.002109546447172761\n",
      "[2338,     1] loss: 0.0021705932449549437\n",
      "[2339,     1] loss: 0.002221907489001751\n",
      "[2340,     1] loss: 0.0022976503241807222\n",
      "[2341,     1] loss: 0.0023300580214709044\n",
      "[2342,     1] loss: 0.0023782048374414444\n",
      "[2343,     1] loss: 0.0023555252701044083\n",
      "[2344,     1] loss: 0.0023088427260518074\n",
      "[2345,     1] loss: 0.0021985862404108047\n",
      "[2346,     1] loss: 0.0020854868926107883\n",
      "[2347,     1] loss: 0.0019661937840282917\n",
      "[2348,     1] loss: 0.001879016519524157\n",
      "[2349,     1] loss: 0.001836195937357843\n",
      "[2350,     1] loss: 0.0018364129355177283\n",
      "[2351,     1] loss: 0.0018663442460820079\n",
      "[2352,     1] loss: 0.0019051814451813698\n",
      "[2353,     1] loss: 0.0019386450294405222\n",
      "[2354,     1] loss: 0.0019545278046280146\n",
      "[2355,     1] loss: 0.001953733619302511\n",
      "[2356,     1] loss: 0.0019316243706271052\n",
      "[2357,     1] loss: 0.0019054282456636429\n",
      "[2358,     1] loss: 0.0018764277920126915\n",
      "[2359,     1] loss: 0.0018561353208497167\n",
      "[2360,     1] loss: 0.001846217317506671\n",
      "[2361,     1] loss: 0.0018511563539505005\n",
      "[2362,     1] loss: 0.0018676512409001589\n",
      "[2363,     1] loss: 0.0018942105816677213\n",
      "[2364,     1] loss: 0.0019243482965976\n",
      "[2365,     1] loss: 0.0019532442092895508\n",
      "[2366,     1] loss: 0.0019742401782423258\n",
      "[2367,     1] loss: 0.001991363475099206\n",
      "[2368,     1] loss: 0.0019991230219602585\n",
      "[2369,     1] loss: 0.0020041021052747965\n",
      "[2370,     1] loss: 0.002003374043852091\n",
      "[2371,     1] loss: 0.0020103976130485535\n",
      "[2372,     1] loss: 0.002022320870310068\n",
      "[2373,     1] loss: 0.0020618881098926067\n",
      "[2374,     1] loss: 0.002113108290359378\n",
      "[2375,     1] loss: 0.002204401884227991\n",
      "[2376,     1] loss: 0.002295561134815216\n",
      "[2377,     1] loss: 0.0024383962154388428\n",
      "[2378,     1] loss: 0.0025507258251309395\n",
      "[2379,     1] loss: 0.002707564504817128\n",
      "[2380,     1] loss: 0.002776541979983449\n",
      "[2381,     1] loss: 0.0028647214639931917\n",
      "[2382,     1] loss: 0.0028109778650105\n",
      "[2383,     1] loss: 0.0027157473377883434\n",
      "[2384,     1] loss: 0.002525489777326584\n",
      "[2385,     1] loss: 0.0023408711422234774\n",
      "[2386,     1] loss: 0.0021652611903846264\n",
      "[2387,     1] loss: 0.002038627630099654\n",
      "[2388,     1] loss: 0.0019636796787381172\n",
      "[2389,     1] loss: 0.001929153804667294\n",
      "[2390,     1] loss: 0.001918362220749259\n",
      "[2391,     1] loss: 0.0019153238972648978\n",
      "[2392,     1] loss: 0.0019242482958361506\n",
      "[2393,     1] loss: 0.0019393602851778269\n",
      "[2394,     1] loss: 0.0019638033118098974\n",
      "[2395,     1] loss: 0.001988188596442342\n",
      "[2396,     1] loss: 0.0020097065716981888\n",
      "[2397,     1] loss: 0.0020125224255025387\n",
      "[2398,     1] loss: 0.001996436854824424\n",
      "[2399,     1] loss: 0.0019536269828677177\n",
      "[2400,     1] loss: 0.0018938550492748618\n",
      "[2401,     1] loss: 0.0018295749323442578\n",
      "[2402,     1] loss: 0.0017755712615326047\n",
      "[2403,     1] loss: 0.0017443678807467222\n",
      "[2404,     1] loss: 0.001739189145155251\n",
      "[2405,     1] loss: 0.0017538957763463259\n",
      "[2406,     1] loss: 0.0017780654598027468\n",
      "[2407,     1] loss: 0.0018020395655184984\n",
      "[2408,     1] loss: 0.0018185604130849242\n",
      "[2409,     1] loss: 0.0018269161228090525\n",
      "[2410,     1] loss: 0.001824862090870738\n",
      "[2411,     1] loss: 0.0018194898730143905\n",
      "[2412,     1] loss: 0.001811073161661625\n",
      "[2413,     1] loss: 0.0018079737201333046\n",
      "[2414,     1] loss: 0.001806969870813191\n",
      "[2415,     1] loss: 0.0018155649304389954\n",
      "[2416,     1] loss: 0.0018249338027089834\n",
      "[2417,     1] loss: 0.0018399497494101524\n",
      "[2418,     1] loss: 0.0018491027876734734\n",
      "[2419,     1] loss: 0.0018621054477989674\n",
      "[2420,     1] loss: 0.001862130593508482\n",
      "[2421,     1] loss: 0.0018623304786160588\n",
      "[2422,     1] loss: 0.0018523079343140125\n",
      "[2423,     1] loss: 0.001841061282902956\n",
      "[2424,     1] loss: 0.001827056403271854\n",
      "[2425,     1] loss: 0.0018213066505268216\n",
      "[2426,     1] loss: 0.0018166021909564734\n",
      "[2427,     1] loss: 0.001816418720409274\n",
      "[2428,     1] loss: 0.0018177811289206147\n",
      "[2429,     1] loss: 0.0018212584545835853\n",
      "[2430,     1] loss: 0.001822519931010902\n",
      "[2431,     1] loss: 0.001824321923777461\n",
      "[2432,     1] loss: 0.001824581646360457\n",
      "[2433,     1] loss: 0.0018255194881930947\n",
      "[2434,     1] loss: 0.0018273168243467808\n",
      "[2435,     1] loss: 0.001832186128012836\n",
      "[2436,     1] loss: 0.0018376631196588278\n",
      "[2437,     1] loss: 0.0018511891830712557\n",
      "[2438,     1] loss: 0.0018690342549234629\n",
      "[2439,     1] loss: 0.001901415642350912\n",
      "[2440,     1] loss: 0.0019391170935705304\n",
      "[2441,     1] loss: 0.0019995467737317085\n",
      "[2442,     1] loss: 0.002058698795735836\n",
      "[2443,     1] loss: 0.0021464924793690443\n",
      "[2444,     1] loss: 0.002227160381153226\n",
      "[2445,     1] loss: 0.0023406678810715675\n",
      "[2446,     1] loss: 0.002425881801173091\n",
      "[2447,     1] loss: 0.0025493307039141655\n",
      "[2448,     1] loss: 0.002603493630886078\n",
      "[2449,     1] loss: 0.0026687472127377987\n",
      "[2450,     1] loss: 0.00263509270735085\n",
      "[2451,     1] loss: 0.0025864732451736927\n",
      "[2452,     1] loss: 0.002444817451760173\n",
      "[2453,     1] loss: 0.002283920533955097\n",
      "[2454,     1] loss: 0.002105108927935362\n",
      "[2455,     1] loss: 0.0019505411619320512\n",
      "[2456,     1] loss: 0.0018383743008598685\n",
      "[2457,     1] loss: 0.0017787916585803032\n",
      "[2458,     1] loss: 0.0017655292758718133\n",
      "[2459,     1] loss: 0.0017849241849035025\n",
      "[2460,     1] loss: 0.0018237606855109334\n",
      "[2461,     1] loss: 0.0018672936130315065\n",
      "[2462,     1] loss: 0.0019097160547971725\n",
      "[2463,     1] loss: 0.0019378317520022392\n",
      "[2464,     1] loss: 0.0019595224875956774\n",
      "[2465,     1] loss: 0.00195895042270422\n",
      "[2466,     1] loss: 0.00194724986795336\n",
      "[2467,     1] loss: 0.0019139989744871855\n",
      "[2468,     1] loss: 0.001866807579062879\n",
      "[2469,     1] loss: 0.0018098530126735568\n",
      "[2470,     1] loss: 0.0017571727512404323\n",
      "[2471,     1] loss: 0.0017133726505562663\n",
      "[2472,     1] loss: 0.0016844394849613309\n",
      "[2473,     1] loss: 0.0016714960802346468\n",
      "[2474,     1] loss: 0.0016731470823287964\n",
      "[2475,     1] loss: 0.0016850208630785346\n",
      "[2476,     1] loss: 0.0017026105197146535\n",
      "[2477,     1] loss: 0.0017246068455278873\n",
      "[2478,     1] loss: 0.0017444448312744498\n",
      "[2479,     1] loss: 0.001764057669788599\n",
      "[2480,     1] loss: 0.0017808161210268736\n",
      "[2481,     1] loss: 0.0017971113556995988\n",
      "[2482,     1] loss: 0.0018073627725243568\n",
      "[2483,     1] loss: 0.0018200052436441183\n",
      "[2484,     1] loss: 0.0018287848215550184\n",
      "[2485,     1] loss: 0.001843912061303854\n",
      "[2486,     1] loss: 0.0018540319288149476\n",
      "[2487,     1] loss: 0.0018740590894594789\n",
      "[2488,     1] loss: 0.001886445563286543\n",
      "[2489,     1] loss: 0.0019065019441768527\n",
      "[2490,     1] loss: 0.001911766710691154\n",
      "[2491,     1] loss: 0.001918938709422946\n",
      "[2492,     1] loss: 0.0019056637538596988\n",
      "[2493,     1] loss: 0.001893714303150773\n",
      "[2494,     1] loss: 0.001864543417468667\n",
      "[2495,     1] loss: 0.0018324829870834947\n",
      "[2496,     1] loss: 0.0017915088683366776\n",
      "[2497,     1] loss: 0.0017549780895933509\n",
      "[2498,     1] loss: 0.00171990180388093\n",
      "[2499,     1] loss: 0.0016929341945797205\n",
      "[2500,     1] loss: 0.0016735073877498507\n",
      "[2501,     1] loss: 0.0016629428137093782\n",
      "[2502,     1] loss: 0.001660376787185669\n",
      "[2503,     1] loss: 0.0016619375674054027\n",
      "[2504,     1] loss: 0.001666039228439331\n",
      "[2505,     1] loss: 0.0016729108756408095\n",
      "[2506,     1] loss: 0.001678015454672277\n",
      "[2507,     1] loss: 0.001683006645180285\n",
      "[2508,     1] loss: 0.0016885779332369566\n",
      "[2509,     1] loss: 0.0016911095008254051\n",
      "[2510,     1] loss: 0.0016953019658103585\n",
      "[2511,     1] loss: 0.0017014273907989264\n",
      "[2512,     1] loss: 0.0017107597086578608\n",
      "[2513,     1] loss: 0.0017231288366019726\n",
      "[2514,     1] loss: 0.0017448298167437315\n",
      "[2515,     1] loss: 0.0017693699337542057\n",
      "[2516,     1] loss: 0.0018109048251062632\n",
      "[2517,     1] loss: 0.0018595566507428885\n",
      "[2518,     1] loss: 0.0019399267621338367\n",
      "[2519,     1] loss: 0.0020282231271266937\n",
      "[2520,     1] loss: 0.0021701997611671686\n",
      "[2521,     1] loss: 0.0023159815464168787\n",
      "[2522,     1] loss: 0.0025358705315738916\n",
      "[2523,     1] loss: 0.002737131668254733\n",
      "[2524,     1] loss: 0.0030307932756841183\n",
      "[2525,     1] loss: 0.0032288767397403717\n",
      "[2526,     1] loss: 0.0034747389145195484\n",
      "[2527,     1] loss: 0.003488139482215047\n",
      "[2528,     1] loss: 0.0034017153084278107\n",
      "[2529,     1] loss: 0.0030636689625680447\n",
      "[2530,     1] loss: 0.002637891098856926\n",
      "[2531,     1] loss: 0.00219131913036108\n",
      "[2532,     1] loss: 0.001872228691354394\n",
      "[2533,     1] loss: 0.0017423391109332442\n",
      "[2534,     1] loss: 0.0017941804835572839\n",
      "[2535,     1] loss: 0.0019539918284863234\n",
      "[2536,     1] loss: 0.0021151970140635967\n",
      "[2537,     1] loss: 0.0022232404444366693\n",
      "[2538,     1] loss: 0.002208762802183628\n",
      "[2539,     1] loss: 0.002108486369252205\n",
      "[2540,     1] loss: 0.0019351276569068432\n",
      "[2541,     1] loss: 0.0017706044018268585\n",
      "[2542,     1] loss: 0.0016661594854667783\n",
      "[2543,     1] loss: 0.0016452544368803501\n",
      "[2544,     1] loss: 0.001692209392786026\n",
      "[2545,     1] loss: 0.001768338494002819\n",
      "[2546,     1] loss: 0.001839037286117673\n",
      "[2547,     1] loss: 0.0018677882617339492\n",
      "[2548,     1] loss: 0.0018573449924588203\n",
      "[2549,     1] loss: 0.0018035240937024355\n",
      "[2550,     1] loss: 0.0017315810546278954\n",
      "[2551,     1] loss: 0.001662210444919765\n",
      "[2552,     1] loss: 0.0016198543598875403\n",
      "[2553,     1] loss: 0.0016074531013146043\n",
      "[2554,     1] loss: 0.0016235043294727802\n",
      "[2555,     1] loss: 0.0016551984008401632\n",
      "[2556,     1] loss: 0.0016858516028150916\n",
      "[2557,     1] loss: 0.0017081254627555609\n",
      "[2558,     1] loss: 0.0017134903464466333\n",
      "[2559,     1] loss: 0.0017058653756976128\n",
      "[2560,     1] loss: 0.0016835287678986788\n",
      "[2561,     1] loss: 0.001654064399190247\n",
      "[2562,     1] loss: 0.0016236489173024893\n",
      "[2563,     1] loss: 0.0016001196345314384\n",
      "[2564,     1] loss: 0.0015873197698965669\n",
      "[2565,     1] loss: 0.001585107296705246\n",
      "[2566,     1] loss: 0.0015909540234133601\n",
      "[2567,     1] loss: 0.001601966330781579\n",
      "[2568,     1] loss: 0.001615904737263918\n",
      "[2569,     1] loss: 0.0016286056488752365\n",
      "[2570,     1] loss: 0.0016400569584220648\n",
      "[2571,     1] loss: 0.0016467024106532335\n",
      "[2572,     1] loss: 0.001650582766160369\n",
      "[2573,     1] loss: 0.001647931756451726\n",
      "[2574,     1] loss: 0.001644979463890195\n",
      "[2575,     1] loss: 0.0016370273660868406\n",
      "[2576,     1] loss: 0.0016294033266603947\n",
      "[2577,     1] loss: 0.0016185927670449018\n",
      "[2578,     1] loss: 0.0016084916424006224\n",
      "[2579,     1] loss: 0.0015975084388628602\n",
      "[2580,     1] loss: 0.0015891888178884983\n",
      "[2581,     1] loss: 0.001581733813509345\n",
      "[2582,     1] loss: 0.001576801878400147\n",
      "[2583,     1] loss: 0.0015726203564554453\n",
      "[2584,     1] loss: 0.0015706566628068686\n",
      "[2585,     1] loss: 0.001569391810335219\n",
      "[2586,     1] loss: 0.00157044583465904\n",
      "[2587,     1] loss: 0.0015714706387370825\n",
      "[2588,     1] loss: 0.001573092769831419\n",
      "[2589,     1] loss: 0.0015761250397190452\n",
      "[2590,     1] loss: 0.0015788634773343801\n",
      "[2591,     1] loss: 0.001583305886015296\n",
      "[2592,     1] loss: 0.0015869811177253723\n",
      "[2593,     1] loss: 0.0015926327323541045\n",
      "[2594,     1] loss: 0.001597704365849495\n",
      "[2595,     1] loss: 0.001604618621058762\n",
      "[2596,     1] loss: 0.0016119987703859806\n",
      "[2597,     1] loss: 0.0016196619253605604\n",
      "[2598,     1] loss: 0.0016263368306681514\n",
      "[2599,     1] loss: 0.001635116757825017\n",
      "[2600,     1] loss: 0.0016421753680333495\n",
      "[2601,     1] loss: 0.0016508823027834296\n",
      "[2602,     1] loss: 0.0016596016939729452\n",
      "[2603,     1] loss: 0.0016699405387043953\n",
      "[2604,     1] loss: 0.0016778958961367607\n",
      "[2605,     1] loss: 0.001689014257863164\n",
      "[2606,     1] loss: 0.001697771716862917\n",
      "[2607,     1] loss: 0.0017084985738620162\n",
      "[2608,     1] loss: 0.0017186178592965007\n",
      "[2609,     1] loss: 0.001733182929456234\n",
      "[2610,     1] loss: 0.0017478321678936481\n",
      "[2611,     1] loss: 0.0017766429809853435\n",
      "[2612,     1] loss: 0.0018128715455532074\n",
      "[2613,     1] loss: 0.0018792608752846718\n",
      "[2614,     1] loss: 0.001958746463060379\n",
      "[2615,     1] loss: 0.0021074353717267513\n",
      "[2616,     1] loss: 0.002279536798596382\n",
      "[2617,     1] loss: 0.0025755027309060097\n",
      "[2618,     1] loss: 0.0028716851957142353\n",
      "[2619,     1] loss: 0.003319925395771861\n",
      "[2620,     1] loss: 0.0035116018261760473\n",
      "[2621,     1] loss: 0.0036963869351893663\n",
      "[2622,     1] loss: 0.003366597928106785\n",
      "[2623,     1] loss: 0.002902041655033827\n",
      "[2624,     1] loss: 0.002207500860095024\n",
      "[2625,     1] loss: 0.0017000087536871433\n",
      "[2626,     1] loss: 0.001549295149743557\n",
      "[2627,     1] loss: 0.0017356752650812268\n",
      "[2628,     1] loss: 0.002066652989014983\n",
      "[2629,     1] loss: 0.0022992740850895643\n",
      "[2630,     1] loss: 0.0023358436301350594\n",
      "[2631,     1] loss: 0.002121295314282179\n",
      "[2632,     1] loss: 0.0018406721064820886\n",
      "[2633,     1] loss: 0.0016165805282071233\n",
      "[2634,     1] loss: 0.0015610117698088288\n",
      "[2635,     1] loss: 0.0016555361216887832\n",
      "[2636,     1] loss: 0.0018010551575571299\n",
      "[2637,     1] loss: 0.0019026079680770636\n",
      "[2638,     1] loss: 0.0018811196787282825\n",
      "[2639,     1] loss: 0.0017807779368013144\n",
      "[2640,     1] loss: 0.0016406631330028176\n",
      "[2641,     1] loss: 0.0015416309470310807\n",
      "[2642,     1] loss: 0.001523172715678811\n",
      "[2643,     1] loss: 0.001572678447701037\n",
      "[2644,     1] loss: 0.0016433065757155418\n",
      "[2645,     1] loss: 0.0016870555700734258\n",
      "[2646,     1] loss: 0.0016803008038550615\n",
      "[2647,     1] loss: 0.0016305128810927272\n",
      "[2648,     1] loss: 0.0015693737659603357\n",
      "[2649,     1] loss: 0.0015268924180418253\n",
      "[2650,     1] loss: 0.001518476870842278\n",
      "[2651,     1] loss: 0.0015394589863717556\n",
      "[2652,     1] loss: 0.001571329077705741\n",
      "[2653,     1] loss: 0.0015973959816619754\n",
      "[2654,     1] loss: 0.0016024328069761395\n",
      "[2655,     1] loss: 0.0015899871941655874\n",
      "[2656,     1] loss: 0.0015635245945304632\n",
      "[2657,     1] loss: 0.0015368100721389055\n",
      "[2658,     1] loss: 0.001519884099252522\n",
      "[2659,     1] loss: 0.0015173073625192046\n",
      "[2660,     1] loss: 0.0015270332805812359\n",
      "[2661,     1] loss: 0.0015402904246002436\n",
      "[2662,     1] loss: 0.0015536275459453464\n",
      "[2663,     1] loss: 0.0015598853351548314\n",
      "[2664,     1] loss: 0.001557953655719757\n",
      "[2665,     1] loss: 0.0015508714132010937\n",
      "[2666,     1] loss: 0.0015432024374604225\n",
      "[2667,     1] loss: 0.0015395665541291237\n",
      "[2668,     1] loss: 0.0015415233792737126\n",
      "[2669,     1] loss: 0.001552657806314528\n",
      "[2670,     1] loss: 0.0015716295456513762\n",
      "[2671,     1] loss: 0.0015993916895240545\n",
      "[2672,     1] loss: 0.0016306228935718536\n",
      "[2673,     1] loss: 0.0016715535894036293\n",
      "[2674,     1] loss: 0.0017150507774204016\n",
      "[2675,     1] loss: 0.0017755299340933561\n",
      "[2676,     1] loss: 0.0018425309099256992\n",
      "[2677,     1] loss: 0.0019343295134603977\n",
      "[2678,     1] loss: 0.0020307248923927546\n",
      "[2679,     1] loss: 0.0021532760001719\n",
      "[2680,     1] loss: 0.002266473602503538\n",
      "[2681,     1] loss: 0.0023861974477767944\n",
      "[2682,     1] loss: 0.0024571334943175316\n",
      "[2683,     1] loss: 0.0024884671438485384\n",
      "[2684,     1] loss: 0.002415078692138195\n",
      "[2685,     1] loss: 0.002277989871799946\n",
      "[2686,     1] loss: 0.0020680506713688374\n",
      "[2687,     1] loss: 0.0018565839855000377\n",
      "[2688,     1] loss: 0.001680981833487749\n",
      "[2689,     1] loss: 0.0015799864195287228\n",
      "[2690,     1] loss: 0.0015466338954865932\n",
      "[2691,     1] loss: 0.0015624520601704717\n",
      "[2692,     1] loss: 0.0015971807297319174\n",
      "[2693,     1] loss: 0.0016328837955370545\n",
      "[2694,     1] loss: 0.001662430353462696\n",
      "[2695,     1] loss: 0.0016807473730295897\n",
      "[2696,     1] loss: 0.0016954916063696146\n",
      "[2697,     1] loss: 0.001704478869214654\n",
      "[2698,     1] loss: 0.0017204431351274252\n",
      "[2699,     1] loss: 0.0017160908319056034\n",
      "[2700,     1] loss: 0.0017142673023045063\n",
      "[2701,     1] loss: 0.0016787006752565503\n",
      "[2702,     1] loss: 0.00162704277317971\n",
      "[2703,     1] loss: 0.0015613901196047664\n",
      "[2704,     1] loss: 0.001505354535765946\n",
      "[2705,     1] loss: 0.0014714967692270875\n",
      "[2706,     1] loss: 0.0014641120797023177\n",
      "[2707,     1] loss: 0.0014771686401218176\n",
      "[2708,     1] loss: 0.0014988173497840762\n",
      "[2709,     1] loss: 0.001522657461464405\n",
      "[2710,     1] loss: 0.0015388771425932646\n",
      "[2711,     1] loss: 0.0015516538405790925\n",
      "[2712,     1] loss: 0.0015561869367957115\n",
      "[2713,     1] loss: 0.0015581331681460142\n",
      "[2714,     1] loss: 0.001558062736876309\n",
      "[2715,     1] loss: 0.0015608546091243625\n",
      "[2716,     1] loss: 0.0015605587977916002\n",
      "[2717,     1] loss: 0.001562838675454259\n",
      "[2718,     1] loss: 0.001561373588629067\n",
      "[2719,     1] loss: 0.0015585010405629873\n",
      "[2720,     1] loss: 0.0015511340461671352\n",
      "[2721,     1] loss: 0.0015412080101668835\n",
      "[2722,     1] loss: 0.0015287589048966765\n",
      "[2723,     1] loss: 0.0015164026990532875\n",
      "[2724,     1] loss: 0.0015041190199553967\n",
      "[2725,     1] loss: 0.0014959941618144512\n",
      "[2726,     1] loss: 0.0014897417277097702\n",
      "[2727,     1] loss: 0.001488181296736002\n",
      "[2728,     1] loss: 0.00148850679397583\n",
      "[2729,     1] loss: 0.0014917358057573438\n",
      "[2730,     1] loss: 0.0014951596967875957\n",
      "[2731,     1] loss: 0.0015029105124995112\n",
      "[2732,     1] loss: 0.0015094818081706762\n",
      "[2733,     1] loss: 0.0015198582550510764\n",
      "[2734,     1] loss: 0.0015288535505533218\n",
      "[2735,     1] loss: 0.001544077880680561\n",
      "[2736,     1] loss: 0.0015588575042784214\n",
      "[2737,     1] loss: 0.0015806728042662144\n",
      "[2738,     1] loss: 0.0016052722930908203\n",
      "[2739,     1] loss: 0.0016434220597147942\n",
      "[2740,     1] loss: 0.001686136587522924\n",
      "[2741,     1] loss: 0.0017469401936978102\n",
      "[2742,     1] loss: 0.001808765227906406\n",
      "[2743,     1] loss: 0.0018961051246151328\n",
      "[2744,     1] loss: 0.0019811263773590326\n",
      "[2745,     1] loss: 0.0021094295661896467\n",
      "[2746,     1] loss: 0.0022200699895620346\n",
      "[2747,     1] loss: 0.002377558732405305\n",
      "[2748,     1] loss: 0.0024817478843033314\n",
      "[2749,     1] loss: 0.0026198639534413815\n",
      "[2750,     1] loss: 0.0026491512544453144\n",
      "[2751,     1] loss: 0.0026761568151414394\n",
      "[2752,     1] loss: 0.002539740176871419\n",
      "[2753,     1] loss: 0.002326149493455887\n",
      "[2754,     1] loss: 0.0020226328633725643\n",
      "[2755,     1] loss: 0.0017341694328933954\n",
      "[2756,     1] loss: 0.0015228984411805868\n",
      "[2757,     1] loss: 0.0014304405776783824\n",
      "[2758,     1] loss: 0.0014531424967572093\n",
      "[2759,     1] loss: 0.0015523269539698958\n",
      "[2760,     1] loss: 0.0016777388518676162\n",
      "[2761,     1] loss: 0.001778420410118997\n",
      "[2762,     1] loss: 0.0018463291926309466\n",
      "[2763,     1] loss: 0.0018435809761285782\n",
      "[2764,     1] loss: 0.001802324433811009\n",
      "[2765,     1] loss: 0.0017119594849646091\n",
      "[2766,     1] loss: 0.001616982975974679\n",
      "[2767,     1] loss: 0.0015290174633264542\n",
      "[2768,     1] loss: 0.0014681972097605467\n",
      "[2769,     1] loss: 0.0014402231900021434\n",
      "[2770,     1] loss: 0.0014421262312680483\n",
      "[2771,     1] loss: 0.001465054345317185\n",
      "[2772,     1] loss: 0.0014949494507163763\n",
      "[2773,     1] loss: 0.0015244635287672281\n",
      "[2774,     1] loss: 0.001542665297165513\n",
      "[2775,     1] loss: 0.0015527065843343735\n",
      "[2776,     1] loss: 0.0015486935153603554\n",
      "[2777,     1] loss: 0.0015398029936477542\n",
      "[2778,     1] loss: 0.0015227101976051927\n",
      "[2779,     1] loss: 0.0015066725900396705\n",
      "[2780,     1] loss: 0.0014886549906805158\n",
      "[2781,     1] loss: 0.0014719553291797638\n",
      "[2782,     1] loss: 0.0014546207385137677\n",
      "[2783,     1] loss: 0.0014404079411178827\n",
      "[2784,     1] loss: 0.0014292425476014614\n",
      "[2785,     1] loss: 0.0014219601871445775\n",
      "[2786,     1] loss: 0.0014182527083903551\n",
      "[2787,     1] loss: 0.0014179664431139827\n",
      "[2788,     1] loss: 0.0014221285236999393\n",
      "[2789,     1] loss: 0.00142768956720829\n",
      "[2790,     1] loss: 0.001434916048310697\n",
      "[2791,     1] loss: 0.0014433643082156777\n",
      "[2792,     1] loss: 0.0014524449361488223\n",
      "[2793,     1] loss: 0.0014608183410018682\n",
      "[2794,     1] loss: 0.0014704861678183079\n",
      "[2795,     1] loss: 0.0014782019425183535\n",
      "[2796,     1] loss: 0.0014884218107908964\n",
      "[2797,     1] loss: 0.0014945981092751026\n",
      "[2798,     1] loss: 0.001503670122474432\n",
      "[2799,     1] loss: 0.0015090488595888019\n",
      "[2800,     1] loss: 0.0015171482227742672\n",
      "[2801,     1] loss: 0.001521194470115006\n",
      "[2802,     1] loss: 0.0015288081485778093\n",
      "[2803,     1] loss: 0.001532827503979206\n",
      "[2804,     1] loss: 0.0015421595890074968\n",
      "[2805,     1] loss: 0.0015480798901990056\n",
      "[2806,     1] loss: 0.0015592335257679224\n",
      "[2807,     1] loss: 0.0015677893534302711\n",
      "[2808,     1] loss: 0.0015822869027033448\n",
      "[2809,     1] loss: 0.001593494089320302\n",
      "[2810,     1] loss: 0.0016124953981488943\n",
      "[2811,     1] loss: 0.001626045792363584\n",
      "[2812,     1] loss: 0.0016537538031116128\n",
      "[2813,     1] loss: 0.0016708150506019592\n",
      "[2814,     1] loss: 0.0017017591744661331\n",
      "[2815,     1] loss: 0.0017169861821457744\n",
      "[2816,     1] loss: 0.0017483574338257313\n",
      "[2817,     1] loss: 0.0017576973186805844\n",
      "[2818,     1] loss: 0.0017713889246806502\n",
      "[2819,     1] loss: 0.0017582621658220887\n",
      "[2820,     1] loss: 0.0017377224285155535\n",
      "[2821,     1] loss: 0.0016969286371022463\n",
      "[2822,     1] loss: 0.0016547664999961853\n",
      "[2823,     1] loss: 0.0016031070845201612\n",
      "[2824,     1] loss: 0.001555941067636013\n",
      "[2825,     1] loss: 0.001511715236119926\n",
      "[2826,     1] loss: 0.0014771928545087576\n",
      "[2827,     1] loss: 0.0014529058244079351\n",
      "[2828,     1] loss: 0.001438965555280447\n",
      "[2829,     1] loss: 0.00143399927765131\n",
      "[2830,     1] loss: 0.0014377488987520337\n",
      "[2831,     1] loss: 0.0014490151079371572\n",
      "[2832,     1] loss: 0.0014646369963884354\n",
      "[2833,     1] loss: 0.0014838980278000236\n",
      "[2834,     1] loss: 0.001500581973232329\n",
      "[2835,     1] loss: 0.0015186010859906673\n",
      "[2836,     1] loss: 0.0015304310945793986\n",
      "[2837,     1] loss: 0.0015476386761292815\n",
      "[2838,     1] loss: 0.001553718582727015\n",
      "[2839,     1] loss: 0.0015611377311870456\n",
      "[2840,     1] loss: 0.0015583845088258386\n",
      "[2841,     1] loss: 0.0015582966152578592\n",
      "[2842,     1] loss: 0.001551094464957714\n",
      "[2843,     1] loss: 0.0015471848892048001\n",
      "[2844,     1] loss: 0.0015426009194925427\n",
      "[2845,     1] loss: 0.0015491180820390582\n",
      "[2846,     1] loss: 0.0015627359971404076\n",
      "[2847,     1] loss: 0.0016010234830901027\n",
      "[2848,     1] loss: 0.0016513783484697342\n",
      "[2849,     1] loss: 0.0017340077320113778\n",
      "[2850,     1] loss: 0.0018303709803149104\n",
      "[2851,     1] loss: 0.001962425885722041\n",
      "[2852,     1] loss: 0.002100605284795165\n",
      "[2853,     1] loss: 0.0022675141226500273\n",
      "[2854,     1] loss: 0.0024089834187179804\n",
      "[2855,     1] loss: 0.002562490291893482\n",
      "[2856,     1] loss: 0.0026292353868484497\n",
      "[2857,     1] loss: 0.002675762865692377\n",
      "[2858,     1] loss: 0.002600213047116995\n",
      "[2859,     1] loss: 0.0025005119387060404\n",
      "[2860,     1] loss: 0.0023264987394213676\n",
      "[2861,     1] loss: 0.0022279517725110054\n",
      "[2862,     1] loss: 0.002088573295623064\n",
      "[2863,     1] loss: 0.001986119197681546\n",
      "[2864,     1] loss: 0.0018533095717430115\n",
      "[2865,     1] loss: 0.001735387253575027\n",
      "[2866,     1] loss: 0.0016272752545773983\n",
      "[2867,     1] loss: 0.0015523541951552033\n",
      "[2868,     1] loss: 0.0015229886630550027\n",
      "[2869,     1] loss: 0.0015410126652568579\n",
      "[2870,     1] loss: 0.001599672599695623\n",
      "[2871,     1] loss: 0.001666524913161993\n",
      "[2872,     1] loss: 0.001736531499773264\n",
      "[2873,     1] loss: 0.0017347490647807717\n",
      "[2874,     1] loss: 0.001700891531072557\n",
      "[2875,     1] loss: 0.0016083874506875873\n",
      "[2876,     1] loss: 0.0014987632166594267\n",
      "[2877,     1] loss: 0.001398327760398388\n",
      "[2878,     1] loss: 0.001340051763691008\n",
      "[2879,     1] loss: 0.0013346070190891623\n",
      "[2880,     1] loss: 0.0013692828360944986\n",
      "[2881,     1] loss: 0.0014202574966475368\n",
      "[2882,     1] loss: 0.0014631213853135705\n",
      "[2883,     1] loss: 0.0014929863391444087\n",
      "[2884,     1] loss: 0.001492345822043717\n",
      "[2885,     1] loss: 0.001472738804295659\n",
      "[2886,     1] loss: 0.001438642619177699\n",
      "[2887,     1] loss: 0.0014041917165741324\n",
      "[2888,     1] loss: 0.0013765678741037846\n",
      "[2889,     1] loss: 0.0013603413244709373\n",
      "[2890,     1] loss: 0.0013542275410145521\n",
      "[2891,     1] loss: 0.0013551336014643312\n",
      "[2892,     1] loss: 0.001356102991849184\n",
      "[2893,     1] loss: 0.0013551120646297932\n",
      "[2894,     1] loss: 0.0013512915465980768\n",
      "[2895,     1] loss: 0.0013470040867105126\n",
      "[2896,     1] loss: 0.0013437074376270175\n",
      "[2897,     1] loss: 0.0013432875275611877\n",
      "[2898,     1] loss: 0.0013469683472067118\n",
      "[2899,     1] loss: 0.001354613108560443\n",
      "[2900,     1] loss: 0.0013648220337927341\n",
      "[2901,     1] loss: 0.0013755069812759757\n",
      "[2902,     1] loss: 0.0013875269796699286\n",
      "[2903,     1] loss: 0.0013972490560263395\n",
      "[2904,     1] loss: 0.0014074239879846573\n",
      "[2905,     1] loss: 0.0014153638621792197\n",
      "[2906,     1] loss: 0.0014229173539206386\n",
      "[2907,     1] loss: 0.0014273778069764376\n",
      "[2908,     1] loss: 0.0014335073065012693\n",
      "[2909,     1] loss: 0.0014388037379831076\n",
      "[2910,     1] loss: 0.0014487623702734709\n",
      "[2911,     1] loss: 0.0014579358976334333\n",
      "[2912,     1] loss: 0.0014724943321198225\n",
      "[2913,     1] loss: 0.0014849139843136072\n",
      "[2914,     1] loss: 0.001504635321907699\n",
      "[2915,     1] loss: 0.0015184261137619615\n",
      "[2916,     1] loss: 0.0015398982213810086\n",
      "[2917,     1] loss: 0.0015535573475062847\n",
      "[2918,     1] loss: 0.001579223433509469\n",
      "[2919,     1] loss: 0.001594396191649139\n",
      "[2920,     1] loss: 0.0016197115182876587\n",
      "[2921,     1] loss: 0.001631548977456987\n",
      "[2922,     1] loss: 0.0016417165752500296\n",
      "[2923,     1] loss: 0.0016379151493310928\n",
      "[2924,     1] loss: 0.0016400667373090982\n",
      "[2925,     1] loss: 0.0016283574514091015\n",
      "[2926,     1] loss: 0.0016159648075699806\n",
      "[2927,     1] loss: 0.0015939428703859448\n",
      "[2928,     1] loss: 0.0015742465620860457\n",
      "[2929,     1] loss: 0.0015464653261005878\n",
      "[2930,     1] loss: 0.0015186491655185819\n",
      "[2931,     1] loss: 0.0014867811696603894\n",
      "[2932,     1] loss: 0.001455528661608696\n",
      "[2933,     1] loss: 0.0014223546022549272\n",
      "[2934,     1] loss: 0.0013910855632275343\n",
      "[2935,     1] loss: 0.0013609069865196943\n",
      "[2936,     1] loss: 0.0013356271665543318\n",
      "[2937,     1] loss: 0.0013165619457140565\n",
      "[2938,     1] loss: 0.00130359863396734\n",
      "[2939,     1] loss: 0.0012958099832758307\n",
      "[2940,     1] loss: 0.0012928055366501212\n",
      "[2941,     1] loss: 0.001293161534704268\n",
      "[2942,     1] loss: 0.0012956919381394982\n",
      "[2943,     1] loss: 0.0012996611185371876\n",
      "[2944,     1] loss: 0.001303846831433475\n",
      "[2945,     1] loss: 0.0013083816738799214\n",
      "[2946,     1] loss: 0.0013138940557837486\n",
      "[2947,     1] loss: 0.0013187406584620476\n",
      "[2948,     1] loss: 0.0013221310218796134\n",
      "[2949,     1] loss: 0.0013244366273283958\n",
      "[2950,     1] loss: 0.001326373079791665\n",
      "[2951,     1] loss: 0.0013277240796014667\n",
      "[2952,     1] loss: 0.001330052618868649\n",
      "[2953,     1] loss: 0.0013318081619217992\n",
      "[2954,     1] loss: 0.0013365570921450853\n",
      "[2955,     1] loss: 0.0013432783307507634\n",
      "[2956,     1] loss: 0.0013577513163909316\n",
      "[2957,     1] loss: 0.001378270098939538\n",
      "[2958,     1] loss: 0.0014160205610096455\n",
      "[2959,     1] loss: 0.0014682933688163757\n",
      "[2960,     1] loss: 0.001562482095323503\n",
      "[2961,     1] loss: 0.001689653960056603\n",
      "[2962,     1] loss: 0.0019152084132656455\n",
      "[2963,     1] loss: 0.002201099880039692\n",
      "[2964,     1] loss: 0.0026821200735867023\n",
      "[2965,     1] loss: 0.003177727572619915\n",
      "[2966,     1] loss: 0.003957240842282772\n",
      "[2967,     1] loss: 0.004473188892006874\n",
      "[2968,     1] loss: 0.005069076549261808\n",
      "[2969,     1] loss: 0.004904749803245068\n",
      "[2970,     1] loss: 0.004422934725880623\n",
      "[2971,     1] loss: 0.0033477565739303827\n",
      "[2972,     1] loss: 0.0023735766299068928\n",
      "[2973,     1] loss: 0.0017992807552218437\n",
      "[2974,     1] loss: 0.0017704644706100225\n",
      "[2975,     1] loss: 0.002108748070895672\n",
      "[2976,     1] loss: 0.0023967986926436424\n",
      "[2977,     1] loss: 0.002504195785149932\n",
      "[2978,     1] loss: 0.0022379900328814983\n",
      "[2979,     1] loss: 0.0018856502138078213\n",
      "[2980,     1] loss: 0.0016427665250375867\n",
      "[2981,     1] loss: 0.0016167194116860628\n",
      "[2982,     1] loss: 0.001729946699924767\n",
      "[2983,     1] loss: 0.0017966185696423054\n",
      "[2984,     1] loss: 0.0017750626429915428\n",
      "[2985,     1] loss: 0.001633900566957891\n",
      "[2986,     1] loss: 0.0015109983505681157\n",
      "[2987,     1] loss: 0.0014635630650445819\n",
      "[2988,     1] loss: 0.0014835268957540393\n",
      "[2989,     1] loss: 0.0015203949296846986\n",
      "[2990,     1] loss: 0.001506267231889069\n",
      "[2991,     1] loss: 0.0014609533827751875\n",
      "[2992,     1] loss: 0.001398833584971726\n",
      "[2993,     1] loss: 0.0013718297705054283\n",
      "[2994,     1] loss: 0.0013781117741018534\n",
      "[2995,     1] loss: 0.001393892103806138\n",
      "[2996,     1] loss: 0.0013998695649206638\n",
      "[2997,     1] loss: 0.0013761038426309824\n",
      "[2998,     1] loss: 0.0013433503918349743\n",
      "[2999,     1] loss: 0.0013163802213966846\n",
      "[3000,     1] loss: 0.001308262930251658\n",
      "[3001,     1] loss: 0.0013164289994165301\n",
      "[3002,     1] loss: 0.0013248310424387455\n",
      "[3003,     1] loss: 0.001320083043538034\n",
      "[3004,     1] loss: 0.001302059623412788\n",
      "[3005,     1] loss: 0.0012823056895285845\n",
      "[3006,     1] loss: 0.001268646214157343\n",
      "[3007,     1] loss: 0.0012687280541285872\n",
      "[3008,     1] loss: 0.0012780502438545227\n",
      "[3009,     1] loss: 0.0012864329619333148\n",
      "[3010,     1] loss: 0.0012866328470408916\n",
      "[3011,     1] loss: 0.0012775883078575134\n",
      "[3012,     1] loss: 0.0012629537377506495\n",
      "[3013,     1] loss: 0.0012499038130044937\n",
      "[3014,     1] loss: 0.0012435566168278456\n",
      "[3015,     1] loss: 0.0012446953915059566\n",
      "[3016,     1] loss: 0.0012512054527178407\n",
      "[3017,     1] loss: 0.0012579188914969563\n",
      "[3018,     1] loss: 0.0012600866612046957\n",
      "[3019,     1] loss: 0.0012554541463032365\n",
      "[3020,     1] loss: 0.001247014501132071\n",
      "[3021,     1] loss: 0.0012372160563245416\n",
      "[3022,     1] loss: 0.0012309224111959338\n",
      "[3023,     1] loss: 0.0012283253017812967\n",
      "[3024,     1] loss: 0.001229609246365726\n",
      "[3025,     1] loss: 0.0012323446571826935\n",
      "[3026,     1] loss: 0.0012349302414804697\n",
      "[3027,     1] loss: 0.0012357644736766815\n",
      "[3028,     1] loss: 0.0012343634152784944\n",
      "[3029,     1] loss: 0.0012306028511375189\n",
      "[3030,     1] loss: 0.0012264458928257227\n",
      "[3031,     1] loss: 0.0012226453982293606\n",
      "[3032,     1] loss: 0.0012201747158542275\n",
      "[3033,     1] loss: 0.0012194345472380519\n",
      "[3034,     1] loss: 0.0012200732016935945\n",
      "[3035,     1] loss: 0.0012211842695251107\n",
      "[3036,     1] loss: 0.001222732593305409\n",
      "[3037,     1] loss: 0.0012237854534760118\n",
      "[3038,     1] loss: 0.0012243682285770774\n",
      "[3039,     1] loss: 0.0012236250331625342\n",
      "[3040,     1] loss: 0.0012220280477777123\n",
      "[3041,     1] loss: 0.0012201763456687331\n",
      "[3042,     1] loss: 0.0012179301120340824\n",
      "[3043,     1] loss: 0.0012155105359852314\n",
      "[3044,     1] loss: 0.0012133839773014188\n",
      "[3045,     1] loss: 0.0012121200561523438\n",
      "[3046,     1] loss: 0.0012109234230592847\n",
      "[3047,     1] loss: 0.001211017370223999\n",
      "[3048,     1] loss: 0.001211625407449901\n",
      "[3049,     1] loss: 0.0012126303045079112\n",
      "[3050,     1] loss: 0.0012139406753703952\n",
      "[3051,     1] loss: 0.001215107156895101\n",
      "[3052,     1] loss: 0.0012152581475675106\n",
      "[3053,     1] loss: 0.0012150995898991823\n",
      "[3054,     1] loss: 0.0012145633809268475\n",
      "[3055,     1] loss: 0.0012135085416957736\n",
      "[3056,     1] loss: 0.00121165974996984\n",
      "[3057,     1] loss: 0.001209374750033021\n",
      "[3058,     1] loss: 0.0012074601836502552\n",
      "[3059,     1] loss: 0.0012056651758030057\n",
      "[3060,     1] loss: 0.0012038609711453319\n",
      "[3061,     1] loss: 0.0012027719058096409\n",
      "[3062,     1] loss: 0.00120303884614259\n",
      "[3063,     1] loss: 0.001203441759571433\n",
      "[3064,     1] loss: 0.0012049677316099405\n",
      "[3065,     1] loss: 0.0012068054638803005\n",
      "[3066,     1] loss: 0.001209853682667017\n",
      "[3067,     1] loss: 0.0012140878243371844\n",
      "[3068,     1] loss: 0.001220321049913764\n",
      "[3069,     1] loss: 0.0012277179630473256\n",
      "[3070,     1] loss: 0.0012383279390633106\n",
      "[3071,     1] loss: 0.001251554349437356\n",
      "[3072,     1] loss: 0.0012702802196145058\n",
      "[3073,     1] loss: 0.0012914953986182809\n",
      "[3074,     1] loss: 0.0013208016753196716\n",
      "[3075,     1] loss: 0.0013531005242839456\n",
      "[3076,     1] loss: 0.001394905848428607\n",
      "[3077,     1] loss: 0.0014371543657034636\n",
      "[3078,     1] loss: 0.0014950304757803679\n",
      "[3079,     1] loss: 0.0015539481537416577\n",
      "[3080,     1] loss: 0.0016347819473594427\n",
      "[3081,     1] loss: 0.0016963665839284658\n",
      "[3082,     1] loss: 0.0017777979373931885\n",
      "[3083,     1] loss: 0.0018256112234666944\n",
      "[3084,     1] loss: 0.001886904938146472\n",
      "[3085,     1] loss: 0.0018977703293785453\n",
      "[3086,     1] loss: 0.0019051022827625275\n",
      "[3087,     1] loss: 0.0018551627872511744\n",
      "[3088,     1] loss: 0.0017936520744115114\n",
      "[3089,     1] loss: 0.001690653502009809\n",
      "[3090,     1] loss: 0.0015774359926581383\n",
      "[3091,     1] loss: 0.0014593475498259068\n",
      "[3092,     1] loss: 0.0013555997284129262\n",
      "[3093,     1] loss: 0.0012754087802022696\n",
      "[3094,     1] loss: 0.0012246122350916266\n",
      "[3095,     1] loss: 0.0012037184787914157\n",
      "[3096,     1] loss: 0.0012099872110411525\n",
      "[3097,     1] loss: 0.001237727701663971\n",
      "[3098,     1] loss: 0.0012783915735781193\n",
      "[3099,     1] loss: 0.0013278058031573892\n",
      "[3100,     1] loss: 0.0013769763754680753\n",
      "[3101,     1] loss: 0.001423687906935811\n",
      "[3102,     1] loss: 0.0014571156352758408\n",
      "[3103,     1] loss: 0.0014866538112983108\n",
      "[3104,     1] loss: 0.0014914546627551317\n",
      "[3105,     1] loss: 0.0014915191568434238\n",
      "[3106,     1] loss: 0.0014665329363197088\n",
      "[3107,     1] loss: 0.0014368693809956312\n",
      "[3108,     1] loss: 0.0013901590136811137\n",
      "[3109,     1] loss: 0.001346904318779707\n",
      "[3110,     1] loss: 0.0012992698466405272\n",
      "[3111,     1] loss: 0.0012593582505360246\n",
      "[3112,     1] loss: 0.0012231979053467512\n",
      "[3113,     1] loss: 0.0011979046976193786\n",
      "[3114,     1] loss: 0.0011822074884548783\n",
      "[3115,     1] loss: 0.0011761101195588708\n",
      "[3116,     1] loss: 0.001178462989628315\n",
      "[3117,     1] loss: 0.0011857803910970688\n",
      "[3118,     1] loss: 0.0011979532428085804\n",
      "[3119,     1] loss: 0.0012126283254474401\n",
      "[3120,     1] loss: 0.0012292381143197417\n",
      "[3121,     1] loss: 0.0012461269507184625\n",
      "[3122,     1] loss: 0.0012651034630835056\n",
      "[3123,     1] loss: 0.0012854791712015867\n",
      "[3124,     1] loss: 0.0013126041740179062\n",
      "[3125,     1] loss: 0.001340913469903171\n",
      "[3126,     1] loss: 0.0013771470403298736\n",
      "[3127,     1] loss: 0.0014192096423357725\n",
      "[3128,     1] loss: 0.0014861591625958681\n",
      "[3129,     1] loss: 0.0015561702894046903\n",
      "[3130,     1] loss: 0.0016761601436883211\n",
      "[3131,     1] loss: 0.001789803383871913\n",
      "[3132,     1] loss: 0.001988564617931843\n",
      "[3133,     1] loss: 0.0021443814039230347\n",
      "[3134,     1] loss: 0.002370564267039299\n",
      "[3135,     1] loss: 0.0024551828391849995\n",
      "[3136,     1] loss: 0.0025377501733601093\n",
      "[3137,     1] loss: 0.0023936075158417225\n",
      "[3138,     1] loss: 0.0021789097227156162\n",
      "[3139,     1] loss: 0.0018266311381012201\n",
      "[3140,     1] loss: 0.0015009107301011682\n",
      "[3141,     1] loss: 0.001263159909285605\n",
      "[3142,     1] loss: 0.0011801618384197354\n",
      "[3143,     1] loss: 0.00123511569108814\n",
      "[3144,     1] loss: 0.0013660069089382887\n",
      "[3145,     1] loss: 0.0015106614446267486\n",
      "[3146,     1] loss: 0.001587612903676927\n",
      "[3147,     1] loss: 0.0016040338668972254\n",
      "[3148,     1] loss: 0.0015224202070385218\n",
      "[3149,     1] loss: 0.001407973701134324\n",
      "[3150,     1] loss: 0.0012783427955582738\n",
      "[3151,     1] loss: 0.0011881666723638773\n",
      "[3152,     1] loss: 0.0011528816539794207\n",
      "[3153,     1] loss: 0.0011709511745721102\n",
      "[3154,     1] loss: 0.0012211572611704469\n",
      "[3155,     1] loss: 0.0012747893342748284\n",
      "[3156,     1] loss: 0.0013224550057202578\n",
      "[3157,     1] loss: 0.0013346727937459946\n",
      "[3158,     1] loss: 0.001329031540080905\n",
      "[3159,     1] loss: 0.0012897133128717542\n",
      "[3160,     1] loss: 0.001240743906237185\n",
      "[3161,     1] loss: 0.0011905654100701213\n",
      "[3162,     1] loss: 0.0011563258012756705\n",
      "[3163,     1] loss: 0.0011419944930821657\n",
      "[3164,     1] loss: 0.0011472217738628387\n",
      "[3165,     1] loss: 0.0011653538094833493\n",
      "[3166,     1] loss: 0.0011873866897076368\n",
      "[3167,     1] loss: 0.0012081213062629104\n",
      "[3168,     1] loss: 0.0012187390821054578\n",
      "[3169,     1] loss: 0.0012249235296621919\n",
      "[3170,     1] loss: 0.0012184684164822102\n",
      "[3171,     1] loss: 0.0012086089700460434\n",
      "[3172,     1] loss: 0.0011916938237845898\n",
      "[3173,     1] loss: 0.0011772246798500419\n",
      "[3174,     1] loss: 0.0011632725363597274\n",
      "[3175,     1] loss: 0.0011555047240108252\n",
      "[3176,     1] loss: 0.0011529624462127686\n",
      "[3177,     1] loss: 0.0011580237187445164\n",
      "[3178,     1] loss: 0.001169835333712399\n",
      "[3179,     1] loss: 0.0011894942726939917\n",
      "[3180,     1] loss: 0.0012164100771769881\n",
      "[3181,     1] loss: 0.0012542582117021084\n",
      "[3182,     1] loss: 0.0013024412328377366\n",
      "[3183,     1] loss: 0.0013654048088937998\n",
      "[3184,     1] loss: 0.0014436342753469944\n",
      "[3185,     1] loss: 0.0015414470108225942\n",
      "[3186,     1] loss: 0.0016556072514504194\n",
      "[3187,     1] loss: 0.00179126369766891\n",
      "[3188,     1] loss: 0.0019284526351839304\n",
      "[3189,     1] loss: 0.0020781406201422215\n",
      "[3190,     1] loss: 0.0022041434422135353\n",
      "[3191,     1] loss: 0.0023366541136056185\n",
      "[3192,     1] loss: 0.0023991886992007494\n",
      "[3193,     1] loss: 0.0024471047800034285\n",
      "[3194,     1] loss: 0.0024087827187031507\n",
      "[3195,     1] loss: 0.0024123997427523136\n",
      "[3196,     1] loss: 0.002336186356842518\n",
      "[3197,     1] loss: 0.0023326314985752106\n",
      "[3198,     1] loss: 0.002179749310016632\n",
      "[3199,     1] loss: 0.0019837436266243458\n",
      "[3200,     1] loss: 0.0016720377607271075\n",
      "[3201,     1] loss: 0.0013986648991703987\n",
      "[3202,     1] loss: 0.001232139184139669\n",
      "[3203,     1] loss: 0.0012305380078032613\n",
      "[3204,     1] loss: 0.0013587434077635407\n",
      "[3205,     1] loss: 0.0015181133057922125\n",
      "[3206,     1] loss: 0.0016385498456656933\n",
      "[3207,     1] loss: 0.0016289983177557588\n",
      "[3208,     1] loss: 0.0015460816211998463\n",
      "[3209,     1] loss: 0.0013780754525214434\n",
      "[3210,     1] loss: 0.0012206463143229485\n",
      "[3211,     1] loss: 0.0011272209230810404\n",
      "[3212,     1] loss: 0.001124912640079856\n",
      "[3213,     1] loss: 0.0011891145259141922\n",
      "[3214,     1] loss: 0.00126742129214108\n",
      "[3215,     1] loss: 0.0013260680716484785\n",
      "[3216,     1] loss: 0.0013311693910509348\n",
      "[3217,     1] loss: 0.001302005024626851\n",
      "[3218,     1] loss: 0.0012401352869346738\n",
      "[3219,     1] loss: 0.0011829212307929993\n",
      "[3220,     1] loss: 0.00114199158269912\n",
      "[3221,     1] loss: 0.001128719886764884\n",
      "[3222,     1] loss: 0.0011393596651032567\n",
      "[3223,     1] loss: 0.0011583961313590407\n",
      "[3224,     1] loss: 0.0011742250062525272\n",
      "[3225,     1] loss: 0.001176555291749537\n",
      "[3226,     1] loss: 0.0011708574602380395\n",
      "[3227,     1] loss: 0.0011571558425202966\n",
      "[3228,     1] loss: 0.0011481069959700108\n",
      "[3229,     1] loss: 0.001142048160545528\n",
      "[3230,     1] loss: 0.001142897759564221\n",
      "[3231,     1] loss: 0.001148141105659306\n",
      "[3232,     1] loss: 0.001153095276094973\n",
      "[3233,     1] loss: 0.0011538550024852157\n",
      "[3234,     1] loss: 0.0011484934948384762\n",
      "[3235,     1] loss: 0.0011381562799215317\n",
      "[3236,     1] loss: 0.001125080743804574\n",
      "[3237,     1] loss: 0.0011119047412648797\n",
      "[3238,     1] loss: 0.0011014094343408942\n",
      "[3239,     1] loss: 0.001096047693863511\n",
      "[3240,     1] loss: 0.0010946374386548996\n",
      "[3241,     1] loss: 0.0010975117329508066\n",
      "[3242,     1] loss: 0.0011026812717318535\n",
      "[3243,     1] loss: 0.0011084636207669973\n",
      "[3244,     1] loss: 0.0011140585411339998\n",
      "[3245,     1] loss: 0.0011184067698195577\n",
      "[3246,     1] loss: 0.001120089553296566\n",
      "[3247,     1] loss: 0.0011201300658285618\n",
      "[3248,     1] loss: 0.0011182590387761593\n",
      "[3249,     1] loss: 0.0011158253764733672\n",
      "[3250,     1] loss: 0.0011137609835714102\n",
      "[3251,     1] loss: 0.0011127499165013433\n",
      "[3252,     1] loss: 0.0011127529432997108\n",
      "[3253,     1] loss: 0.0011162121081724763\n",
      "[3254,     1] loss: 0.0011220516171306372\n",
      "[3255,     1] loss: 0.0011331818532198668\n",
      "[3256,     1] loss: 0.0011459672823548317\n",
      "[3257,     1] loss: 0.0011643643956631422\n",
      "[3258,     1] loss: 0.0011831300798803568\n",
      "[3259,     1] loss: 0.0012089647352695465\n",
      "[3260,     1] loss: 0.0012333368649706244\n",
      "[3261,     1] loss: 0.0012699051294475794\n",
      "[3262,     1] loss: 0.0013048987602815032\n",
      "[3263,     1] loss: 0.0013589749578386545\n",
      "[3264,     1] loss: 0.0014124134322628379\n",
      "[3265,     1] loss: 0.001494994037784636\n",
      "[3266,     1] loss: 0.0015710591105744243\n",
      "[3267,     1] loss: 0.0016851496184244752\n",
      "[3268,     1] loss: 0.0017816007602959871\n",
      "[3269,     1] loss: 0.001904023578390479\n",
      "[3270,     1] loss: 0.0019858169835060835\n",
      "[3271,     1] loss: 0.0020780928898602724\n",
      "[3272,     1] loss: 0.0020938441157341003\n",
      "[3273,     1] loss: 0.002083276864141226\n",
      "[3274,     1] loss: 0.0019699307158589363\n",
      "[3275,     1] loss: 0.0018136674771085382\n",
      "[3276,     1] loss: 0.0016032997518777847\n",
      "[3277,     1] loss: 0.0014020828530192375\n",
      "[3278,     1] loss: 0.0012304914416745305\n",
      "[3279,     1] loss: 0.0011241475585848093\n",
      "[3280,     1] loss: 0.0010888137621805072\n",
      "[3281,     1] loss: 0.001113754347898066\n",
      "[3282,     1] loss: 0.001176504883915186\n",
      "[3283,     1] loss: 0.0012489217333495617\n",
      "[3284,     1] loss: 0.0013156146742403507\n",
      "[3285,     1] loss: 0.0013593299081549048\n",
      "[3286,     1] loss: 0.0013836915604770184\n",
      "[3287,     1] loss: 0.0013781985035166144\n",
      "[3288,     1] loss: 0.001365960226394236\n",
      "[3289,     1] loss: 0.0013332811649888754\n",
      "[3290,     1] loss: 0.0013075652532279491\n",
      "[3291,     1] loss: 0.0012715263292193413\n",
      "[3292,     1] loss: 0.0012439507991075516\n",
      "[3293,     1] loss: 0.0012090166565030813\n",
      "[3294,     1] loss: 0.0011800832580775023\n",
      "[3295,     1] loss: 0.0011500114342197776\n",
      "[3296,     1] loss: 0.0011254596756771207\n",
      "[3297,     1] loss: 0.0011081125121563673\n",
      "[3298,     1] loss: 0.0010982789099216461\n",
      "[3299,     1] loss: 0.0010986959096044302\n",
      "[3300,     1] loss: 0.0011058258824050426\n",
      "[3301,     1] loss: 0.001117856940254569\n",
      "[3302,     1] loss: 0.001131656114012003\n",
      "[3303,     1] loss: 0.001150460448116064\n",
      "[3304,     1] loss: 0.0011680600000545382\n",
      "[3305,     1] loss: 0.0011909392196685076\n",
      "[3306,     1] loss: 0.001208453788422048\n",
      "[3307,     1] loss: 0.0012342366389930248\n",
      "[3308,     1] loss: 0.0012506264029070735\n",
      "[3309,     1] loss: 0.0012822155840694904\n",
      "[3310,     1] loss: 0.0012983882334083319\n",
      "[3311,     1] loss: 0.001325259916484356\n",
      "[3312,     1] loss: 0.0013324199244379997\n",
      "[3313,     1] loss: 0.0013442544732242823\n",
      "[3314,     1] loss: 0.0013354134280234575\n",
      "[3315,     1] loss: 0.0013368765357881784\n",
      "[3316,     1] loss: 0.0013178394874557853\n",
      "[3317,     1] loss: 0.0012993334094062448\n",
      "[3318,     1] loss: 0.0012719384394586086\n",
      "[3319,     1] loss: 0.0012509594671428204\n",
      "[3320,     1] loss: 0.0012280092341825366\n",
      "[3321,     1] loss: 0.0012125169159844518\n",
      "[3322,     1] loss: 0.0012011084472760558\n",
      "[3323,     1] loss: 0.0011949317995458841\n",
      "[3324,     1] loss: 0.0011893046321347356\n",
      "[3325,     1] loss: 0.0011829477734863758\n",
      "[3326,     1] loss: 0.0011762074427679181\n",
      "[3327,     1] loss: 0.0011655502021312714\n",
      "[3328,     1] loss: 0.0011513695353642106\n",
      "[3329,     1] loss: 0.0011340791825205088\n",
      "[3330,     1] loss: 0.001117158797569573\n",
      "[3331,     1] loss: 0.0010993221076205373\n",
      "[3332,     1] loss: 0.0010823346674442291\n",
      "[3333,     1] loss: 0.001067579723894596\n",
      "[3334,     1] loss: 0.0010559225920587778\n",
      "[3335,     1] loss: 0.0010479881893843412\n",
      "[3336,     1] loss: 0.0010430477559566498\n",
      "[3337,     1] loss: 0.0010408372618258\n",
      "[3338,     1] loss: 0.0010409355163574219\n",
      "[3339,     1] loss: 0.0010432946728542447\n",
      "[3340,     1] loss: 0.001047331839799881\n",
      "[3341,     1] loss: 0.0010527062695473433\n",
      "[3342,     1] loss: 0.001060629147104919\n",
      "[3343,     1] loss: 0.001070585218258202\n",
      "[3344,     1] loss: 0.001084076357074082\n",
      "[3345,     1] loss: 0.0011008379515260458\n",
      "[3346,     1] loss: 0.001123728696256876\n",
      "[3347,     1] loss: 0.001153315301053226\n",
      "[3348,     1] loss: 0.001195390010252595\n",
      "[3349,     1] loss: 0.0012491208035498857\n",
      "[3350,     1] loss: 0.0013304443564265966\n",
      "[3351,     1] loss: 0.0014395865146070719\n",
      "[3352,     1] loss: 0.0016131768934428692\n",
      "[3353,     1] loss: 0.001838761381804943\n",
      "[3354,     1] loss: 0.002213108353316784\n",
      "[3355,     1] loss: 0.002672277856618166\n",
      "[3356,     1] loss: 0.003478170372545719\n",
      "[3357,     1] loss: 0.0042775594629347324\n",
      "[3358,     1] loss: 0.00560674536973238\n",
      "[3359,     1] loss: 0.006287403404712677\n",
      "[3360,     1] loss: 0.0067232465371489525\n",
      "[3361,     1] loss: 0.005371249280869961\n",
      "[3362,     1] loss: 0.0034657763317227364\n",
      "[3363,     1] loss: 0.0015983771299943328\n",
      "[3364,     1] loss: 0.0010871684644371271\n",
      "[3365,     1] loss: 0.0018945566844195127\n",
      "[3366,     1] loss: 0.002974783070385456\n",
      "[3367,     1] loss: 0.0034043111372739077\n",
      "[3368,     1] loss: 0.0026466085109859705\n",
      "[3369,     1] loss: 0.0016096931649371982\n",
      "[3370,     1] loss: 0.0011057615047320724\n",
      "[3371,     1] loss: 0.0014264944475144148\n",
      "[3372,     1] loss: 0.0020202386658638716\n",
      "[3373,     1] loss: 0.0021455613896250725\n",
      "[3374,     1] loss: 0.0017736111767590046\n",
      "[3375,     1] loss: 0.001249041873961687\n",
      "[3376,     1] loss: 0.0011082031996920705\n",
      "[3377,     1] loss: 0.0013775302795693278\n",
      "[3378,     1] loss: 0.0016491168644279242\n",
      "[3379,     1] loss: 0.001639481750316918\n",
      "[3380,     1] loss: 0.001329978578723967\n",
      "[3381,     1] loss: 0.001067589153535664\n",
      "[3382,     1] loss: 0.0010745315812528133\n",
      "[3383,     1] loss: 0.0012701158411800861\n",
      "[3384,     1] loss: 0.0014156245160847902\n",
      "[3385,     1] loss: 0.0013426518999040127\n",
      "[3386,     1] loss: 0.001154010184109211\n",
      "[3387,     1] loss: 0.0010318664135411382\n",
      "[3388,     1] loss: 0.0010693888179957867\n",
      "[3389,     1] loss: 0.001181149622425437\n",
      "[3390,     1] loss: 0.0012255925685167313\n",
      "[3391,     1] loss: 0.0011719181202352047\n",
      "[3392,     1] loss: 0.0010713898809626698\n",
      "[3393,     1] loss: 0.0010241017444059253\n",
      "[3394,     1] loss: 0.0010586179560050368\n",
      "[3395,     1] loss: 0.0011187276104465127\n",
      "[3396,     1] loss: 0.001141324988566339\n",
      "[3397,     1] loss: 0.001099655986763537\n",
      "[3398,     1] loss: 0.0010421231854707003\n",
      "[3399,     1] loss: 0.0010122057283297181\n",
      "[3400,     1] loss: 0.0010279369307681918\n",
      "[3401,     1] loss: 0.0010633062338456511\n",
      "[3402,     1] loss: 0.0010784646729007363\n",
      "[3403,     1] loss: 0.0010660493280738592\n",
      "[3404,     1] loss: 0.0010348416399210691\n",
      "[3405,     1] loss: 0.0010134195908904076\n",
      "[3406,     1] loss: 0.0010155567433685064\n",
      "[3407,     1] loss: 0.001031638472341001\n",
      "[3408,     1] loss: 0.0010433788411319256\n",
      "[3409,     1] loss: 0.0010383838089182973\n",
      "[3410,     1] loss: 0.0010229795007035136\n",
      "[3411,     1] loss: 0.0010074133751913905\n",
      "[3412,     1] loss: 0.0010031887795776129\n",
      "[3413,     1] loss: 0.0010102239903062582\n",
      "[3414,     1] loss: 0.001018110429868102\n",
      "[3415,     1] loss: 0.0010200757533311844\n",
      "[3416,     1] loss: 0.0010136956116184592\n",
      "[3417,     1] loss: 0.001004933612421155\n",
      "[3418,     1] loss: 0.0010001257760450244\n",
      "[3419,     1] loss: 0.0010000347392633557\n",
      "[3420,     1] loss: 0.0010035583982244134\n",
      "[3421,     1] loss: 0.0010064021917060018\n",
      "[3422,     1] loss: 0.0010065484093502164\n",
      "[3423,     1] loss: 0.0010037538595497608\n",
      "[3424,     1] loss: 0.000999331008642912\n",
      "[3425,     1] loss: 0.0009961389005184174\n",
      "[3426,     1] loss: 0.0009950665989890695\n",
      "[3427,     1] loss: 0.0009961838368326426\n",
      "[3428,     1] loss: 0.000998354167677462\n",
      "[3429,     1] loss: 0.0010002346243709326\n",
      "[3430,     1] loss: 0.0010002856142818928\n",
      "[3431,     1] loss: 0.0009997012093663216\n",
      "[3432,     1] loss: 0.0009985417127609253\n",
      "[3433,     1] loss: 0.0009986863005906343\n",
      "[3434,     1] loss: 0.0009993601124733686\n",
      "[3435,     1] loss: 0.0010009671095758677\n",
      "[3436,     1] loss: 0.0010034944862127304\n",
      "[3437,     1] loss: 0.0010056968312710524\n",
      "[3438,     1] loss: 0.0010072533041238785\n",
      "[3439,     1] loss: 0.0010077876504510641\n",
      "[3440,     1] loss: 0.0010077781043946743\n",
      "[3441,     1] loss: 0.0010073339799419045\n",
      "[3442,     1] loss: 0.0010072044096887112\n",
      "[3443,     1] loss: 0.0010079806670546532\n",
      "[3444,     1] loss: 0.001008793362416327\n",
      "[3445,     1] loss: 0.0010103641543537378\n",
      "[3446,     1] loss: 0.0010114090982824564\n",
      "[3447,     1] loss: 0.0010133514879271388\n",
      "[3448,     1] loss: 0.0010150613961741328\n",
      "[3449,     1] loss: 0.0010172283509746194\n",
      "[3450,     1] loss: 0.001019729534164071\n",
      "[3451,     1] loss: 0.0010239072144031525\n",
      "[3452,     1] loss: 0.0010290369391441345\n",
      "[3453,     1] loss: 0.00103490031324327\n",
      "[3454,     1] loss: 0.0010420192265883088\n",
      "[3455,     1] loss: 0.0010496733011677861\n",
      "[3456,     1] loss: 0.0010579184163361788\n",
      "[3457,     1] loss: 0.001067444565705955\n",
      "[3458,     1] loss: 0.0010784214828163385\n",
      "[3459,     1] loss: 0.0010911970166489482\n",
      "[3460,     1] loss: 0.0011036614887416363\n",
      "[3461,     1] loss: 0.0011172911617904902\n",
      "[3462,     1] loss: 0.0011338487965986133\n",
      "[3463,     1] loss: 0.0011526657035574317\n",
      "[3464,     1] loss: 0.0011707472149282694\n",
      "[3465,     1] loss: 0.0011890034656971693\n",
      "[3466,     1] loss: 0.0012017562985420227\n",
      "[3467,     1] loss: 0.0012123356573283672\n",
      "[3468,     1] loss: 0.0012156075099483132\n",
      "[3469,     1] loss: 0.0012172625865787268\n",
      "[3470,     1] loss: 0.0012139546452090144\n",
      "[3471,     1] loss: 0.0012070556404069066\n",
      "[3472,     1] loss: 0.0011938941897824407\n",
      "[3473,     1] loss: 0.00117276213131845\n",
      "[3474,     1] loss: 0.0011446268763393164\n",
      "[3475,     1] loss: 0.0011121087009087205\n",
      "[3476,     1] loss: 0.0010782846948131919\n",
      "[3477,     1] loss: 0.001047413214109838\n",
      "[3478,     1] loss: 0.0010202297708019614\n",
      "[3479,     1] loss: 0.0009992012055590749\n",
      "[3480,     1] loss: 0.000984151498414576\n",
      "[3481,     1] loss: 0.0009748331503942609\n",
      "[3482,     1] loss: 0.0009705039556138217\n",
      "[3483,     1] loss: 0.0009704935364425182\n",
      "[3484,     1] loss: 0.0009732830803841352\n",
      "[3485,     1] loss: 0.000978200463578105\n",
      "[3486,     1] loss: 0.0009846064494922757\n",
      "[3487,     1] loss: 0.0009937259601429105\n",
      "[3488,     1] loss: 0.001003816956654191\n",
      "[3489,     1] loss: 0.0010153834009543061\n",
      "[3490,     1] loss: 0.001029616454616189\n",
      "[3491,     1] loss: 0.001045072334818542\n",
      "[3492,     1] loss: 0.0010623619891703129\n",
      "[3493,     1] loss: 0.0010818932205438614\n",
      "[3494,     1] loss: 0.0011052601039409637\n",
      "[3495,     1] loss: 0.0011309725232422352\n",
      "[3496,     1] loss: 0.0011598645942285657\n",
      "[3497,     1] loss: 0.0011893342016264796\n",
      "[3498,     1] loss: 0.0012224408565089107\n",
      "[3499,     1] loss: 0.001249636639840901\n",
      "[3500,     1] loss: 0.0012774326605722308\n",
      "[3501,     1] loss: 0.0012964160414412618\n",
      "[3502,     1] loss: 0.001315850531682372\n",
      "[3503,     1] loss: 0.001317777787335217\n",
      "[3504,     1] loss: 0.001311639090999961\n",
      "[3505,     1] loss: 0.0012873318046331406\n",
      "[3506,     1] loss: 0.0012543778866529465\n",
      "[3507,     1] loss: 0.0012062443420290947\n",
      "[3508,     1] loss: 0.0011589304776862264\n",
      "[3509,     1] loss: 0.001107462216168642\n",
      "[3510,     1] loss: 0.0010619777021929622\n",
      "[3511,     1] loss: 0.0010212677298113704\n",
      "[3512,     1] loss: 0.0009914154652506113\n",
      "[3513,     1] loss: 0.0009711995953693986\n",
      "[3514,     1] loss: 0.0009612939320504665\n",
      "[3515,     1] loss: 0.0009593734284862876\n",
      "[3516,     1] loss: 0.0009647507686167955\n",
      "[3517,     1] loss: 0.0009750958997756243\n",
      "[3518,     1] loss: 0.0009886659681797028\n",
      "[3519,     1] loss: 0.0010056690080091357\n",
      "[3520,     1] loss: 0.001022161915898323\n",
      "[3521,     1] loss: 0.0010410287650302052\n",
      "[3522,     1] loss: 0.0010600637178868055\n",
      "[3523,     1] loss: 0.0010801870375871658\n",
      "[3524,     1] loss: 0.0010965480469167233\n",
      "[3525,     1] loss: 0.0011161377187818289\n",
      "[3526,     1] loss: 0.0011310582049190998\n",
      "[3527,     1] loss: 0.001148860203102231\n",
      "[3528,     1] loss: 0.0011606196640059352\n",
      "[3529,     1] loss: 0.0011767474934458733\n",
      "[3530,     1] loss: 0.0011830716393887997\n",
      "[3531,     1] loss: 0.0011938659008592367\n",
      "[3532,     1] loss: 0.0011926502920687199\n",
      "[3533,     1] loss: 0.0011955515947192907\n",
      "[3534,     1] loss: 0.001186662120744586\n",
      "[3535,     1] loss: 0.001181984320282936\n",
      "[3536,     1] loss: 0.0011637057177722454\n",
      "[3537,     1] loss: 0.0011465838178992271\n",
      "[3538,     1] loss: 0.0011181539157405496\n",
      "[3539,     1] loss: 0.0010892084101215005\n",
      "[3540,     1] loss: 0.0010563654359430075\n",
      "[3541,     1] loss: 0.0010255301604047418\n",
      "[3542,     1] loss: 0.000998778734356165\n",
      "[3543,     1] loss: 0.0009796563535928726\n",
      "[3544,     1] loss: 0.0009671748266555369\n",
      "[3545,     1] loss: 0.0009615436429157853\n",
      "[3546,     1] loss: 0.0009623790392652154\n",
      "[3547,     1] loss: 0.0009685686673037708\n",
      "[3548,     1] loss: 0.0009790104813873768\n",
      "[3549,     1] loss: 0.0009912265231832862\n",
      "[3550,     1] loss: 0.001006630132906139\n",
      "[3551,     1] loss: 0.0010207714512944221\n",
      "[3552,     1] loss: 0.001044591423124075\n",
      "[3553,     1] loss: 0.0010664069559425116\n",
      "[3554,     1] loss: 0.0010987966088578105\n",
      "[3555,     1] loss: 0.001125368638895452\n",
      "[3556,     1] loss: 0.001164688030257821\n",
      "[3557,     1] loss: 0.0011947308667004108\n",
      "[3558,     1] loss: 0.0012443502200767398\n",
      "[3559,     1] loss: 0.001274437177926302\n",
      "[3560,     1] loss: 0.0013284736778587103\n",
      "[3561,     1] loss: 0.001354279462248087\n",
      "[3562,     1] loss: 0.0014110737247392535\n",
      "[3563,     1] loss: 0.0014269126113504171\n",
      "[3564,     1] loss: 0.001455805730074644\n",
      "[3565,     1] loss: 0.0014453043695539236\n",
      "[3566,     1] loss: 0.0014685624046251178\n",
      "[3567,     1] loss: 0.0014712958363816142\n",
      "[3568,     1] loss: 0.0015287077985703945\n",
      "[3569,     1] loss: 0.001587951323017478\n",
      "[3570,     1] loss: 0.001712770201265812\n",
      "[3571,     1] loss: 0.0018605450168251991\n",
      "[3572,     1] loss: 0.0020533232018351555\n",
      "[3573,     1] loss: 0.0022201435640454292\n",
      "[3574,     1] loss: 0.0023530928883701563\n",
      "[3575,     1] loss: 0.002320436295121908\n",
      "[3576,     1] loss: 0.0021174440626055002\n",
      "[3577,     1] loss: 0.0017430594889447093\n",
      "[3578,     1] loss: 0.0013280559796839952\n",
      "[3579,     1] loss: 0.001027971156872809\n",
      "[3580,     1] loss: 0.0009368964238092303\n",
      "[3581,     1] loss: 0.0010362757602706552\n",
      "[3582,     1] loss: 0.0012236349284648895\n",
      "[3583,     1] loss: 0.0013771242229267955\n",
      "[3584,     1] loss: 0.0014184416504576802\n",
      "[3585,     1] loss: 0.001334741129539907\n",
      "[3586,     1] loss: 0.001182307954877615\n",
      "[3587,     1] loss: 0.0010457229800522327\n",
      "[3588,     1] loss: 0.0009885235922411084\n",
      "[3589,     1] loss: 0.001025438541546464\n",
      "[3590,     1] loss: 0.001105972216464579\n",
      "[3591,     1] loss: 0.0011833591852337122\n",
      "[3592,     1] loss: 0.00119302561506629\n",
      "[3593,     1] loss: 0.0011483938433229923\n",
      "[3594,     1] loss: 0.0010587285505607724\n",
      "[3595,     1] loss: 0.000976724666543305\n",
      "[3596,     1] loss: 0.0009349134052172303\n",
      "[3597,     1] loss: 0.0009433672530576587\n",
      "[3598,     1] loss: 0.0009810165502130985\n",
      "[3599,     1] loss: 0.0010164834093302488\n",
      "[3600,     1] loss: 0.001028835540637374\n",
      "[3601,     1] loss: 0.001010726671665907\n",
      "[3602,     1] loss: 0.0009746094583533704\n",
      "[3603,     1] loss: 0.0009374116198159754\n",
      "[3604,     1] loss: 0.0009157494641840458\n",
      "[3605,     1] loss: 0.0009145658113993704\n",
      "[3606,     1] loss: 0.0009286602144129574\n",
      "[3607,     1] loss: 0.0009474932448938489\n",
      "[3608,     1] loss: 0.0009605442173779011\n",
      "[3609,     1] loss: 0.0009623524965718389\n",
      "[3610,     1] loss: 0.0009540448663756251\n",
      "[3611,     1] loss: 0.0009407128090970218\n",
      "[3612,     1] loss: 0.000928219873458147\n",
      "[3613,     1] loss: 0.0009226057445630431\n",
      "[3614,     1] loss: 0.0009266813285648823\n",
      "[3615,     1] loss: 0.0009375204099342227\n",
      "[3616,     1] loss: 0.000955832889303565\n",
      "[3617,     1] loss: 0.0009744479320943356\n",
      "[3618,     1] loss: 0.000997808761894703\n",
      "[3619,     1] loss: 0.001019283547066152\n",
      "[3620,     1] loss: 0.0010557292262092233\n",
      "[3621,     1] loss: 0.001096898689866066\n",
      "[3622,     1] loss: 0.0011788529809564352\n",
      "[3623,     1] loss: 0.0012769129825755954\n",
      "[3624,     1] loss: 0.0014623664319515228\n",
      "[3625,     1] loss: 0.001673743361607194\n",
      "[3626,     1] loss: 0.0020336713641881943\n",
      "[3627,     1] loss: 0.0023952871561050415\n",
      "[3628,     1] loss: 0.0029959820676594973\n",
      "[3629,     1] loss: 0.0034475193824619055\n",
      "[3630,     1] loss: 0.004120452329516411\n",
      "[3631,     1] loss: 0.00423668697476387\n",
      "[3632,     1] loss: 0.004199494607746601\n",
      "[3633,     1] loss: 0.003320887451991439\n",
      "[3634,     1] loss: 0.0022471207194030285\n",
      "[3635,     1] loss: 0.0012890425277873874\n",
      "[3636,     1] loss: 0.0009341787081211805\n",
      "[3637,     1] loss: 0.0012116186553612351\n",
      "[3638,     1] loss: 0.001760090934112668\n",
      "[3639,     1] loss: 0.0021879447158426046\n",
      "[3640,     1] loss: 0.002138483338057995\n",
      "[3641,     1] loss: 0.0017874257173389196\n",
      "[3642,     1] loss: 0.0012864635791629553\n",
      "[3643,     1] loss: 0.0009837038815021515\n",
      "[3644,     1] loss: 0.0010086259571835399\n",
      "[3645,     1] loss: 0.001235773554071784\n",
      "[3646,     1] loss: 0.0014371400466188788\n",
      "[3647,     1] loss: 0.0014453507028520107\n",
      "[3648,     1] loss: 0.0013050243724137545\n",
      "[3649,     1] loss: 0.0011033102637156844\n",
      "[3650,     1] loss: 0.000981950550340116\n",
      "[3651,     1] loss: 0.0009837269317358732\n",
      "[3652,     1] loss: 0.0010573442559689283\n",
      "[3653,     1] loss: 0.0011239838786423206\n",
      "[3654,     1] loss: 0.0011268712114542723\n",
      "[3655,     1] loss: 0.001079669571481645\n",
      "[3656,     1] loss: 0.001014825887978077\n",
      "[3657,     1] loss: 0.0009740249370224774\n",
      "[3658,     1] loss: 0.0009673384483903646\n",
      "[3659,     1] loss: 0.0009795877849683166\n",
      "[3660,     1] loss: 0.0009906801860779524\n",
      "[3661,     1] loss: 0.0009853763040155172\n",
      "[3662,     1] loss: 0.0009733075276017189\n",
      "[3663,     1] loss: 0.0009567034430801868\n",
      "[3664,     1] loss: 0.0009455383406020701\n",
      "[3665,     1] loss: 0.0009401247370988131\n",
      "[3666,     1] loss: 0.0009368723258376122\n",
      "[3667,     1] loss: 0.000933073228225112\n",
      "[3668,     1] loss: 0.0009251664741896093\n",
      "[3669,     1] loss: 0.0009183853399008512\n",
      "[3670,     1] loss: 0.0009135414729826152\n",
      "[3671,     1] loss: 0.0009132412960752845\n",
      "[3672,     1] loss: 0.0009168165852315724\n",
      "[3673,     1] loss: 0.0009203866356983781\n",
      "[3674,     1] loss: 0.0009190271957777441\n",
      "[3675,     1] loss: 0.0009124300559051335\n",
      "[3676,     1] loss: 0.0009025009931065142\n",
      "[3677,     1] loss: 0.00089234858751297\n",
      "[3678,     1] loss: 0.0008861140813678503\n",
      "[3679,     1] loss: 0.0008850450394675136\n",
      "[3680,     1] loss: 0.00088878208771348\n",
      "[3681,     1] loss: 0.0008944706642068923\n",
      "[3682,     1] loss: 0.0008996074320748448\n",
      "[3683,     1] loss: 0.0009004052262753248\n",
      "[3684,     1] loss: 0.0008970737690106034\n",
      "[3685,     1] loss: 0.0008907480514608324\n",
      "[3686,     1] loss: 0.0008838538196869195\n",
      "[3687,     1] loss: 0.0008781480137258768\n",
      "[3688,     1] loss: 0.0008753611473366618\n",
      "[3689,     1] loss: 0.0008755942108109593\n",
      "[3690,     1] loss: 0.0008777202456258237\n",
      "[3691,     1] loss: 0.000880759209394455\n",
      "[3692,     1] loss: 0.0008832383318804204\n",
      "[3693,     1] loss: 0.000884351902641356\n",
      "[3694,     1] loss: 0.0008835800690576434\n",
      "[3695,     1] loss: 0.00088140630396083\n",
      "[3696,     1] loss: 0.0008785055833868682\n",
      "[3697,     1] loss: 0.0008749843691475689\n",
      "[3698,     1] loss: 0.0008719734032638371\n",
      "[3699,     1] loss: 0.0008702997001819313\n",
      "[3700,     1] loss: 0.0008691013208590448\n",
      "[3701,     1] loss: 0.0008685842039994895\n",
      "[3702,     1] loss: 0.0008683386258780956\n",
      "[3703,     1] loss: 0.0008687782101333141\n",
      "[3704,     1] loss: 0.000868516624905169\n",
      "[3705,     1] loss: 0.0008686091750860214\n",
      "[3706,     1] loss: 0.0008682814077474177\n",
      "[3707,     1] loss: 0.0008681084145791829\n",
      "[3708,     1] loss: 0.0008684059139341116\n",
      "[3709,     1] loss: 0.0008681376930326223\n",
      "[3710,     1] loss: 0.0008675753488205373\n",
      "[3711,     1] loss: 0.0008672296535223722\n",
      "[3712,     1] loss: 0.0008667433285154402\n",
      "[3713,     1] loss: 0.0008661823812872171\n",
      "[3714,     1] loss: 0.0008658180013298988\n",
      "[3715,     1] loss: 0.0008651770185679197\n",
      "[3716,     1] loss: 0.0008640636224299669\n",
      "[3717,     1] loss: 0.0008632062235847116\n",
      "[3718,     1] loss: 0.00086243636906147\n",
      "[3719,     1] loss: 0.0008615716360509396\n",
      "[3720,     1] loss: 0.0008606301853433251\n",
      "[3721,     1] loss: 0.0008602802408859134\n",
      "[3722,     1] loss: 0.0008600499713793397\n",
      "[3723,     1] loss: 0.0008603243622928858\n",
      "[3724,     1] loss: 0.0008608317002654076\n",
      "[3725,     1] loss: 0.0008617894491180778\n",
      "[3726,     1] loss: 0.0008632959797978401\n",
      "[3727,     1] loss: 0.0008653042023070157\n",
      "[3728,     1] loss: 0.0008682443294674158\n",
      "[3729,     1] loss: 0.0008725840016268194\n",
      "[3730,     1] loss: 0.0008785359677858651\n",
      "[3731,     1] loss: 0.0008875870262272656\n",
      "[3732,     1] loss: 0.0008991539943963289\n",
      "[3733,     1] loss: 0.0009156215819530189\n",
      "[3734,     1] loss: 0.0009350845939479768\n",
      "[3735,     1] loss: 0.0009642436634749174\n",
      "[3736,     1] loss: 0.0009980418253690004\n",
      "[3737,     1] loss: 0.0010533002205193043\n",
      "[3738,     1] loss: 0.001114935614168644\n",
      "[3739,     1] loss: 0.0012068592477589846\n",
      "[3740,     1] loss: 0.0013033382128924131\n",
      "[3741,     1] loss: 0.00145327381324023\n",
      "[3742,     1] loss: 0.001595381647348404\n",
      "[3743,     1] loss: 0.0017966738669201732\n",
      "[3744,     1] loss: 0.0019592815078794956\n",
      "[3745,     1] loss: 0.002187546109780669\n",
      "[3746,     1] loss: 0.0022975648753345013\n",
      "[3747,     1] loss: 0.002412437926977873\n",
      "[3748,     1] loss: 0.0023117566015571356\n",
      "[3749,     1] loss: 0.002137179486453533\n",
      "[3750,     1] loss: 0.0017862704116851091\n",
      "[3751,     1] loss: 0.0014246393693611026\n",
      "[3752,     1] loss: 0.0010924013331532478\n",
      "[3753,     1] loss: 0.0008940617553889751\n",
      "[3754,     1] loss: 0.0008622820023447275\n",
      "[3755,     1] loss: 0.0009621527278795838\n",
      "[3756,     1] loss: 0.0011220087762922049\n",
      "[3757,     1] loss: 0.0012581734918057919\n",
      "[3758,     1] loss: 0.0013334974646568298\n",
      "[3759,     1] loss: 0.0013094291789457202\n",
      "[3760,     1] loss: 0.0012262652162462473\n",
      "[3761,     1] loss: 0.0010952233569696546\n",
      "[3762,     1] loss: 0.0009687800193205476\n",
      "[3763,     1] loss: 0.0008811578736640513\n",
      "[3764,     1] loss: 0.0008513715583831072\n",
      "[3765,     1] loss: 0.0008721612975932658\n",
      "[3766,     1] loss: 0.0009217850747518241\n",
      "[3767,     1] loss: 0.0009755442733876407\n",
      "[3768,     1] loss: 0.0010107222478836775\n",
      "[3769,     1] loss: 0.0010304051684215665\n",
      "[3770,     1] loss: 0.0010178794618695974\n",
      "[3771,     1] loss: 0.0009932905668392777\n",
      "[3772,     1] loss: 0.0009514980483800173\n",
      "[3773,     1] loss: 0.0009080545278266072\n",
      "[3774,     1] loss: 0.0008707818342372775\n",
      "[3775,     1] loss: 0.0008475894574075937\n",
      "[3776,     1] loss: 0.0008403221145272255\n",
      "[3777,     1] loss: 0.0008454944472759962\n",
      "[3778,     1] loss: 0.0008597230771556497\n",
      "[3779,     1] loss: 0.000877360173035413\n",
      "[3780,     1] loss: 0.0008959115366451442\n",
      "[3781,     1] loss: 0.0009095316054299474\n",
      "[3782,     1] loss: 0.000922173960134387\n",
      "[3783,     1] loss: 0.0009251898154616356\n",
      "[3784,     1] loss: 0.000927492103073746\n",
      "[3785,     1] loss: 0.0009214597521349788\n",
      "[3786,     1] loss: 0.000914270814973861\n",
      "[3787,     1] loss: 0.0009003462037071586\n",
      "[3788,     1] loss: 0.0008866339339874685\n",
      "[3789,     1] loss: 0.0008708155364729464\n",
      "[3790,     1] loss: 0.0008558129193261266\n",
      "[3791,     1] loss: 0.000843551941215992\n",
      "[3792,     1] loss: 0.0008354390738531947\n",
      "[3793,     1] loss: 0.0008313022553920746\n",
      "[3794,     1] loss: 0.0008302070200443268\n",
      "[3795,     1] loss: 0.0008319871267303824\n",
      "[3796,     1] loss: 0.0008352062432095408\n",
      "[3797,     1] loss: 0.0008401678060181439\n",
      "[3798,     1] loss: 0.000845659407787025\n",
      "[3799,     1] loss: 0.000853554520290345\n",
      "[3800,     1] loss: 0.0008613958489149809\n",
      "[3801,     1] loss: 0.0008709052344784141\n",
      "[3802,     1] loss: 0.0008803526870906353\n",
      "[3803,     1] loss: 0.0008975124801509082\n",
      "[3804,     1] loss: 0.0009151003323495388\n",
      "[3805,     1] loss: 0.0009420430869795382\n",
      "[3806,     1] loss: 0.0009701115777716041\n",
      "[3807,     1] loss: 0.0010190709726884961\n",
      "[3808,     1] loss: 0.0010672479402273893\n",
      "[3809,     1] loss: 0.0011373002780601382\n",
      "[3810,     1] loss: 0.0012004413874819875\n",
      "[3811,     1] loss: 0.0013092928566038609\n",
      "[3812,     1] loss: 0.0013985349796712399\n",
      "[3813,     1] loss: 0.0015277272323146462\n",
      "[3814,     1] loss: 0.0016040371265262365\n",
      "[3815,     1] loss: 0.0017093997448682785\n",
      "[3816,     1] loss: 0.0017143937293440104\n",
      "[3817,     1] loss: 0.0016972374869510531\n",
      "[3818,     1] loss: 0.0015556237194687128\n",
      "[3819,     1] loss: 0.0013733174419030547\n",
      "[3820,     1] loss: 0.0011525852605700493\n",
      "[3821,     1] loss: 0.0009761310648173094\n",
      "[3822,     1] loss: 0.0008708147797733545\n",
      "[3823,     1] loss: 0.0008537018438801169\n",
      "[3824,     1] loss: 0.0009074286208488047\n",
      "[3825,     1] loss: 0.0009948168881237507\n",
      "[3826,     1] loss: 0.0010859544854611158\n",
      "[3827,     1] loss: 0.0011431088205426931\n",
      "[3828,     1] loss: 0.001184079796075821\n",
      "[3829,     1] loss: 0.001170387607999146\n",
      "[3830,     1] loss: 0.0011456325883045793\n",
      "[3831,     1] loss: 0.0010921033099293709\n",
      "[3832,     1] loss: 0.0010507486294955015\n",
      "[3833,     1] loss: 0.0010326521005481482\n",
      "[3834,     1] loss: 0.0010572378523647785\n",
      "[3835,     1] loss: 0.0011196997947990894\n",
      "[3836,     1] loss: 0.0012159786419942975\n",
      "[3837,     1] loss: 0.0013122474774718285\n",
      "[3838,     1] loss: 0.00139145040884614\n",
      "[3839,     1] loss: 0.0014309107791632414\n",
      "[3840,     1] loss: 0.0014406307600438595\n",
      "[3841,     1] loss: 0.0014043115079402924\n",
      "[3842,     1] loss: 0.0013465126976370811\n",
      "[3843,     1] loss: 0.0012815792579203844\n",
      "[3844,     1] loss: 0.0012464502360671759\n",
      "[3845,     1] loss: 0.0012244486715644598\n",
      "[3846,     1] loss: 0.001243520062416792\n",
      "[3847,     1] loss: 0.0012522394536063075\n",
      "[3848,     1] loss: 0.0012880240101367235\n",
      "[3849,     1] loss: 0.0012768949382007122\n",
      "[3850,     1] loss: 0.0012655338505282998\n",
      "[3851,     1] loss: 0.001193388132378459\n",
      "[3852,     1] loss: 0.0011104964651167393\n",
      "[3853,     1] loss: 0.0010076849721372128\n",
      "[3854,     1] loss: 0.0009204619564116001\n",
      "[3855,     1] loss: 0.0008684289641678333\n",
      "[3856,     1] loss: 0.0008566489559598267\n",
      "[3857,     1] loss: 0.0008725249790586531\n",
      "[3858,     1] loss: 0.0008977240649983287\n",
      "[3859,     1] loss: 0.0009154355502687395\n",
      "[3860,     1] loss: 0.0009156791493296623\n",
      "[3861,     1] loss: 0.0009035809198394418\n",
      "[3862,     1] loss: 0.0008790894062258303\n",
      "[3863,     1] loss: 0.000853912380989641\n",
      "[3864,     1] loss: 0.0008355826139450073\n",
      "[3865,     1] loss: 0.0008310364210046828\n",
      "[3866,     1] loss: 0.0008395335753448308\n",
      "[3867,     1] loss: 0.0008577294647693634\n",
      "[3868,     1] loss: 0.0008766648825258017\n",
      "[3869,     1] loss: 0.0008896796498447657\n",
      "[3870,     1] loss: 0.000895176490303129\n",
      "[3871,     1] loss: 0.0008905270951800048\n",
      "[3872,     1] loss: 0.000881458749063313\n",
      "[3873,     1] loss: 0.0008706958033144474\n",
      "[3874,     1] loss: 0.0008635815465822816\n",
      "[3875,     1] loss: 0.0008645194466225803\n",
      "[3876,     1] loss: 0.0008747291867621243\n",
      "[3877,     1] loss: 0.0008956713136285543\n",
      "[3878,     1] loss: 0.0009218576597049832\n",
      "[3879,     1] loss: 0.000963790575042367\n",
      "[3880,     1] loss: 0.001010459614917636\n",
      "[3881,     1] loss: 0.0010879188776016235\n",
      "[3882,     1] loss: 0.0011699172900989652\n",
      "[3883,     1] loss: 0.0013018313329666853\n",
      "[3884,     1] loss: 0.0014373838203027844\n",
      "[3885,     1] loss: 0.0016538617201149464\n",
      "[3886,     1] loss: 0.0018635380547493696\n",
      "[3887,     1] loss: 0.0022136392071843147\n",
      "[3888,     1] loss: 0.0024901877623051405\n",
      "[3889,     1] loss: 0.0028870846144855022\n",
      "[3890,     1] loss: 0.0030563808977603912\n",
      "[3891,     1] loss: 0.0031672476325184107\n",
      "[3892,     1] loss: 0.002860954962670803\n",
      "[3893,     1] loss: 0.0023875408805906773\n",
      "[3894,     1] loss: 0.001705368049442768\n",
      "[3895,     1] loss: 0.0011262003099545836\n",
      "[3896,     1] loss: 0.0008253188570961356\n",
      "[3897,     1] loss: 0.0008633577963337302\n",
      "[3898,     1] loss: 0.001128174364566803\n",
      "[3899,     1] loss: 0.001422027125954628\n",
      "[3900,     1] loss: 0.0015858091646805406\n",
      "[3901,     1] loss: 0.0015278884675353765\n",
      "[3902,     1] loss: 0.0013145324774086475\n",
      "[3903,     1] loss: 0.0010413299314677715\n",
      "[3904,     1] loss: 0.0008453234913758934\n",
      "[3905,     1] loss: 0.000794159946963191\n",
      "[3906,     1] loss: 0.0008719129837118089\n",
      "[3907,     1] loss: 0.00100510916672647\n",
      "[3908,     1] loss: 0.001111009856685996\n",
      "[3909,     1] loss: 0.0011436024215072393\n",
      "[3910,     1] loss: 0.0010868486715480685\n",
      "[3911,     1] loss: 0.0009878046112135053\n",
      "[3912,     1] loss: 0.0008775671594776213\n",
      "[3913,     1] loss: 0.000804646871984005\n",
      "[3914,     1] loss: 0.000789179524872452\n",
      "[3915,     1] loss: 0.0008215428679250181\n",
      "[3916,     1] loss: 0.0008748463587835431\n",
      "[3917,     1] loss: 0.0009191906428895891\n",
      "[3918,     1] loss: 0.0009377264068461955\n",
      "[3919,     1] loss: 0.0009201029897667468\n",
      "[3920,     1] loss: 0.0008827857673168182\n",
      "[3921,     1] loss: 0.0008375470642931759\n",
      "[3922,     1] loss: 0.0008022888796404004\n",
      "[3923,     1] loss: 0.0007847505039535463\n",
      "[3924,     1] loss: 0.0007859948091208935\n",
      "[3925,     1] loss: 0.0008004518458619714\n",
      "[3926,     1] loss: 0.0008193360990844667\n",
      "[3927,     1] loss: 0.0008355588652193546\n",
      "[3928,     1] loss: 0.0008420008234679699\n",
      "[3929,     1] loss: 0.000839839456602931\n",
      "[3930,     1] loss: 0.0008295226143673062\n",
      "[3931,     1] loss: 0.0008162755984812975\n",
      "[3932,     1] loss: 0.0008018328808248043\n",
      "[3933,     1] loss: 0.0007907029357738793\n",
      "[3934,     1] loss: 0.0007833861745893955\n",
      "[3935,     1] loss: 0.0007807828951627016\n",
      "[3936,     1] loss: 0.0007818574085831642\n",
      "[3937,     1] loss: 0.0007855640724301338\n",
      "[3938,     1] loss: 0.0007897860486991704\n",
      "[3939,     1] loss: 0.0007929354324005544\n",
      "[3940,     1] loss: 0.0007958661881275475\n",
      "[3941,     1] loss: 0.000795818108599633\n",
      "[3942,     1] loss: 0.0007947224075905979\n",
      "[3943,     1] loss: 0.0007929177954792976\n",
      "[3944,     1] loss: 0.0007910506101325154\n",
      "[3945,     1] loss: 0.0007890085107646883\n",
      "[3946,     1] loss: 0.0007881991914473474\n",
      "[3947,     1] loss: 0.0007869768887758255\n",
      "[3948,     1] loss: 0.0007865650113672018\n",
      "[3949,     1] loss: 0.0007858905009925365\n",
      "[3950,     1] loss: 0.0007854801369830966\n",
      "[3951,     1] loss: 0.0007842570194043219\n",
      "[3952,     1] loss: 0.0007841902552172542\n",
      "[3953,     1] loss: 0.0007822879706509411\n",
      "[3954,     1] loss: 0.0007808799855411053\n",
      "[3955,     1] loss: 0.0007790123345330358\n",
      "[3956,     1] loss: 0.0007776349084451795\n",
      "[3957,     1] loss: 0.0007752752862870693\n",
      "[3958,     1] loss: 0.0007730863289907575\n",
      "[3959,     1] loss: 0.0007710052304901183\n",
      "[3960,     1] loss: 0.0007692087674513459\n",
      "[3961,     1] loss: 0.0007679587579332292\n",
      "[3962,     1] loss: 0.0007668955950066447\n",
      "[3963,     1] loss: 0.0007658380782231688\n",
      "[3964,     1] loss: 0.0007652627537027001\n",
      "[3965,     1] loss: 0.000765216420404613\n",
      "[3966,     1] loss: 0.0007644584402441978\n",
      "[3967,     1] loss: 0.000764481897931546\n",
      "[3968,     1] loss: 0.000764655414968729\n",
      "[3969,     1] loss: 0.0007647647871635854\n",
      "[3970,     1] loss: 0.0007655007066205144\n",
      "[3971,     1] loss: 0.0007664073491469026\n",
      "[3972,     1] loss: 0.0007675488013774157\n",
      "[3973,     1] loss: 0.0007695156964473426\n",
      "[3974,     1] loss: 0.0007728692726232111\n",
      "[3975,     1] loss: 0.0007780271116644144\n",
      "[3976,     1] loss: 0.0007858419558033347\n",
      "[3977,     1] loss: 0.0007982015376910567\n",
      "[3978,     1] loss: 0.0008143302984535694\n",
      "[3979,     1] loss: 0.000841754546854645\n",
      "[3980,     1] loss: 0.0008779205963946879\n",
      "[3981,     1] loss: 0.0009419774869456887\n",
      "[3982,     1] loss: 0.001023355987854302\n",
      "[3983,     1] loss: 0.001162730623036623\n",
      "[3984,     1] loss: 0.0013343817554414272\n",
      "[3985,     1] loss: 0.0016412842087447643\n",
      "[3986,     1] loss: 0.0019981074146926403\n",
      "[3987,     1] loss: 0.002611050847917795\n",
      "[3988,     1] loss: 0.0032009973656386137\n",
      "[3989,     1] loss: 0.004205373581498861\n",
      "[3990,     1] loss: 0.00472207460552454\n",
      "[3991,     1] loss: 0.005271465051919222\n",
      "[3992,     1] loss: 0.004571206402033567\n",
      "[3993,     1] loss: 0.0034158723428845406\n",
      "[3994,     1] loss: 0.0017952155321836472\n",
      "[3995,     1] loss: 0.0008695696014910936\n",
      "[3996,     1] loss: 0.000997573253698647\n",
      "[3997,     1] loss: 0.001774672302417457\n",
      "[3998,     1] loss: 0.0024659675545990467\n",
      "[3999,     1] loss: 0.002380965743213892\n",
      "[4000,     1] loss: 0.0017871554009616375\n",
      "[4001,     1] loss: 0.001052655978128314\n",
      "[4002,     1] loss: 0.0008035426144488156\n",
      "[4003,     1] loss: 0.0011057956144213676\n",
      "[4004,     1] loss: 0.0015286877751350403\n",
      "[4005,     1] loss: 0.0016787115018814802\n",
      "[4006,     1] loss: 0.00136720878072083\n",
      "[4007,     1] loss: 0.0009578343597240746\n",
      "[4008,     1] loss: 0.0007646989542990923\n",
      "[4009,     1] loss: 0.0008979575359262526\n",
      "[4010,     1] loss: 0.0011480709072202444\n",
      "[4011,     1] loss: 0.0012326071737334132\n",
      "[4012,     1] loss: 0.001122745219618082\n",
      "[4013,     1] loss: 0.0008949390612542629\n",
      "[4014,     1] loss: 0.000761686242185533\n",
      "[4015,     1] loss: 0.0008075646474026144\n",
      "[4016,     1] loss: 0.0009405877790413797\n",
      "[4017,     1] loss: 0.0010228343307971954\n",
      "[4018,     1] loss: 0.0009680464281700552\n",
      "[4019,     1] loss: 0.0008524487493559718\n",
      "[4020,     1] loss: 0.0007626815349794924\n",
      "[4021,     1] loss: 0.0007634316571056843\n",
      "[4022,     1] loss: 0.0008304580114781857\n",
      "[4023,     1] loss: 0.0008832440944388509\n",
      "[4024,     1] loss: 0.0008821511873975396\n",
      "[4025,     1] loss: 0.0008239427697844803\n",
      "[4026,     1] loss: 0.0007651990163139999\n",
      "[4027,     1] loss: 0.0007479898631572723\n",
      "[4028,     1] loss: 0.0007742993766441941\n",
      "[4029,     1] loss: 0.000811185163911432\n",
      "[4030,     1] loss: 0.0008214814588427544\n",
      "[4031,     1] loss: 0.0008033590856939554\n",
      "[4032,     1] loss: 0.0007687404286116362\n",
      "[4033,     1] loss: 0.0007445861119776964\n",
      "[4034,     1] loss: 0.0007445047376677394\n",
      "[4035,     1] loss: 0.0007612783811055124\n",
      "[4036,     1] loss: 0.0007772859535180032\n",
      "[4037,     1] loss: 0.0007783275214023888\n",
      "[4038,     1] loss: 0.0007673394866287708\n",
      "[4039,     1] loss: 0.0007504523964598775\n",
      "[4040,     1] loss: 0.0007393334526568651\n",
      "[4041,     1] loss: 0.0007396044675260782\n",
      "[4042,     1] loss: 0.0007474343292415142\n",
      "[4043,     1] loss: 0.0007562636164948344\n",
      "[4044,     1] loss: 0.00075796979945153\n",
      "[4045,     1] loss: 0.000754175940528512\n",
      "[4046,     1] loss: 0.0007462491048499942\n",
      "[4047,     1] loss: 0.0007392007973976433\n",
      "[4048,     1] loss: 0.0007364813354797661\n",
      "[4049,     1] loss: 0.0007385966018773615\n",
      "[4050,     1] loss: 0.0007433725986629725\n",
      "[4051,     1] loss: 0.0007478292682208121\n",
      "[4052,     1] loss: 0.0007510234718210995\n",
      "[4053,     1] loss: 0.0007519291248172522\n",
      "[4054,     1] loss: 0.000753308180719614\n",
      "[4055,     1] loss: 0.0007564002880826592\n",
      "[4056,     1] loss: 0.0007632625056430697\n",
      "[4057,     1] loss: 0.0007757500861771405\n",
      "[4058,     1] loss: 0.000792880542576313\n",
      "[4059,     1] loss: 0.0008182278252206743\n",
      "[4060,     1] loss: 0.0008483101846650243\n",
      "[4061,     1] loss: 0.00088582030730322\n",
      "[4062,     1] loss: 0.0009313097689300776\n",
      "[4063,     1] loss: 0.0009888546774163842\n",
      "[4064,     1] loss: 0.0010662029962986708\n",
      "[4065,     1] loss: 0.0011565323220565915\n",
      "[4066,     1] loss: 0.0012656889157369733\n",
      "[4067,     1] loss: 0.0013728574849665165\n",
      "[4068,     1] loss: 0.0014907203149050474\n",
      "[4069,     1] loss: 0.0015745137352496386\n",
      "[4070,     1] loss: 0.0016151925083249807\n",
      "[4071,     1] loss: 0.0015712652821093798\n",
      "[4072,     1] loss: 0.001469550421461463\n",
      "[4073,     1] loss: 0.0012883582385256886\n",
      "[4074,     1] loss: 0.0010804882040247321\n",
      "[4075,     1] loss: 0.000892038457095623\n",
      "[4076,     1] loss: 0.0007687647012062371\n",
      "[4077,     1] loss: 0.0007280976860783994\n",
      "[4078,     1] loss: 0.0007589309825561941\n",
      "[4079,     1] loss: 0.0008330234559252858\n",
      "[4080,     1] loss: 0.0009153387509286404\n",
      "[4081,     1] loss: 0.000976496608927846\n",
      "[4082,     1] loss: 0.0009975711582228541\n",
      "[4083,     1] loss: 0.000975566916167736\n",
      "[4084,     1] loss: 0.0009191983845084906\n",
      "[4085,     1] loss: 0.000847981427796185\n",
      "[4086,     1] loss: 0.0007824971107766032\n",
      "[4087,     1] loss: 0.0007387999794445932\n",
      "[4088,     1] loss: 0.0007226030575111508\n",
      "[4089,     1] loss: 0.0007310818182304502\n",
      "[4090,     1] loss: 0.0007554549956694245\n",
      "[4091,     1] loss: 0.0007855701842345297\n",
      "[4092,     1] loss: 0.0008116783574223518\n",
      "[4093,     1] loss: 0.0008283589268103242\n",
      "[4094,     1] loss: 0.0008331690332852304\n",
      "[4095,     1] loss: 0.0008251415565609932\n",
      "[4096,     1] loss: 0.0008090228657238185\n",
      "[4097,     1] loss: 0.0007877417956478894\n",
      "[4098,     1] loss: 0.000764750933740288\n",
      "[4099,     1] loss: 0.0007444955408573151\n",
      "[4100,     1] loss: 0.0007297085248865187\n",
      "[4101,     1] loss: 0.0007214682991616428\n",
      "[4102,     1] loss: 0.00071921810740605\n",
      "[4103,     1] loss: 0.0007215292425826192\n",
      "[4104,     1] loss: 0.0007274935487657785\n",
      "[4105,     1] loss: 0.0007348177023231983\n",
      "[4106,     1] loss: 0.0007415753789246082\n",
      "[4107,     1] loss: 0.0007477577310055494\n",
      "[4108,     1] loss: 0.0007535711047239602\n",
      "[4109,     1] loss: 0.0007580207311548293\n",
      "[4110,     1] loss: 0.0007606694125570357\n",
      "[4111,     1] loss: 0.0007627095328643918\n",
      "[4112,     1] loss: 0.0007635443471372128\n",
      "[4113,     1] loss: 0.0007636424852535129\n",
      "[4114,     1] loss: 0.0007617209921590984\n",
      "[4115,     1] loss: 0.0007592601468786597\n",
      "[4116,     1] loss: 0.0007553627365268767\n",
      "[4117,     1] loss: 0.0007514425669796765\n",
      "[4118,     1] loss: 0.0007464659283868968\n",
      "[4119,     1] loss: 0.0007422568160109222\n",
      "[4120,     1] loss: 0.0007371396059170365\n",
      "[4121,     1] loss: 0.0007322442252188921\n",
      "[4122,     1] loss: 0.00072822580114007\n",
      "[4123,     1] loss: 0.0007247846224345267\n",
      "[4124,     1] loss: 0.0007219207473099232\n",
      "[4125,     1] loss: 0.0007199959363788366\n",
      "[4126,     1] loss: 0.0007191086770035326\n",
      "[4127,     1] loss: 0.0007189661264419556\n",
      "[4128,     1] loss: 0.0007196429651230574\n",
      "[4129,     1] loss: 0.0007209426257759333\n",
      "[4130,     1] loss: 0.000723597826436162\n",
      "[4131,     1] loss: 0.0007265082094818354\n",
      "[4132,     1] loss: 0.0007311769295483828\n",
      "[4133,     1] loss: 0.0007360218442045152\n",
      "[4134,     1] loss: 0.0007432454731315374\n",
      "[4135,     1] loss: 0.0007501334184780717\n",
      "[4136,     1] loss: 0.0007583397091366351\n",
      "[4137,     1] loss: 0.0007665995508432388\n",
      "[4138,     1] loss: 0.0007776988204568624\n",
      "[4139,     1] loss: 0.0007899809861555696\n",
      "[4140,     1] loss: 0.0008049450698308647\n",
      "[4141,     1] loss: 0.0008246279321610928\n",
      "[4142,     1] loss: 0.0008527545724064112\n",
      "[4143,     1] loss: 0.0008900378015823662\n",
      "[4144,     1] loss: 0.0009371581254526973\n",
      "[4145,     1] loss: 0.0010089140851050615\n",
      "[4146,     1] loss: 0.0010945047251880169\n",
      "[4147,     1] loss: 0.001212364761158824\n",
      "[4148,     1] loss: 0.001340407645329833\n",
      "[4149,     1] loss: 0.0015294281765818596\n",
      "[4150,     1] loss: 0.0017073542112484574\n",
      "[4151,     1] loss: 0.0019355665426701307\n",
      "[4152,     1] loss: 0.002093022223562002\n",
      "[4153,     1] loss: 0.002319399733096361\n",
      "[4154,     1] loss: 0.0023558642715215683\n",
      "[4155,     1] loss: 0.0024021295830607414\n",
      "[4156,     1] loss: 0.00216992711648345\n",
      "[4157,     1] loss: 0.0018767709843814373\n",
      "[4158,     1] loss: 0.0014334442093968391\n",
      "[4159,     1] loss: 0.0010581654496490955\n",
      "[4160,     1] loss: 0.0008089572074823081\n",
      "[4161,     1] loss: 0.0007612153422087431\n",
      "[4162,     1] loss: 0.0008855503983795643\n",
      "[4163,     1] loss: 0.0010830278042703867\n",
      "[4164,     1] loss: 0.0012485664337873459\n",
      "[4165,     1] loss: 0.0012951483950018883\n",
      "[4166,     1] loss: 0.0012440173886716366\n",
      "[4167,     1] loss: 0.0010846882360056043\n",
      "[4168,     1] loss: 0.0009095807326957583\n",
      "[4169,     1] loss: 0.0007652826025150716\n",
      "[4170,     1] loss: 0.0007016290910542011\n",
      "[4171,     1] loss: 0.0007210669573396444\n",
      "[4172,     1] loss: 0.0007926867692731321\n",
      "[4173,     1] loss: 0.0008735688752494752\n",
      "[4174,     1] loss: 0.0009236446348950267\n",
      "[4175,     1] loss: 0.000942676910199225\n",
      "[4176,     1] loss: 0.000908878049813211\n",
      "[4177,     1] loss: 0.0008544759475626051\n",
      "[4178,     1] loss: 0.0007864951039664447\n",
      "[4179,     1] loss: 0.000730458355974406\n",
      "[4180,     1] loss: 0.0007001591729931533\n",
      "[4181,     1] loss: 0.0006987839005887508\n",
      "[4182,     1] loss: 0.0007189632160589099\n",
      "[4183,     1] loss: 0.0007467055111192167\n",
      "[4184,     1] loss: 0.0007752068340778351\n",
      "[4185,     1] loss: 0.0007898070616647601\n",
      "[4186,     1] loss: 0.0007975357002578676\n",
      "[4187,     1] loss: 0.0007870355038903654\n",
      "[4188,     1] loss: 0.0007717409753240645\n",
      "[4189,     1] loss: 0.0007474056328646839\n",
      "[4190,     1] loss: 0.0007235294906422496\n",
      "[4191,     1] loss: 0.0007037022151052952\n",
      "[4192,     1] loss: 0.0006916595157235861\n",
      "[4193,     1] loss: 0.0006881963345222175\n",
      "[4194,     1] loss: 0.0006911028176546097\n",
      "[4195,     1] loss: 0.0006985614891164005\n",
      "[4196,     1] loss: 0.0007073961314745247\n",
      "[4197,     1] loss: 0.0007171222241595387\n",
      "[4198,     1] loss: 0.000724246259778738\n",
      "[4199,     1] loss: 0.0007331690285354853\n",
      "[4200,     1] loss: 0.0007381117320619524\n",
      "[4201,     1] loss: 0.0007417610613629222\n",
      "[4202,     1] loss: 0.0007403688505291939\n",
      "[4203,     1] loss: 0.0007425940129905939\n",
      "[4204,     1] loss: 0.0007404682110063732\n",
      "[4205,     1] loss: 0.0007417630986310542\n",
      "[4206,     1] loss: 0.0007398226880468428\n",
      "[4207,     1] loss: 0.0007377015426754951\n",
      "[4208,     1] loss: 0.0007347434875555336\n",
      "[4209,     1] loss: 0.0007364189950749278\n",
      "[4210,     1] loss: 0.0007387767545878887\n",
      "[4211,     1] loss: 0.0007469976553693414\n",
      "[4212,     1] loss: 0.0007562474347651005\n",
      "[4213,     1] loss: 0.0007720714202150702\n",
      "[4214,     1] loss: 0.0007895213784649968\n",
      "[4215,     1] loss: 0.000812568876426667\n",
      "[4216,     1] loss: 0.0008380995132029057\n",
      "[4217,     1] loss: 0.0008685232605785131\n",
      "[4218,     1] loss: 0.0009008384076878428\n",
      "[4219,     1] loss: 0.0009329019812867045\n",
      "[4220,     1] loss: 0.0009645845275372267\n",
      "[4221,     1] loss: 0.00099348952062428\n",
      "[4222,     1] loss: 0.0010172284673899412\n",
      "[4223,     1] loss: 0.0010297888657078147\n",
      "[4224,     1] loss: 0.001032186090014875\n",
      "[4225,     1] loss: 0.0010191767942160368\n",
      "[4226,     1] loss: 0.000998817034997046\n",
      "[4227,     1] loss: 0.0009670497965998948\n",
      "[4228,     1] loss: 0.0009346629958599806\n",
      "[4229,     1] loss: 0.0009003074374049902\n",
      "[4230,     1] loss: 0.0008851304301060736\n",
      "[4231,     1] loss: 0.0008788779960013926\n",
      "[4232,     1] loss: 0.0009041302255354822\n",
      "[4233,     1] loss: 0.0009368353057652712\n",
      "[4234,     1] loss: 0.0010178325464949012\n",
      "[4235,     1] loss: 0.0010972913587465882\n",
      "[4236,     1] loss: 0.0012263362295925617\n",
      "[4237,     1] loss: 0.001324787619523704\n",
      "[4238,     1] loss: 0.0014637045096606016\n",
      "[4239,     1] loss: 0.0015200553461909294\n",
      "[4240,     1] loss: 0.0015692883171141148\n",
      "[4241,     1] loss: 0.0014932147460058331\n",
      "[4242,     1] loss: 0.0013750703074038029\n",
      "[4243,     1] loss: 0.0011645416961982846\n",
      "[4244,     1] loss: 0.0009650826686993241\n",
      "[4245,     1] loss: 0.0007966677658259869\n",
      "[4246,     1] loss: 0.0007095017936080694\n",
      "[4247,     1] loss: 0.0007097691996023059\n",
      "[4248,     1] loss: 0.0007734725950285792\n",
      "[4249,     1] loss: 0.0008612391538918018\n",
      "[4250,     1] loss: 0.0009293542243540287\n",
      "[4251,     1] loss: 0.0009703283431008458\n",
      "[4252,     1] loss: 0.0009527072543278337\n",
      "[4253,     1] loss: 0.0009092582622542977\n",
      "[4254,     1] loss: 0.0008316326420754194\n",
      "[4255,     1] loss: 0.0007585292332805693\n",
      "[4256,     1] loss: 0.0007082768715918064\n",
      "[4257,     1] loss: 0.0006954609416425228\n",
      "[4258,     1] loss: 0.000716182985343039\n",
      "[4259,     1] loss: 0.0007560127414762974\n",
      "[4260,     1] loss: 0.0007977738277986646\n",
      "[4261,     1] loss: 0.0008254370768554509\n",
      "[4262,     1] loss: 0.0008364812820218503\n",
      "[4263,     1] loss: 0.0008233330445364118\n",
      "[4264,     1] loss: 0.0007953749736770988\n",
      "[4265,     1] loss: 0.0007571261376142502\n",
      "[4266,     1] loss: 0.0007228294271044433\n",
      "[4267,     1] loss: 0.0006999073084443808\n",
      "[4268,     1] loss: 0.0006925408961251378\n",
      "[4269,     1] loss: 0.0007007418898865581\n",
      "[4270,     1] loss: 0.0007186204893514514\n",
      "[4271,     1] loss: 0.0007470979471690953\n",
      "[4272,     1] loss: 0.0007724667666479945\n",
      "[4273,     1] loss: 0.0008080826373770833\n",
      "[4274,     1] loss: 0.0008332891156896949\n",
      "[4275,     1] loss: 0.0008691155817359686\n",
      "[4276,     1] loss: 0.0008946959860622883\n",
      "[4277,     1] loss: 0.0009402038995176554\n",
      "[4278,     1] loss: 0.0009839336853474379\n",
      "[4279,     1] loss: 0.0010787610663101077\n",
      "[4280,     1] loss: 0.00117823900654912\n",
      "[4281,     1] loss: 0.001342692645266652\n",
      "[4282,     1] loss: 0.0015108137158676982\n",
      "[4283,     1] loss: 0.0017879379447549582\n",
      "[4284,     1] loss: 0.002031085779890418\n",
      "[4285,     1] loss: 0.002312846016138792\n",
      "[4286,     1] loss: 0.0024576117284595966\n",
      "[4287,     1] loss: 0.002658493584021926\n",
      "[4288,     1] loss: 0.0025657406076788902\n",
      "[4289,     1] loss: 0.002346683293581009\n",
      "[4290,     1] loss: 0.0018895049579441547\n",
      "[4291,     1] loss: 0.0014318176545202732\n",
      "[4292,     1] loss: 0.0010410899994894862\n",
      "[4293,     1] loss: 0.0008442115504294634\n",
      "[4294,     1] loss: 0.0008455311181023717\n",
      "[4295,     1] loss: 0.0009797048987820745\n",
      "[4296,     1] loss: 0.0011423446703702211\n",
      "[4297,     1] loss: 0.001242790836840868\n",
      "[4298,     1] loss: 0.0012501801829785109\n",
      "[4299,     1] loss: 0.001152333803474903\n",
      "[4300,     1] loss: 0.001022379961796105\n",
      "[4301,     1] loss: 0.0008818109636195004\n",
      "[4302,     1] loss: 0.0007891112472862005\n",
      "[4303,     1] loss: 0.0007515207980759442\n",
      "[4304,     1] loss: 0.0007670093327760696\n",
      "[4305,     1] loss: 0.0008122134022414684\n",
      "[4306,     1] loss: 0.0008586132316850126\n",
      "[4307,     1] loss: 0.0008820726070553064\n",
      "[4308,     1] loss: 0.0008702899212948978\n",
      "[4309,     1] loss: 0.0008369027054868639\n",
      "[4310,     1] loss: 0.0007850563852116466\n",
      "[4311,     1] loss: 0.0007441170164383948\n",
      "[4312,     1] loss: 0.0007122568786144257\n",
      "[4313,     1] loss: 0.0006980682956054807\n",
      "[4314,     1] loss: 0.0007001446792855859\n",
      "[4315,     1] loss: 0.0007116759661585093\n",
      "[4316,     1] loss: 0.0007239476544782519\n",
      "[4317,     1] loss: 0.0007305385661311448\n",
      "[4318,     1] loss: 0.0007334640249609947\n",
      "[4319,     1] loss: 0.0007293869275599718\n",
      "[4320,     1] loss: 0.0007286059553734958\n",
      "[4321,     1] loss: 0.000723986653611064\n",
      "[4322,     1] loss: 0.0007245243759825826\n",
      "[4323,     1] loss: 0.0007174813072197139\n",
      "[4324,     1] loss: 0.000704005011357367\n",
      "[4325,     1] loss: 0.0006858475971966982\n",
      "[4326,     1] loss: 0.0006685664993710816\n",
      "[4327,     1] loss: 0.0006559069734066725\n",
      "[4328,     1] loss: 0.0006508526857942343\n",
      "[4329,     1] loss: 0.0006539855967275798\n",
      "[4330,     1] loss: 0.000662857317365706\n",
      "[4331,     1] loss: 0.0006736349314451218\n",
      "[4332,     1] loss: 0.0006823877338320017\n",
      "[4333,     1] loss: 0.0006889384239912033\n",
      "[4334,     1] loss: 0.0006899788277223706\n",
      "[4335,     1] loss: 0.0006901189917698503\n",
      "[4336,     1] loss: 0.0006857099942862988\n",
      "[4337,     1] loss: 0.0006830437923781574\n",
      "[4338,     1] loss: 0.0006779505638405681\n",
      "[4339,     1] loss: 0.0006730112945660949\n",
      "[4340,     1] loss: 0.0006678180652670562\n",
      "[4341,     1] loss: 0.000663398823235184\n",
      "[4342,     1] loss: 0.0006596019375137985\n",
      "[4343,     1] loss: 0.000657368334941566\n",
      "[4344,     1] loss: 0.0006560906767845154\n",
      "[4345,     1] loss: 0.0006556588341481984\n",
      "[4346,     1] loss: 0.0006557087763212621\n",
      "[4347,     1] loss: 0.0006561634945683181\n",
      "[4348,     1] loss: 0.0006558386376127601\n",
      "[4349,     1] loss: 0.0006550682010129094\n",
      "[4350,     1] loss: 0.0006536067230626941\n",
      "[4351,     1] loss: 0.0006516507128253579\n",
      "[4352,     1] loss: 0.0006497480208054185\n",
      "[4353,     1] loss: 0.0006480431766249239\n",
      "[4354,     1] loss: 0.0006463912432081997\n",
      "[4355,     1] loss: 0.0006443794118240476\n",
      "[4356,     1] loss: 0.0006426339386962354\n",
      "[4357,     1] loss: 0.0006416267715394497\n",
      "[4358,     1] loss: 0.0006407800246961415\n",
      "[4359,     1] loss: 0.0006406566826626658\n",
      "[4360,     1] loss: 0.0006407563341781497\n",
      "[4361,     1] loss: 0.000641626538708806\n",
      "[4362,     1] loss: 0.0006426153122447431\n",
      "[4363,     1] loss: 0.0006446369807235897\n",
      "[4364,     1] loss: 0.0006476675625890493\n",
      "[4365,     1] loss: 0.0006534449639730155\n",
      "[4366,     1] loss: 0.0006623661029152572\n",
      "[4367,     1] loss: 0.0006799938855692744\n",
      "[4368,     1] loss: 0.0007059219642542303\n",
      "[4369,     1] loss: 0.0007547684945166111\n",
      "[4370,     1] loss: 0.0008241065661422908\n",
      "[4371,     1] loss: 0.0009503213805146515\n",
      "[4372,     1] loss: 0.001122330198995769\n",
      "[4373,     1] loss: 0.00145891890861094\n",
      "[4374,     1] loss: 0.0018974966369569302\n",
      "[4375,     1] loss: 0.0026917336508631706\n",
      "[4376,     1] loss: 0.0035881418734788895\n",
      "[4377,     1] loss: 0.005183569621294737\n",
      "[4378,     1] loss: 0.00634673610329628\n",
      "[4379,     1] loss: 0.007680765353143215\n",
      "[4380,     1] loss: 0.006679486483335495\n",
      "[4381,     1] loss: 0.004715934861451387\n",
      "[4382,     1] loss: 0.0020182260777801275\n",
      "[4383,     1] loss: 0.0008855107007548213\n",
      "[4384,     1] loss: 0.0017142286524176598\n",
      "[4385,     1] loss: 0.0030598314478993416\n",
      "[4386,     1] loss: 0.0034928242675960064\n",
      "[4387,     1] loss: 0.0023187354672700167\n",
      "[4388,     1] loss: 0.0010575123596936464\n",
      "[4389,     1] loss: 0.0008855729829519987\n",
      "[4390,     1] loss: 0.0016820731107145548\n",
      "[4391,     1] loss: 0.0022704382427036762\n",
      "[4392,     1] loss: 0.001804895349778235\n",
      "[4393,     1] loss: 0.0009766457369551063\n",
      "[4394,     1] loss: 0.0006743044359609485\n",
      "[4395,     1] loss: 0.0011025599669665098\n",
      "[4396,     1] loss: 0.0015508868964388967\n",
      "[4397,     1] loss: 0.0013881272170692682\n",
      "[4398,     1] loss: 0.0009113188716582954\n",
      "[4399,     1] loss: 0.0006570769473910332\n",
      "[4400,     1] loss: 0.0008531180792488158\n",
      "[4401,     1] loss: 0.0011205316986888647\n",
      "[4402,     1] loss: 0.001060778391547501\n",
      "[4403,     1] loss: 0.0007957630441524088\n",
      "[4404,     1] loss: 0.0006487412611022592\n",
      "[4405,     1] loss: 0.0007616306538693607\n",
      "[4406,     1] loss: 0.0009225156391039491\n",
      "[4407,     1] loss: 0.0008949120528995991\n",
      "[4408,     1] loss: 0.00073707674164325\n",
      "[4409,     1] loss: 0.0006350993644446135\n",
      "[4410,     1] loss: 0.0006885866168886423\n",
      "[4411,     1] loss: 0.0007900989730842412\n",
      "[4412,     1] loss: 0.0007920525385998189\n",
      "[4413,     1] loss: 0.0007115262560546398\n",
      "[4414,     1] loss: 0.0006387431640177965\n",
      "[4415,     1] loss: 0.0006508812657557428\n",
      "[4416,     1] loss: 0.0007090114522725344\n",
      "[4417,     1] loss: 0.0007251298520714045\n",
      "[4418,     1] loss: 0.0006858004489913583\n",
      "[4419,     1] loss: 0.0006360325496643782\n",
      "[4420,     1] loss: 0.0006302679539658129\n",
      "[4421,     1] loss: 0.0006622587679885328\n",
      "[4422,     1] loss: 0.0006830670172348619\n",
      "[4423,     1] loss: 0.0006688063149340451\n",
      "[4424,     1] loss: 0.0006374813383445144\n",
      "[4425,     1] loss: 0.0006238814676180482\n",
      "[4426,     1] loss: 0.0006367639871314168\n",
      "[4427,     1] loss: 0.0006537684239447117\n",
      "[4428,     1] loss: 0.0006533224368467927\n",
      "[4429,     1] loss: 0.0006366058951243758\n",
      "[4430,     1] loss: 0.0006222517695277929\n",
      "[4431,     1] loss: 0.0006229468272067606\n",
      "[4432,     1] loss: 0.0006338752573356032\n",
      "[4433,     1] loss: 0.0006401739083230495\n",
      "[4434,     1] loss: 0.0006351169431582093\n",
      "[4435,     1] loss: 0.000624417734798044\n",
      "[4436,     1] loss: 0.0006182659417390823\n",
      "[4437,     1] loss: 0.000620631966739893\n",
      "[4438,     1] loss: 0.0006261257803998888\n",
      "[4439,     1] loss: 0.0006279321387410164\n",
      "[4440,     1] loss: 0.0006251453305594623\n",
      "[4441,     1] loss: 0.0006191164720803499\n",
      "[4442,     1] loss: 0.0006159187760204077\n",
      "[4443,     1] loss: 0.0006172200082801282\n",
      "[4444,     1] loss: 0.0006203081575222313\n",
      "[4445,     1] loss: 0.0006226404220797122\n",
      "[4446,     1] loss: 0.0006214353488758206\n",
      "[4447,     1] loss: 0.0006177341565489769\n",
      "[4448,     1] loss: 0.000614614924415946\n",
      "[4449,     1] loss: 0.000614275224506855\n",
      "[4450,     1] loss: 0.0006160459597595036\n",
      "[4451,     1] loss: 0.0006172170396894217\n",
      "[4452,     1] loss: 0.0006171185523271561\n",
      "[4453,     1] loss: 0.0006152702262625098\n",
      "[4454,     1] loss: 0.0006133476854301989\n",
      "[4455,     1] loss: 0.0006123576895333827\n",
      "[4456,     1] loss: 0.0006126826629042625\n",
      "[4457,     1] loss: 0.0006137778400443494\n",
      "[4458,     1] loss: 0.000614605494774878\n",
      "[4459,     1] loss: 0.0006149366963654757\n",
      "[4460,     1] loss: 0.0006145001389086246\n",
      "[4461,     1] loss: 0.0006142953643575311\n",
      "[4462,     1] loss: 0.0006145588122308254\n",
      "[4463,     1] loss: 0.0006153950816951692\n",
      "[4464,     1] loss: 0.0006172348512336612\n",
      "[4465,     1] loss: 0.0006191433640196919\n",
      "[4466,     1] loss: 0.0006206390680745244\n",
      "[4467,     1] loss: 0.0006228163838386536\n",
      "[4468,     1] loss: 0.0006254678592085838\n",
      "[4469,     1] loss: 0.000629482907243073\n",
      "[4470,     1] loss: 0.0006350476178340614\n",
      "[4471,     1] loss: 0.000641348771750927\n",
      "[4472,     1] loss: 0.0006481556920334697\n",
      "[4473,     1] loss: 0.0006559198955073953\n",
      "[4474,     1] loss: 0.0006636675680056214\n",
      "[4475,     1] loss: 0.000672386318910867\n",
      "[4476,     1] loss: 0.000682569807395339\n",
      "[4477,     1] loss: 0.0006970443646423519\n",
      "[4478,     1] loss: 0.0007145952549763024\n",
      "[4479,     1] loss: 0.0007332664681598544\n",
      "[4480,     1] loss: 0.0007535566110163927\n",
      "[4481,     1] loss: 0.000773920095525682\n",
      "[4482,     1] loss: 0.0007948305574245751\n",
      "[4483,     1] loss: 0.0008139621932059526\n",
      "[4484,     1] loss: 0.000834502512589097\n",
      "[4485,     1] loss: 0.0008531187195330858\n",
      "[4486,     1] loss: 0.000867929367814213\n",
      "[4487,     1] loss: 0.0008763208170421422\n",
      "[4488,     1] loss: 0.0008796692127361894\n",
      "[4489,     1] loss: 0.0008704537758603692\n",
      "[4490,     1] loss: 0.0008504888392053545\n",
      "[4491,     1] loss: 0.0008208650397136807\n",
      "[4492,     1] loss: 0.0007827578810974956\n",
      "[4493,     1] loss: 0.0007408580277115107\n",
      "[4494,     1] loss: 0.0007003275095485151\n",
      "[4495,     1] loss: 0.0006639845087192953\n",
      "[4496,     1] loss: 0.000635435339063406\n",
      "[4497,     1] loss: 0.0006158023024909198\n",
      "[4498,     1] loss: 0.0006049760850146413\n",
      "[4499,     1] loss: 0.0006013544043526053\n",
      "[4500,     1] loss: 0.0006035759579390287\n",
      "[4501,     1] loss: 0.0006103135528974235\n",
      "[4502,     1] loss: 0.0006202260265126824\n",
      "[4503,     1] loss: 0.0006322881090454757\n",
      "[4504,     1] loss: 0.0006464264588430524\n",
      "[4505,     1] loss: 0.0006624649395234883\n",
      "[4506,     1] loss: 0.0006794003420509398\n",
      "[4507,     1] loss: 0.0006975381402298808\n",
      "[4508,     1] loss: 0.0007169164018705487\n",
      "[4509,     1] loss: 0.0007390865357592702\n",
      "[4510,     1] loss: 0.0007625630823895335\n",
      "[4511,     1] loss: 0.0007885094964876771\n",
      "[4512,     1] loss: 0.0008106617024168372\n",
      "[4513,     1] loss: 0.0008304450893774629\n",
      "[4514,     1] loss: 0.0008418307406827807\n",
      "[4515,     1] loss: 0.0008495160145685077\n",
      "[4516,     1] loss: 0.000849991396535188\n",
      "[4517,     1] loss: 0.0008496185764670372\n",
      "[4518,     1] loss: 0.0008402687963098288\n",
      "[4519,     1] loss: 0.0008242091862484813\n",
      "[4520,     1] loss: 0.0007992633036337793\n",
      "[4521,     1] loss: 0.000768466736190021\n",
      "[4522,     1] loss: 0.0007348274812102318\n",
      "[4523,     1] loss: 0.0007000301266089082\n",
      "[4524,     1] loss: 0.0006668474525213242\n",
      "[4525,     1] loss: 0.0006386727327480912\n",
      "[4526,     1] loss: 0.0006170172127895057\n",
      "[4527,     1] loss: 0.0006023857276886702\n",
      "[4528,     1] loss: 0.0005942727439105511\n",
      "[4529,     1] loss: 0.000591491989325732\n",
      "[4530,     1] loss: 0.0005925543955527246\n",
      "[4531,     1] loss: 0.0005959618138149381\n",
      "[4532,     1] loss: 0.0006011164514347911\n",
      "[4533,     1] loss: 0.0006077013094909489\n",
      "[4534,     1] loss: 0.0006162765203043818\n",
      "[4535,     1] loss: 0.0006266656564548612\n",
      "[4536,     1] loss: 0.000640322919934988\n",
      "[4537,     1] loss: 0.0006567473756149411\n",
      "[4538,     1] loss: 0.0006781465490348637\n",
      "[4539,     1] loss: 0.0007050714921206236\n",
      "[4540,     1] loss: 0.0007394477725028992\n",
      "[4541,     1] loss: 0.0007774578989483416\n",
      "[4542,     1] loss: 0.0008289291872642934\n",
      "[4543,     1] loss: 0.0008846714626997709\n",
      "[4544,     1] loss: 0.0009596766321919858\n",
      "[4545,     1] loss: 0.0010372479446232319\n",
      "[4546,     1] loss: 0.0011269227834418416\n",
      "[4547,     1] loss: 0.0012012298684567213\n",
      "[4548,     1] loss: 0.001263548736460507\n",
      "[4549,     1] loss: 0.00128651293925941\n",
      "[4550,     1] loss: 0.0012909662909805775\n",
      "[4551,     1] loss: 0.0012405699817463756\n",
      "[4552,     1] loss: 0.0011501286644488573\n",
      "[4553,     1] loss: 0.0010205631842836738\n",
      "[4554,     1] loss: 0.0008881394751369953\n",
      "[4555,     1] loss: 0.0007651234045624733\n",
      "[4556,     1] loss: 0.000676969822961837\n",
      "[4557,     1] loss: 0.0006258974899537861\n",
      "[4558,     1] loss: 0.0006154929869808257\n",
      "[4559,     1] loss: 0.0006313106860034168\n",
      "[4560,     1] loss: 0.0006633523153141141\n",
      "[4561,     1] loss: 0.0006995481671765447\n",
      "[4562,     1] loss: 0.0007331025553867221\n",
      "[4563,     1] loss: 0.0007571845781058073\n",
      "[4564,     1] loss: 0.0007698736153542995\n",
      "[4565,     1] loss: 0.0007713895756751299\n",
      "[4566,     1] loss: 0.0007583948317915201\n",
      "[4567,     1] loss: 0.0007405816577374935\n",
      "[4568,     1] loss: 0.0007111827726475894\n",
      "[4569,     1] loss: 0.0006853542290627956\n",
      "[4570,     1] loss: 0.0006557799642905593\n",
      "[4571,     1] loss: 0.000631668430287391\n",
      "[4572,     1] loss: 0.0006103214691393077\n",
      "[4573,     1] loss: 0.0005958318361081183\n",
      "[4574,     1] loss: 0.0005885259597562253\n",
      "[4575,     1] loss: 0.0005885637365281582\n",
      "[4576,     1] loss: 0.0005949213518761098\n",
      "[4577,     1] loss: 0.0006073054973967373\n",
      "[4578,     1] loss: 0.0006218150374479592\n",
      "[4579,     1] loss: 0.0006369142211042345\n",
      "[4580,     1] loss: 0.0006555928266607225\n",
      "[4581,     1] loss: 0.0006718943477608263\n",
      "[4582,     1] loss: 0.0006920184823684394\n",
      "[4583,     1] loss: 0.0007067109690979123\n",
      "[4584,     1] loss: 0.000727702456060797\n",
      "[4585,     1] loss: 0.0007424857467412949\n",
      "[4586,     1] loss: 0.0007617922383360565\n",
      "[4587,     1] loss: 0.0007706931792199612\n",
      "[4588,     1] loss: 0.0007857134332880378\n",
      "[4589,     1] loss: 0.0007907024119049311\n",
      "[4590,     1] loss: 0.0007987624267116189\n",
      "[4591,     1] loss: 0.0007952630403451622\n",
      "[4592,     1] loss: 0.0007929091225378215\n",
      "[4593,     1] loss: 0.0007813796401023865\n",
      "[4594,     1] loss: 0.000768197001889348\n",
      "[4595,     1] loss: 0.0007508008275181055\n",
      "[4596,     1] loss: 0.0007329569198191166\n",
      "[4597,     1] loss: 0.0007144788396544755\n",
      "[4598,     1] loss: 0.0006968470988795161\n",
      "[4599,     1] loss: 0.00067823042627424\n",
      "[4600,     1] loss: 0.0006601273780688643\n",
      "[4601,     1] loss: 0.0006426099571399391\n",
      "[4602,     1] loss: 0.0006259034271351993\n",
      "[4603,     1] loss: 0.0006110870162956417\n",
      "[4604,     1] loss: 0.0005982498405501246\n",
      "[4605,     1] loss: 0.0005878309020772576\n",
      "[4606,     1] loss: 0.0005801870720461011\n",
      "[4607,     1] loss: 0.000575259851757437\n",
      "[4608,     1] loss: 0.0005725528462789953\n",
      "[4609,     1] loss: 0.0005714355502277613\n",
      "[4610,     1] loss: 0.0005715562147088349\n",
      "[4611,     1] loss: 0.0005730252014473081\n",
      "[4612,     1] loss: 0.0005757331382483244\n",
      "[4613,     1] loss: 0.0005795041215606034\n",
      "[4614,     1] loss: 0.000584567547775805\n",
      "[4615,     1] loss: 0.0005908990860916674\n",
      "[4616,     1] loss: 0.0005985361058264971\n",
      "[4617,     1] loss: 0.0006085812929086387\n",
      "[4618,     1] loss: 0.0006221480434760451\n",
      "[4619,     1] loss: 0.0006406464381143451\n",
      "[4620,     1] loss: 0.0006658908096142113\n",
      "[4621,     1] loss: 0.0007014034781605005\n",
      "[4622,     1] loss: 0.0007491069263778627\n",
      "[4623,     1] loss: 0.0008169031934812665\n",
      "[4624,     1] loss: 0.0009052201639860868\n",
      "[4625,     1] loss: 0.0010594294872134924\n",
      "[4626,     1] loss: 0.0012545608915388584\n",
      "[4627,     1] loss: 0.0015907443594187498\n",
      "[4628,     1] loss: 0.001993867103010416\n",
      "[4629,     1] loss: 0.002701967488974333\n",
      "[4630,     1] loss: 0.003435439895838499\n",
      "[4631,     1] loss: 0.004649197682738304\n",
      "[4632,     1] loss: 0.005376671440899372\n",
      "[4633,     1] loss: 0.006199182011187077\n",
      "[4634,     1] loss: 0.005464822985231876\n",
      "[4635,     1] loss: 0.004106391221284866\n",
      "[4636,     1] loss: 0.0020254827104508877\n",
      "[4637,     1] loss: 0.0007812873809598386\n",
      "[4638,     1] loss: 0.000976655399426818\n",
      "[4639,     1] loss: 0.002059007529169321\n",
      "[4640,     1] loss: 0.002906257752329111\n",
      "[4641,     1] loss: 0.002591976895928383\n",
      "[4642,     1] loss: 0.0015810860786587\n",
      "[4643,     1] loss: 0.0007099721115082502\n",
      "[4644,     1] loss: 0.0007123690447770059\n",
      "[4645,     1] loss: 0.0013398248702287674\n",
      "[4646,     1] loss: 0.0017774810548871756\n",
      "[4647,     1] loss: 0.0016579519724473357\n",
      "[4648,     1] loss: 0.0010602433467283845\n",
      "[4649,     1] loss: 0.0006262667011469603\n",
      "[4650,     1] loss: 0.0006998998578637838\n",
      "[4651,     1] loss: 0.0010543973185122013\n",
      "[4652,     1] loss: 0.0012675818288698792\n",
      "[4653,     1] loss: 0.0010888184187933803\n",
      "[4654,     1] loss: 0.0007525329710915685\n",
      "[4655,     1] loss: 0.0005887343431822956\n",
      "[4656,     1] loss: 0.000707880244590342\n",
      "[4657,     1] loss: 0.0009144525392912328\n",
      "[4658,     1] loss: 0.0009517715079709888\n",
      "[4659,     1] loss: 0.0008091818308457732\n",
      "[4660,     1] loss: 0.0006242564413696527\n",
      "[4661,     1] loss: 0.0005791715229861438\n",
      "[4662,     1] loss: 0.000676562252920121\n",
      "[4663,     1] loss: 0.0007766250055283308\n",
      "[4664,     1] loss: 0.000780796050094068\n",
      "[4665,     1] loss: 0.0006794068613089621\n",
      "[4666,     1] loss: 0.0005852932226844132\n",
      "[4667,     1] loss: 0.0005720893386751413\n",
      "[4668,     1] loss: 0.0006293863989412785\n",
      "[4669,     1] loss: 0.0006813840591348708\n",
      "[4670,     1] loss: 0.0006725440616719425\n",
      "[4671,     1] loss: 0.0006211198633536696\n",
      "[4672,     1] loss: 0.0005705992225557566\n",
      "[4673,     1] loss: 0.0005632363609038293\n",
      "[4674,     1] loss: 0.0005932825733907521\n",
      "[4675,     1] loss: 0.000621346989646554\n",
      "[4676,     1] loss: 0.0006217416375875473\n",
      "[4677,     1] loss: 0.0005941074341535568\n",
      "[4678,     1] loss: 0.0005653166444972157\n",
      "[4679,     1] loss: 0.0005574377137236297\n",
      "[4680,     1] loss: 0.0005707893287763\n",
      "[4681,     1] loss: 0.000587953079957515\n",
      "[4682,     1] loss: 0.0005915684159845114\n",
      "[4683,     1] loss: 0.0005817930796183646\n",
      "[4684,     1] loss: 0.0005650262464769185\n",
      "[4685,     1] loss: 0.0005549060297198594\n",
      "[4686,     1] loss: 0.0005566487088799477\n",
      "[4687,     1] loss: 0.0005654706619679928\n",
      "[4688,     1] loss: 0.0005738071631640196\n",
      "[4689,     1] loss: 0.0005740702035836875\n",
      "[4690,     1] loss: 0.000568258052226156\n",
      "[4691,     1] loss: 0.0005588816129602492\n",
      "[4692,     1] loss: 0.0005533595103770494\n",
      "[4693,     1] loss: 0.0005535439122468233\n",
      "[4694,     1] loss: 0.0005575337563641369\n",
      "[4695,     1] loss: 0.0005612311069853604\n",
      "[4696,     1] loss: 0.0005609921645373106\n",
      "[4697,     1] loss: 0.0005572158261202276\n",
      "[4698,     1] loss: 0.0005527125322259963\n",
      "[4699,     1] loss: 0.0005498456885106862\n",
      "[4700,     1] loss: 0.0005498286336660385\n",
      "[4701,     1] loss: 0.0005515216616913676\n",
      "[4702,     1] loss: 0.0005538302939385176\n",
      "[4703,     1] loss: 0.000554832920897752\n",
      "[4704,     1] loss: 0.0005547466571442783\n",
      "[4705,     1] loss: 0.0005526446620933712\n",
      "[4706,     1] loss: 0.0005503371357917786\n",
      "[4707,     1] loss: 0.0005483045824803412\n",
      "[4708,     1] loss: 0.0005483172135427594\n",
      "[4709,     1] loss: 0.0005490019684657454\n",
      "[4710,     1] loss: 0.0005504174623638391\n",
      "[4711,     1] loss: 0.000551095581613481\n",
      "[4712,     1] loss: 0.0005510538467206061\n",
      "[4713,     1] loss: 0.0005504367290996015\n",
      "[4714,     1] loss: 0.0005499040125869215\n",
      "[4715,     1] loss: 0.0005497747915796936\n",
      "[4716,     1] loss: 0.0005503019201569259\n",
      "[4717,     1] loss: 0.000551944540347904\n",
      "[4718,     1] loss: 0.0005552201764658093\n",
      "[4719,     1] loss: 0.0005591571098193526\n",
      "[4720,     1] loss: 0.0005637147696688771\n",
      "[4721,     1] loss: 0.000568209623452276\n",
      "[4722,     1] loss: 0.0005743638030253351\n",
      "[4723,     1] loss: 0.0005804705433547497\n",
      "[4724,     1] loss: 0.0005891077453270555\n",
      "[4725,     1] loss: 0.0005983956507407129\n",
      "[4726,     1] loss: 0.0006099854363128543\n",
      "[4727,     1] loss: 0.0006220888462848961\n",
      "[4728,     1] loss: 0.0006372069474309683\n",
      "[4729,     1] loss: 0.0006523951306007802\n",
      "[4730,     1] loss: 0.0006694920593872666\n",
      "[4731,     1] loss: 0.0006839313427917659\n",
      "[4732,     1] loss: 0.0006973373820073903\n",
      "[4733,     1] loss: 0.0007070833817124367\n",
      "[4734,     1] loss: 0.0007176456274464726\n",
      "[4735,     1] loss: 0.0007213212666101754\n",
      "[4736,     1] loss: 0.0007211200427263975\n",
      "[4737,     1] loss: 0.000711619621142745\n",
      "[4738,     1] loss: 0.0006985621294006705\n",
      "[4739,     1] loss: 0.0006779556861147285\n",
      "[4740,     1] loss: 0.0006583053036592901\n",
      "[4741,     1] loss: 0.0006344934226945043\n",
      "[4742,     1] loss: 0.0006102976622059941\n",
      "[4743,     1] loss: 0.0005879075033590198\n",
      "[4744,     1] loss: 0.0005696081789210439\n",
      "[4745,     1] loss: 0.0005561080179177225\n",
      "[4746,     1] loss: 0.0005470699979923666\n",
      "[4747,     1] loss: 0.0005422081449069083\n",
      "[4748,     1] loss: 0.0005403378745540977\n",
      "[4749,     1] loss: 0.000541175133548677\n",
      "[4750,     1] loss: 0.0005440610693767667\n",
      "[4751,     1] loss: 0.0005496412632055581\n",
      "[4752,     1] loss: 0.0005573000526055694\n",
      "[4753,     1] loss: 0.0005689573008567095\n",
      "[4754,     1] loss: 0.0005826285341754556\n",
      "[4755,     1] loss: 0.0006013379315845668\n",
      "[4756,     1] loss: 0.0006221087533049285\n",
      "[4757,     1] loss: 0.0006478206487372518\n",
      "[4758,     1] loss: 0.000676518480759114\n",
      "[4759,     1] loss: 0.000712667650077492\n",
      "[4760,     1] loss: 0.0007516908808611333\n",
      "[4761,     1] loss: 0.0007975931512191892\n",
      "[4762,     1] loss: 0.0008432296453975141\n",
      "[4763,     1] loss: 0.0008871488971635699\n",
      "[4764,     1] loss: 0.0009186416864395142\n",
      "[4765,     1] loss: 0.000930505630094558\n",
      "[4766,     1] loss: 0.0009183752117678523\n",
      "[4767,     1] loss: 0.0008854127954691648\n",
      "[4768,     1] loss: 0.0008280633483082056\n",
      "[4769,     1] loss: 0.0007568132132291794\n",
      "[4770,     1] loss: 0.0006828500190749764\n",
      "[4771,     1] loss: 0.000617878744378686\n",
      "[4772,     1] loss: 0.0005712542915716767\n",
      "[4773,     1] loss: 0.0005469878669828176\n",
      "[4774,     1] loss: 0.0005443816189654171\n",
      "[4775,     1] loss: 0.0005585147882811725\n",
      "[4776,     1] loss: 0.000584432331379503\n",
      "[4777,     1] loss: 0.0006146466475911438\n",
      "[4778,     1] loss: 0.0006477625574916601\n",
      "[4779,     1] loss: 0.0006735543720424175\n",
      "[4780,     1] loss: 0.000693881418555975\n",
      "[4781,     1] loss: 0.0007005090592429042\n",
      "[4782,     1] loss: 0.0006999126635491848\n",
      "[4783,     1] loss: 0.0006845993921160698\n",
      "[4784,     1] loss: 0.0006660483195446432\n",
      "[4785,     1] loss: 0.000637806486338377\n",
      "[4786,     1] loss: 0.0006084399065002799\n",
      "[4787,     1] loss: 0.0005794688477180898\n",
      "[4788,     1] loss: 0.0005570778739638627\n",
      "[4789,     1] loss: 0.0005416328203864396\n",
      "[4790,     1] loss: 0.0005343992379494011\n",
      "[4791,     1] loss: 0.0005354800960049033\n",
      "[4792,     1] loss: 0.0005430374294519424\n",
      "[4793,     1] loss: 0.0005558445700444281\n",
      "[4794,     1] loss: 0.000572478398680687\n",
      "[4795,     1] loss: 0.0005918934475630522\n",
      "[4796,     1] loss: 0.0006119299214333296\n",
      "[4797,     1] loss: 0.0006346458103507757\n",
      "[4798,     1] loss: 0.0006573876598849893\n",
      "[4799,     1] loss: 0.0006830618367530406\n",
      "[4800,     1] loss: 0.0007069558487273753\n",
      "[4801,     1] loss: 0.0007314612157642841\n",
      "[4802,     1] loss: 0.0007598407100886106\n",
      "[4803,     1] loss: 0.0007843137718737125\n",
      "[4804,     1] loss: 0.0008094484219327569\n",
      "[4805,     1] loss: 0.0008268547244369984\n",
      "[4806,     1] loss: 0.0008426558924838901\n",
      "[4807,     1] loss: 0.0008435597410425544\n",
      "[4808,     1] loss: 0.0008401370141655207\n",
      "[4809,     1] loss: 0.0008257568115368485\n",
      "[4810,     1] loss: 0.0008370653376914561\n",
      "[4811,     1] loss: 0.000850832206197083\n",
      "[4812,     1] loss: 0.0009112550760619342\n",
      "[4813,     1] loss: 0.0009750035824254155\n",
      "[4814,     1] loss: 0.0010975399054586887\n",
      "[4815,     1] loss: 0.0011889939196407795\n",
      "[4816,     1] loss: 0.0013178337831050158\n",
      "[4817,     1] loss: 0.001364968135021627\n",
      "[4818,     1] loss: 0.0014327636454254389\n",
      "[4819,     1] loss: 0.0013813393888995051\n",
      "[4820,     1] loss: 0.0012970550451427698\n",
      "[4821,     1] loss: 0.001117817359045148\n",
      "[4822,     1] loss: 0.0009322118712589145\n",
      "[4823,     1] loss: 0.0007424693321809173\n",
      "[4824,     1] loss: 0.0006091421819292009\n",
      "[4825,     1] loss: 0.0005535254022106528\n",
      "[4826,     1] loss: 0.0005716379382647574\n",
      "[4827,     1] loss: 0.0006355894729495049\n",
      "[4828,     1] loss: 0.0007076013134792447\n",
      "[4829,     1] loss: 0.0007763833273202181\n",
      "[4830,     1] loss: 0.0008050994947552681\n",
      "[4831,     1] loss: 0.0008220943855121732\n",
      "[4832,     1] loss: 0.0007921362412162125\n",
      "[4833,     1] loss: 0.0007540964288637042\n",
      "[4834,     1] loss: 0.0006947642541490495\n",
      "[4835,     1] loss: 0.0006394653464667499\n",
      "[4836,     1] loss: 0.0005994897801429033\n",
      "[4837,     1] loss: 0.0005837102071382105\n",
      "[4838,     1] loss: 0.0005916680674999952\n",
      "[4839,     1] loss: 0.0006124939536675811\n",
      "[4840,     1] loss: 0.0006396432290785015\n",
      "[4841,     1] loss: 0.0006602723151445389\n",
      "[4842,     1] loss: 0.000676716910675168\n",
      "[4843,     1] loss: 0.0006779177929274738\n",
      "[4844,     1] loss: 0.0006721791578456759\n",
      "[4845,     1] loss: 0.0006501127500087023\n",
      "[4846,     1] loss: 0.0006227458361536264\n",
      "[4847,     1] loss: 0.0005906248698011041\n",
      "[4848,     1] loss: 0.0005622197641059756\n",
      "[4849,     1] loss: 0.0005418552900664508\n",
      "[4850,     1] loss: 0.0005321541102603078\n",
      "[4851,     1] loss: 0.0005329361301846802\n",
      "[4852,     1] loss: 0.0005414258921518922\n",
      "[4853,     1] loss: 0.000554740778170526\n",
      "[4854,     1] loss: 0.0005679787136614323\n",
      "[4855,     1] loss: 0.0005829376168549061\n",
      "[4856,     1] loss: 0.0005935169756412506\n",
      "[4857,     1] loss: 0.0006048304494470358\n",
      "[4858,     1] loss: 0.0006107438821345568\n",
      "[4859,     1] loss: 0.0006204452365636826\n",
      "[4860,     1] loss: 0.0006278688670136034\n",
      "[4861,     1] loss: 0.0006485139019787312\n",
      "[4862,     1] loss: 0.0006733093759976327\n",
      "[4863,     1] loss: 0.0007170136086642742\n",
      "[4864,     1] loss: 0.0007723477319814265\n",
      "[4865,     1] loss: 0.000864229048602283\n",
      "[4866,     1] loss: 0.0009755706414580345\n",
      "[4867,     1] loss: 0.0011488550808280706\n",
      "[4868,     1] loss: 0.0013410653918981552\n",
      "[4869,     1] loss: 0.0015875841490924358\n",
      "[4870,     1] loss: 0.0018032764783129096\n",
      "[4871,     1] loss: 0.002098738681524992\n",
      "[4872,     1] loss: 0.0022558216005563736\n",
      "[4873,     1] loss: 0.002336622215807438\n",
      "[4874,     1] loss: 0.0021748063154518604\n",
      "[4875,     1] loss: 0.0020218011923134327\n",
      "[4876,     1] loss: 0.0017110207118093967\n",
      "[4877,     1] loss: 0.001476739183999598\n",
      "[4878,     1] loss: 0.001244791317731142\n",
      "[4879,     1] loss: 0.0011305389925837517\n",
      "[4880,     1] loss: 0.0010418524034321308\n",
      "[4881,     1] loss: 0.0009886136977002025\n",
      "[4882,     1] loss: 0.0009174339938908815\n",
      "[4883,     1] loss: 0.0008454928756691515\n",
      "[4884,     1] loss: 0.0007998888613656163\n",
      "[4885,     1] loss: 0.0007946096593514085\n",
      "[4886,     1] loss: 0.0008373073651455343\n",
      "[4887,     1] loss: 0.000882093736436218\n",
      "[4888,     1] loss: 0.0009224622044712305\n",
      "[4889,     1] loss: 0.0008885354618541896\n",
      "[4890,     1] loss: 0.0008089891052804887\n",
      "[4891,     1] loss: 0.0006855660467408597\n",
      "[4892,     1] loss: 0.000579766696318984\n",
      "[4893,     1] loss: 0.0005308760446496308\n",
      "[4894,     1] loss: 0.0005491195479407907\n",
      "[4895,     1] loss: 0.0006091785617172718\n",
      "[4896,     1] loss: 0.0006698361248709261\n",
      "[4897,     1] loss: 0.0007033750298433006\n",
      "[4898,     1] loss: 0.0006883688038215041\n",
      "[4899,     1] loss: 0.0006420137942768633\n",
      "[4900,     1] loss: 0.0005799056962132454\n",
      "[4901,     1] loss: 0.0005299358745105565\n",
      "[4902,     1] loss: 0.0005078205722384155\n",
      "[4903,     1] loss: 0.0005144206807017326\n",
      "[4904,     1] loss: 0.0005386726697906852\n",
      "[4905,     1] loss: 0.0005641086027026176\n",
      "[4906,     1] loss: 0.0005812621093355119\n",
      "[4907,     1] loss: 0.0005815732292830944\n",
      "[4908,     1] loss: 0.0005743722431361675\n",
      "[4909,     1] loss: 0.0005578038399107754\n",
      "[4910,     1] loss: 0.0005411714082583785\n",
      "[4911,     1] loss: 0.0005296813906170428\n",
      "[4912,     1] loss: 0.0005255534779280424\n",
      "[4913,     1] loss: 0.0005266628577373922\n",
      "[4914,     1] loss: 0.0005298025207594037\n",
      "[4915,     1] loss: 0.0005317780305631459\n",
      "[4916,     1] loss: 0.0005302190547809005\n",
      "[4917,     1] loss: 0.0005251659895293415\n",
      "[4918,     1] loss: 0.0005178079009056091\n",
      "[4919,     1] loss: 0.0005107985343784094\n",
      "[4920,     1] loss: 0.0005057707312516868\n",
      "[4921,     1] loss: 0.0005041101831011474\n",
      "[4922,     1] loss: 0.0005053741042502224\n",
      "[4923,     1] loss: 0.0005087683675810695\n",
      "[4924,     1] loss: 0.000512902915943414\n",
      "[4925,     1] loss: 0.0005169548094272614\n",
      "[4926,     1] loss: 0.0005204807966947556\n",
      "[4927,     1] loss: 0.0005228748195804656\n",
      "[4928,     1] loss: 0.0005248881643638015\n",
      "[4929,     1] loss: 0.0005258871824480593\n",
      "[4930,     1] loss: 0.0005263136699795723\n",
      "[4931,     1] loss: 0.0005261451588012278\n",
      "[4932,     1] loss: 0.0005258865421637893\n",
      "[4933,     1] loss: 0.000527199066709727\n",
      "[4934,     1] loss: 0.0005295053706504405\n",
      "[4935,     1] loss: 0.0005354669992811978\n",
      "[4936,     1] loss: 0.0005427274736575782\n",
      "[4937,     1] loss: 0.0005556833930313587\n",
      "[4938,     1] loss: 0.0005695519503206015\n",
      "[4939,     1] loss: 0.0005907471640966833\n",
      "[4940,     1] loss: 0.000611657917033881\n",
      "[4941,     1] loss: 0.0006471723318099976\n",
      "[4942,     1] loss: 0.0006836778484284878\n",
      "[4943,     1] loss: 0.0007404921925626695\n",
      "[4944,     1] loss: 0.0007970170117914677\n",
      "[4945,     1] loss: 0.0008935523219406605\n",
      "[4946,     1] loss: 0.0009872268419712782\n",
      "[4947,     1] loss: 0.0011322371428832412\n",
      "[4948,     1] loss: 0.0012615114683285356\n",
      "[4949,     1] loss: 0.0014964204747229815\n",
      "[4950,     1] loss: 0.0016751617658883333\n",
      "[4951,     1] loss: 0.0019447340164333582\n",
      "[4952,     1] loss: 0.0020682220347225666\n",
      "[4953,     1] loss: 0.0022386808414012194\n",
      "[4954,     1] loss: 0.0021441495046019554\n",
      "[4955,     1] loss: 0.0020034112967550755\n",
      "[4956,     1] loss: 0.0016131831798702478\n",
      "[4957,     1] loss: 0.001187033485621214\n",
      "[4958,     1] loss: 0.0007824556669220328\n",
      "[4959,     1] loss: 0.000545410206541419\n",
      "[4960,     1] loss: 0.0005143360467627645\n",
      "[4961,     1] loss: 0.0006444102618843317\n",
      "[4962,     1] loss: 0.0008411144372075796\n",
      "[4963,     1] loss: 0.0009968035155907273\n",
      "[4964,     1] loss: 0.0010752256494015455\n",
      "[4965,     1] loss: 0.001021017087623477\n",
      "[4966,     1] loss: 0.0008955530938692391\n",
      "[4967,     1] loss: 0.0007221408886834979\n",
      "[4968,     1] loss: 0.000580242951400578\n",
      "[4969,     1] loss: 0.0005082038696855307\n",
      "[4970,     1] loss: 0.0005138004198670387\n",
      "[4971,     1] loss: 0.0005728089017793536\n",
      "[4972,     1] loss: 0.0006448147469200194\n",
      "[4973,     1] loss: 0.0007026554667390883\n",
      "[4974,     1] loss: 0.0007165376446209848\n",
      "[4975,     1] loss: 0.0007052944274619222\n",
      "[4976,     1] loss: 0.0006556113949045539\n",
      "[4977,     1] loss: 0.0005950412014499307\n",
      "[4978,     1] loss: 0.0005395505577325821\n",
      "[4979,     1] loss: 0.0005056578665971756\n",
      "[4980,     1] loss: 0.0004975688643753529\n",
      "[4981,     1] loss: 0.0005107078468427062\n",
      "[4982,     1] loss: 0.0005357075133360922\n",
      "[4983,     1] loss: 0.0005594148533418775\n",
      "[4984,     1] loss: 0.0005787804257124662\n",
      "[4985,     1] loss: 0.000583033193834126\n",
      "[4986,     1] loss: 0.0005799558130092919\n",
      "[4987,     1] loss: 0.0005629229126498103\n",
      "[4988,     1] loss: 0.000543261063285172\n",
      "[4989,     1] loss: 0.0005210161907598376\n",
      "[4990,     1] loss: 0.0005028473678976297\n",
      "[4991,     1] loss: 0.0004915246972814202\n",
      "[4992,     1] loss: 0.00048820493975654244\n",
      "[4993,     1] loss: 0.0004918280756101012\n",
      "[4994,     1] loss: 0.0004997007781639695\n",
      "[4995,     1] loss: 0.0005088538746349514\n",
      "[4996,     1] loss: 0.0005173595272935927\n",
      "[4997,     1] loss: 0.0005251835682429373\n",
      "[4998,     1] loss: 0.0005296441377140582\n",
      "[4999,     1] loss: 0.0005356638575904071\n",
      "[5000,     1] loss: 0.0005368625861592591\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "epochs      = 5_000\n",
    "batch_size  = 500\n",
    "num_batches = N_train // batch_size\n",
    "\n",
    "losses = []\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    rolling_loss = 0\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        theta_batch, (A_batch, B_batch) = thetas_train[i*batch_size:(i+1)*batch_size], (As_train[i*batch_size:(i+1)*batch_size], Bs_train[i*batch_size:(i+1)*batch_size])\n",
    "        A_hat_batch, B_hat_batch = net(theta_batch)\n",
    "        \n",
    "        loss = criterion(A_hat_batch, A_batch) + criterion(B_hat_batch, B_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        rolling_loss += loss.item()\n",
    "    losses.append(rolling_loss)\n",
    "    print(f'[{epoch + 1}, {i + 1:5d}] loss: {rolling_loss}')\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_scores(net, num_samples, get_true_dynamics=False):\n",
    "    if get_true_dynamics:\n",
    "        xs, (As, Bs), _ = generate_data(num_samples)\n",
    "    else:\n",
    "        xs, _, (As, Bs) = generate_data(num_samples)\n",
    "    A_hat, B_hat = net(xs)\n",
    "\n",
    "    C = torch.cat([As, Bs], axis=-1).cpu().detach().numpy()\n",
    "    C_hat = torch.cat([A_hat, B_hat], axis=-1).cpu().detach().numpy()\n",
    "    diff = C - C_hat\n",
    "    return (C, C_hat), np.linalg.norm(diff, ord=2, axis=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1648569250.6082177. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6.10743788505025e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6.740338532024325e+16. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 440233.213234244. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.9123493995059966e+21. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 115445.57261040148. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2145196684.390448. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 546556735810992.4. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6.1511686139709e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 17639381.622541487. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 352589947027.31085. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4043501.7865522658. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 8273148972547.831. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 61111791.60750868. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3.2188743561124412e+16. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 429376.24812381313. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.5856881345222608e+16. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 11214405.300308062. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 39232831.96197691. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.886761171567712e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4455236.560991683. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 21910780199190.2. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2028812558103.4585. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4.1390468233677494e+21. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 586495570829947.1. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 5030448232.243758. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4.440916478741756e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1731112.877072036. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 103334304.62599167. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 49311049.80406512. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 7589426.368263156. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1371090.26089299. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.8792533397931828e+16. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1182828.0753625564. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 701734.6066406119. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 198429792829.0008. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 340699708045.6498. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1867544.1942746544. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2579496.613876742. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 294673.4959932655. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4973510.718373643. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 81620492.09625283. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 13661640.660039654. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 426192.3545640274. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3.8264315030141645e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1164629.21051017. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 181028471.12436154. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 11009412174.756968. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 14436885.720307577. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 204395289.4731842. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 220990915.1458925. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 10352440037.170483. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.0192312054608114e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 9.565501815585243e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 140933.4134471873. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1451159957.8345463. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2148632703.461843. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3.0741914673691086e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.6319890848203735e+22. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 32040581.654294826. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 437859.6725255579. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6.158453746663142e+16. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 129832.90157179338. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3.973665072726395e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3209490521901018.5. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 7.732566758015334e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.2840518680680336e+16. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.513868092012097e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 17495422.111465458. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 846135119048.7726. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 369937.209027772. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4303257681.400635. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 75002688.25933991. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 923706.579867392. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 829781020281499.1. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.5296165518589457e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 208734.40726829087. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3.20726533731816e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 47004395035.4402. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 329028057.01236695. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.0258331090871014e+16. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 101728975683.56396. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 12702750312888.664. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 17155977179.766752. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 214252461.40010542. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 125116.33659139044. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 12749274.922479985. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 144832538.42451596. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 5634740.971419716. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 22814589001.0931. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.0781431494233709e+24. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 59029793.79894955. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 569264.4568505306. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.405239287724526e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 60376827099.017296. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 21083934590.945297. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 283730217645.9297. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 285768109.6929337. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 20725388641298.02. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 368557.09765633254. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6065432.6959919445. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 594362.4901768538. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 7071049276.00996. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6.984236613796435e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1653031.1617946215. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 832216998.674416. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 242455474.97865704. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4.0303488429304095e+19. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 73847983416.38829. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 10614041.677643653. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 705927840.3305382. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 5.711017621615449e+17. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 463899073263476.25. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 8837526.215209736. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 222729.8388333825. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 51750051713.915565. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1248436.1403623696. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 27345228697548.082. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 7192826391.531595. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 52662909043.379715. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1384533572.020058. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 230238.2044328781. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 97009778.83161137. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 5.736303432696144e+16. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.876529016413106e+22. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2559706.469419951. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 173248698.64740515. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.1374428134883113e+23. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.1457945454499615e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.2024194572775252e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 288185.24190055765. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 10338664094882.889. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2926993656053.0195. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2011434.6228541443. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 476757248.4130408. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 362626.8233205996. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 711068119.8362008. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3804930557480.657. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 244284826.70268756. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4.336100900502632e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.8567562793760307e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2977837.6642406983. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 74704784.6763039. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 7999227727211.7295. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 6.106376462269168e+20. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3678390631.8962092. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 506160.93609355204. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4805612432009.379. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2082197670678.4172. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 4.4444087910805117e+21. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 574832763662716.8. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2.0727292178858535e+21. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 443724938.62409157. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2050296306095.6448. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 210391.17243748947. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 210453.8235769862. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 248931836665292.44. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 8.889023648443811e+16. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 50457566.47777206. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 288234.7107950506. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 408568627607.15106. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 201965.8535552407. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 2616757.667565153. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 7967486816.376607. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 19364331.59730966. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 3.6557665929119565e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1372600.5662497543. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 658892918813949.1. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 1.0587309607092732e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 5.804477736922704e+18. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n",
      "/home/yppatel/anaconda3/envs/operator/lib/python3.11/site-packages/pydmd/snapshots.py:73: UserWarning: Input data condition number 18562878.649536368. Consider preprocessing data, passing in augmented data\n",
      "matrix, or regularization methods.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "N_cal, N_test = 200, 200\n",
    "(cal_C, cal_C_hat),   cal_scores  = generate_scores(net, num_samples=N_cal,  get_true_dynamics=False)\n",
    "(test_C, test_C_hat), test_scores = generate_scores(net, num_samples=N_test, get_true_dynamics=True)\n",
    "N_cal, N_test = len(cal_C), len(test_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '$\\\\mathrm{Model\\\\ Calibration}$')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_theme()\n",
    "\n",
    "plt.rcParams['mathtext.fontset'] = 'stix'\n",
    "plt.rcParams['font.family'] = 'STIXGeneral'\n",
    "\n",
    "SMALL_SIZE = 12\n",
    "MEDIUM_SIZE = 14\n",
    "BIGGER_SIZE = 18\n",
    "\n",
    "plt.rc('font', size=MEDIUM_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=MEDIUM_SIZE)  # fontsize of the figure title\n",
    "\n",
    "alphas = np.arange(0, 1, 0.05)\n",
    "coverages = []\n",
    "for alpha in alphas:\n",
    "    q_hat = np.quantile(cal_scores, q = 1-alpha)\n",
    "    coverages.append(np.sum(test_scores < q_hat) / N_test)\n",
    "\n",
    "sns.lineplot(x=(1-alphas), y=(1-alphas), linestyle='--')\n",
    "sns.lineplot(x=(1-alphas), y=coverages)\n",
    "plt.xlabel(r\"$\\mathrm{Expected\\ Coverage} (1-\\alpha)$\")\n",
    "plt.ylabel(r\"$\\mathrm{Empirical\\ Coverage}$\")\n",
    "plt.title(r\"$\\mathrm{Model\\ Calibration}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "q_hat = np.quantile(cal_scores, q = 1-alpha)\n",
    "\n",
    "with open(\"experiments/load_pos.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"test_C\": test_C, \n",
    "        \"test_C_hat\": test_C_hat,\n",
    "        \"q_hat\": q_hat,\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "operator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
