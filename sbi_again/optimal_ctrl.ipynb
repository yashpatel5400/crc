{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from train_dynamics import generate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Flow(\n",
       "  (_transform): CompositeTransform(\n",
       "    (_transforms): ModuleList(\n",
       "      (0): PiecewiseRationalQuadraticCouplingTransform(\n",
       "        (transform_net): ResidualNet(\n",
       "          (initial_layer): Linear(in_features=15, out_features=50, bias=True)\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x ResidualBlock(\n",
       "              (context_layer): Linear(in_features=12, out_features=50, bias=True)\n",
       "              (linear_layers): ModuleList(\n",
       "                (0-1): 2 x Linear(in_features=50, out_features=50, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (final_layer): Linear(in_features=50, out_features=87, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): LULinear()\n",
       "      (2): PiecewiseRationalQuadraticCouplingTransform(\n",
       "        (transform_net): ResidualNet(\n",
       "          (initial_layer): Linear(in_features=15, out_features=50, bias=True)\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x ResidualBlock(\n",
       "              (context_layer): Linear(in_features=12, out_features=50, bias=True)\n",
       "              (linear_layers): ModuleList(\n",
       "                (0-1): 2 x Linear(in_features=50, out_features=50, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (final_layer): Linear(in_features=50, out_features=87, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): LULinear()\n",
       "      (4): PiecewiseRationalQuadraticCouplingTransform(\n",
       "        (transform_net): ResidualNet(\n",
       "          (initial_layer): Linear(in_features=15, out_features=50, bias=True)\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x ResidualBlock(\n",
       "              (context_layer): Linear(in_features=12, out_features=50, bias=True)\n",
       "              (linear_layers): ModuleList(\n",
       "                (0-1): 2 x Linear(in_features=50, out_features=50, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (final_layer): Linear(in_features=50, out_features=87, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (5): LULinear()\n",
       "      (6): PiecewiseRationalQuadraticCouplingTransform(\n",
       "        (transform_net): ResidualNet(\n",
       "          (initial_layer): Linear(in_features=15, out_features=50, bias=True)\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x ResidualBlock(\n",
       "              (context_layer): Linear(in_features=12, out_features=50, bias=True)\n",
       "              (linear_layers): ModuleList(\n",
       "                (0-1): 2 x Linear(in_features=50, out_features=50, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (final_layer): Linear(in_features=50, out_features=87, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (7): LULinear()\n",
       "      (8): PiecewiseRationalQuadraticCouplingTransform(\n",
       "        (transform_net): ResidualNet(\n",
       "          (initial_layer): Linear(in_features=15, out_features=50, bias=True)\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x ResidualBlock(\n",
       "              (context_layer): Linear(in_features=12, out_features=50, bias=True)\n",
       "              (linear_layers): ModuleList(\n",
       "                (0-1): 2 x Linear(in_features=50, out_features=50, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (final_layer): Linear(in_features=50, out_features=87, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (9): LULinear()\n",
       "    )\n",
       "  )\n",
       "  (_distribution): StandardNormal()\n",
       "  (_embedding_net): Identity()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "cached_fn = os.path.join(\"dynamics_trained\", \"dynamics.nf\")\n",
    "with open(cached_fn, \"rb\") as f:\n",
    "    encoder = pickle.load(f)\n",
    "encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_scores(xs, Cs, k=10):\n",
    "    cal_samples = encoder.sample(k, xs).detach().cpu().numpy()\n",
    "    cal_samples = cal_samples.reshape((cal_samples.shape[0], k, 2, 3))\n",
    "    cal_tiled = np.transpose(np.tile(Cs.detach().cpu().numpy(), (k, 1, 1, 1)), (1, 0, 2, 3))\n",
    "    cal_diff = cal_samples - cal_tiled\n",
    "    cal_norms = np.linalg.norm(cal_diff, ord=2, axis=(2,3))\n",
    "    return np.min(cal_norms, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C in R^2x3\n",
    "cal_sims = 1_000\n",
    "cal_C_hats, cal_x = generate_data(cal_sims)\n",
    "cal_C_hats = cal_C_hats.reshape((cal_sims, 2, 3))\n",
    "cal_scores = calc_scores(cal_x, cal_C_hats)\n",
    "q_hat = np.quantile(cal_scores, q = 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "test_sims = 1\n",
    "_, test_x = generate_data(test_sims)\n",
    "test_samples = encoder.sample(k, test_x).detach().cpu().numpy()\n",
    "test_samples = test_samples.reshape((test_samples.shape[0], k, 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two steps:\n",
    "# 1. policy gradient for *fixed C*: check if formulation is correct (compare to C obtained from Ricatti eqns)\n",
    "# --- attempt w/ our choice of A/B (w/out noise)\n",
    "# 2. find C maximizer: compare to alt. robust formulations\n",
    "# 3. done with synthetics?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
